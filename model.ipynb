{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Training - Simplified Single-Branch Models\n",
    "\n",
    "This notebook trains separate simplified CNN models for each feature type and then creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 10:23:38.040690: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-09 10:23:38.192598: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-09 10:23:38.192682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-09 10:23:38.217012: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-09 10:23:38.267877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 10:23:38.799936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Average\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from modules.PostgresDBHandler import PostgresDBHandler\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 10:23:39.925095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 10:23:40.006631: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "dbParams = {\n",
    "    \"dbname\": \"mydatabase\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"host\": \"postgres_server\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "KFOLD_SPLITS = 5\n",
    "FIXED_LENGTH = 128\n",
    "\n",
    "# Feature types to train models for\n",
    "FEATURE_TYPES = [\n",
    "    'mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast',\n",
    "    'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength'\n",
    "]\n",
    "\n",
    "# GPU configuration\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Number of available GPUs: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instrument classes: 9\n",
      "Instruments: ['flute', 'violin', 'cello', 'sax', 'oboe', 'trumpet', 'piccolo', 'clarinet', 'bass']\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get instrument mappings\n",
    "instruments_mappings = db.get_mappings_instruments()\n",
    "num_classes = len(instruments_mappings)\n",
    "print(f\"Number of instrument classes: {num_classes}\")\n",
    "print(\"Instruments:\", instruments_mappings['name'].tolist())\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbConnect = PostgresDBHandler(**dbParams)\n",
    "dbConnect.connect()\n",
    "audioIDs = dbConnect.get_all_unique_audio_ids_in_processed()\n",
    "\n",
    "\n",
    "audio_aug_dict = defaultdict(lambda: {'featurePaths': {}, 'instrumentID': None})\n",
    "\n",
    "for audio_id in audioIDs:\n",
    "    features = dbConnect.get_all_feature_types_for_audio(audio_id)\n",
    "    instrumentID = dbConnect.get_audio_file(audio_id)['instrumentID']\n",
    "    for f in features:\n",
    "        key = (audio_id, f['augmentation'])\n",
    "        audio_aug_dict[key]['featurePaths'][f['featureTypeName']] = f['featurePath']\n",
    "        audio_aug_dict[key]['instrumentID'] = instrumentID\n",
    "\n",
    "all_processed_data = []\n",
    "for (audio_id, augmentation), data in audio_aug_dict.items():\n",
    "    row = {ftype: path for ftype, path in data['featurePaths'].items()}\n",
    "    row['audio_id'] = audio_id\n",
    "    row['augmentation'] = augmentation\n",
    "    row['instrumentID'] = data['instrumentID']\n",
    "    all_processed_data.append(row)\n",
    "\n",
    "processed_df = pd.DataFrame(all_processed_data)\n",
    "dbConnect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_spectrogram</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>chromagram</th>\n",
       "      <th>spectral_contrast</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>constant_q</th>\n",
       "      <th>cqt</th>\n",
       "      <th>stft</th>\n",
       "      <th>harmonic_percussive</th>\n",
       "      <th>onset_strength</th>\n",
       "      <th>audio_id</th>\n",
       "      <th>augmentation</th>\n",
       "      <th>instrumentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/84e4acbb-21...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/5a693...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/aaf752d4...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/0fc7c...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/c167800c-651...</td>\n",
       "      <td>ensemble_intermediate_results/stft/793f682f-b3...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/d...</td>\n",
       "      <td>116</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/ba5193db-55...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/636d9...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/6ec6d3aa...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/ea181...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/83cb08ab-a3a...</td>\n",
       "      <td>ensemble_intermediate_results/stft/a7463a37-69...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/f...</td>\n",
       "      <td>87</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/8333fc8e-65...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/ad55d...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/378e29e3...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/16653...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/91ed6a1f-e6c...</td>\n",
       "      <td>ensemble_intermediate_results/stft/a55b67ec-ef...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/a...</td>\n",
       "      <td>71</td>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/6283fbdc-53...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/becc7...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/2b3156d8...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/1acdc...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/07ddd0ff-6a9...</td>\n",
       "      <td>ensemble_intermediate_results/stft/b90453c5-c3...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/b...</td>\n",
       "      <td>68</td>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/4dd2ab2b-ac...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/6d7ca...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/a350e363...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/6860b...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/cd16eb8a-7c5...</td>\n",
       "      <td>ensemble_intermediate_results/stft/8fe10708-a5...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/1...</td>\n",
       "      <td>51</td>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/bd211bc5-77...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/ae2db...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/0e8ea923...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/6f03a...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/b3deefbc-8bb...</td>\n",
       "      <td>ensemble_intermediate_results/stft/bc3bf6b2-50...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/a...</td>\n",
       "      <td>27</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/5f871cad-92...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/3bce4...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/333e3fbf...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/b87f1...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/f520083a-9be...</td>\n",
       "      <td>ensemble_intermediate_results/stft/c5e0867e-97...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/3...</td>\n",
       "      <td>143</td>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/2b90c290-95...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/39172...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/9069e6d8...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/6984b...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/0e2432cc-9b0...</td>\n",
       "      <td>ensemble_intermediate_results/stft/3b382092-9e...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/7...</td>\n",
       "      <td>23</td>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/186a2ea6-c9...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/ee8e6...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/7bdaff5e...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/9d49d...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/921086ea-af4...</td>\n",
       "      <td>ensemble_intermediate_results/stft/eb3f944a-76...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/0...</td>\n",
       "      <td>58</td>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/693d881c-58...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/8124d...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/9af8c968...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/0797d...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/718bb73e-d03...</td>\n",
       "      <td>ensemble_intermediate_results/stft/db96e4f9-bc...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/2...</td>\n",
       "      <td>8</td>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mel_spectrogram  \\\n",
       "0    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "1    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "2    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "3    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "4    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "176  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "177  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "178  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "179  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "\n",
       "                                                  mfcc  \\\n",
       "0    ensemble_intermediate_results/mfcc/84e4acbb-21...   \n",
       "1    ensemble_intermediate_results/mfcc/ba5193db-55...   \n",
       "2    ensemble_intermediate_results/mfcc/8333fc8e-65...   \n",
       "3    ensemble_intermediate_results/mfcc/6283fbdc-53...   \n",
       "4    ensemble_intermediate_results/mfcc/4dd2ab2b-ac...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/mfcc/bd211bc5-77...   \n",
       "176  ensemble_intermediate_results/mfcc/5f871cad-92...   \n",
       "177  ensemble_intermediate_results/mfcc/2b90c290-95...   \n",
       "178  ensemble_intermediate_results/mfcc/186a2ea6-c9...   \n",
       "179  ensemble_intermediate_results/mfcc/693d881c-58...   \n",
       "\n",
       "                                            chromagram  \\\n",
       "0    ensemble_intermediate_results/chromagram/5a693...   \n",
       "1    ensemble_intermediate_results/chromagram/636d9...   \n",
       "2    ensemble_intermediate_results/chromagram/ad55d...   \n",
       "3    ensemble_intermediate_results/chromagram/becc7...   \n",
       "4    ensemble_intermediate_results/chromagram/6d7ca...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/chromagram/ae2db...   \n",
       "176  ensemble_intermediate_results/chromagram/3bce4...   \n",
       "177  ensemble_intermediate_results/chromagram/39172...   \n",
       "178  ensemble_intermediate_results/chromagram/ee8e6...   \n",
       "179  ensemble_intermediate_results/chromagram/8124d...   \n",
       "\n",
       "                                     spectral_contrast  \\\n",
       "0    ensemble_intermediate_results/spectral_contras...   \n",
       "1    ensemble_intermediate_results/spectral_contras...   \n",
       "2    ensemble_intermediate_results/spectral_contras...   \n",
       "3    ensemble_intermediate_results/spectral_contras...   \n",
       "4    ensemble_intermediate_results/spectral_contras...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/spectral_contras...   \n",
       "176  ensemble_intermediate_results/spectral_contras...   \n",
       "177  ensemble_intermediate_results/spectral_contras...   \n",
       "178  ensemble_intermediate_results/spectral_contras...   \n",
       "179  ensemble_intermediate_results/spectral_contras...   \n",
       "\n",
       "                                               tonnetz  \\\n",
       "0    ensemble_intermediate_results/tonnetz/aaf752d4...   \n",
       "1    ensemble_intermediate_results/tonnetz/6ec6d3aa...   \n",
       "2    ensemble_intermediate_results/tonnetz/378e29e3...   \n",
       "3    ensemble_intermediate_results/tonnetz/2b3156d8...   \n",
       "4    ensemble_intermediate_results/tonnetz/a350e363...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/tonnetz/0e8ea923...   \n",
       "176  ensemble_intermediate_results/tonnetz/333e3fbf...   \n",
       "177  ensemble_intermediate_results/tonnetz/9069e6d8...   \n",
       "178  ensemble_intermediate_results/tonnetz/7bdaff5e...   \n",
       "179  ensemble_intermediate_results/tonnetz/9af8c968...   \n",
       "\n",
       "                                            constant_q  \\\n",
       "0    ensemble_intermediate_results/constant_q/0fc7c...   \n",
       "1    ensemble_intermediate_results/constant_q/ea181...   \n",
       "2    ensemble_intermediate_results/constant_q/16653...   \n",
       "3    ensemble_intermediate_results/constant_q/1acdc...   \n",
       "4    ensemble_intermediate_results/constant_q/6860b...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/constant_q/6f03a...   \n",
       "176  ensemble_intermediate_results/constant_q/b87f1...   \n",
       "177  ensemble_intermediate_results/constant_q/6984b...   \n",
       "178  ensemble_intermediate_results/constant_q/9d49d...   \n",
       "179  ensemble_intermediate_results/constant_q/0797d...   \n",
       "\n",
       "                                                   cqt  \\\n",
       "0    ensemble_intermediate_results/cqt/c167800c-651...   \n",
       "1    ensemble_intermediate_results/cqt/83cb08ab-a3a...   \n",
       "2    ensemble_intermediate_results/cqt/91ed6a1f-e6c...   \n",
       "3    ensemble_intermediate_results/cqt/07ddd0ff-6a9...   \n",
       "4    ensemble_intermediate_results/cqt/cd16eb8a-7c5...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/cqt/b3deefbc-8bb...   \n",
       "176  ensemble_intermediate_results/cqt/f520083a-9be...   \n",
       "177  ensemble_intermediate_results/cqt/0e2432cc-9b0...   \n",
       "178  ensemble_intermediate_results/cqt/921086ea-af4...   \n",
       "179  ensemble_intermediate_results/cqt/718bb73e-d03...   \n",
       "\n",
       "                                                  stft  \\\n",
       "0    ensemble_intermediate_results/stft/793f682f-b3...   \n",
       "1    ensemble_intermediate_results/stft/a7463a37-69...   \n",
       "2    ensemble_intermediate_results/stft/a55b67ec-ef...   \n",
       "3    ensemble_intermediate_results/stft/b90453c5-c3...   \n",
       "4    ensemble_intermediate_results/stft/8fe10708-a5...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/stft/bc3bf6b2-50...   \n",
       "176  ensemble_intermediate_results/stft/c5e0867e-97...   \n",
       "177  ensemble_intermediate_results/stft/3b382092-9e...   \n",
       "178  ensemble_intermediate_results/stft/eb3f944a-76...   \n",
       "179  ensemble_intermediate_results/stft/db96e4f9-bc...   \n",
       "\n",
       "                                   harmonic_percussive  \\\n",
       "0    ensemble_intermediate_results/harmonic_percuss...   \n",
       "1    ensemble_intermediate_results/harmonic_percuss...   \n",
       "2    ensemble_intermediate_results/harmonic_percuss...   \n",
       "3    ensemble_intermediate_results/harmonic_percuss...   \n",
       "4    ensemble_intermediate_results/harmonic_percuss...   \n",
       "..                                                 ...   \n",
       "175  ensemble_intermediate_results/harmonic_percuss...   \n",
       "176  ensemble_intermediate_results/harmonic_percuss...   \n",
       "177  ensemble_intermediate_results/harmonic_percuss...   \n",
       "178  ensemble_intermediate_results/harmonic_percuss...   \n",
       "179  ensemble_intermediate_results/harmonic_percuss...   \n",
       "\n",
       "                                        onset_strength  audio_id augmentation  \\\n",
       "0    ensemble_intermediate_results/onset_strength/d...       116     original   \n",
       "1    ensemble_intermediate_results/onset_strength/f...        87     original   \n",
       "2    ensemble_intermediate_results/onset_strength/a...        71     original   \n",
       "3    ensemble_intermediate_results/onset_strength/b...        68     original   \n",
       "4    ensemble_intermediate_results/onset_strength/1...        51     original   \n",
       "..                                                 ...       ...          ...   \n",
       "175  ensemble_intermediate_results/onset_strength/a...        27     original   \n",
       "176  ensemble_intermediate_results/onset_strength/3...       143     original   \n",
       "177  ensemble_intermediate_results/onset_strength/7...        23     original   \n",
       "178  ensemble_intermediate_results/onset_strength/0...        58     original   \n",
       "179  ensemble_intermediate_results/onset_strength/2...         8     original   \n",
       "\n",
       "     instrumentID  \n",
       "0               1  \n",
       "1               1  \n",
       "2               8  \n",
       "3               8  \n",
       "4               3  \n",
       "..            ...  \n",
       "175             6  \n",
       "176             5  \n",
       "177             6  \n",
       "178             8  \n",
       "179             2  \n",
       "\n",
       "[180 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = pd.DataFrame(all_processed_data)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_shape(feature_type, df):\n",
    "    feature_path_col = feature_type \n",
    "    for path in df[feature_path_col]:\n",
    "        if isinstance(path, str) and os.path.exists(path):\n",
    "            arr = np.load(path)\n",
    "            return arr.shape\n",
    "    raise ValueError(f\"No valid file found for {feature_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleFeatureDataGenerator(Sequence):\n",
    "    def __init__(self, df, feature_col, batch_size=32, shuffle=True, num_classes=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_col = feature_col\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = num_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            try:\n",
    "                arr = np.load(row[self.feature_col])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {row[self.feature_col]}: {e}\")\n",
    "                continue\n",
    "        \n",
    "            if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "                raise ValueError(f\"Feature file {row[self.feature_col]} contains NaNs or Infs.\")\n",
    "        \n",
    "            arr = (arr - np.mean(arr)) / (np.std(arr) + 1e-8)\n",
    "            if arr.ndim == 2:\n",
    "                arr = np.expand_dims(arr, -1)  # shape: (H, W, 1)\n",
    "        \n",
    "            X.append(arr)\n",
    "            y.append(row['instrumentID'])  # already label-encoded\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = to_categorical(np.array(y), num_classes=self.num_classes)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(input_shape, num_classes, model_name=\"simple_cnn\"):\n",
    "    input_layer = Input(shape=(*input_shape, 1), name=f\"{model_name}_input\")\n",
    "\n",
    "    x = Conv2D(4, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    output = Dense(num_classes, activation='softmax', name=f\"{model_name}_output\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output, name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training features:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for mel_spectrogram\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 70.8796 - accuracy: 0.2957 - val_loss: 14.7397 - val_accuracy: 0.2069\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 31.5004 - accuracy: 0.6087 - val_loss: 5.9689 - val_accuracy: 0.3103\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 9.5407 - accuracy: 0.7478 - val_loss: 8.7022 - val_accuracy: 0.2759\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9927 - accuracy: 0.9130 - val_loss: 11.3907 - val_accuracy: 0.2759\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3698 - accuracy: 0.9304 - val_loss: 10.9294 - val_accuracy: 0.3448\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0429 - accuracy: 0.9913 - val_loss: 9.6451 - val_accuracy: 0.3793\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4778 - accuracy: 0.9826 - val_loss: 8.8222 - val_accuracy: 0.3793\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1171 - accuracy: 0.9826 - val_loss: 8.2842 - val_accuracy: 0.4483\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1458 - accuracy: 0.9913 - val_loss: 8.0845 - val_accuracy: 0.4828\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7330e-06 - accuracy: 1.0000 - val_loss: 8.0727 - val_accuracy: 0.4828\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.5610e-06 - accuracy: 1.0000 - val_loss: 7.9236 - val_accuracy: 0.4828\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0770e-05 - accuracy: 1.0000 - val_loss: 7.7105 - val_accuracy: 0.5517\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.6529 - accuracy: 0.3056\n",
      "mel_spectrogram - Fold 1 Test accuracy: 0.3056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 95.0003 - accuracy: 0.1913 - val_loss: 7.4731 - val_accuracy: 0.5517\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 25.5613 - accuracy: 0.5652 - val_loss: 7.9232 - val_accuracy: 0.4138\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 15.0851 - accuracy: 0.6348 - val_loss: 9.2107 - val_accuracy: 0.5172\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 11.1891 - accuracy: 0.7826 - val_loss: 8.1244 - val_accuracy: 0.5517\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.1333 - accuracy: 0.8870 - val_loss: 11.6722 - val_accuracy: 0.5172\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.5981 - accuracy: 0.9478 - val_loss: 11.6623 - val_accuracy: 0.4828\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5334 - accuracy: 0.9826 - val_loss: 9.6661 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4598 - accuracy: 0.9739 - val_loss: 9.4257 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9216 - accuracy: 0.9652 - val_loss: 9.5881 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 10.5578 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.9895 - val_accuracy: 0.5172\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9625 - accuracy: 0.5000\n",
      "mel_spectrogram - Fold 2 Test accuracy: 0.5000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 31ms/step - loss: 69.3001 - accuracy: 0.2087 - val_loss: 7.4665 - val_accuracy: 0.3793\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 23.3106 - accuracy: 0.6696 - val_loss: 18.2028 - val_accuracy: 0.3103\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.8565 - accuracy: 0.8174 - val_loss: 17.9458 - val_accuracy: 0.3793\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.5408 - accuracy: 0.9043 - val_loss: 17.6884 - val_accuracy: 0.3793\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9153 - accuracy: 0.9565 - val_loss: 15.5644 - val_accuracy: 0.4828\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5767 - accuracy: 0.9826 - val_loss: 15.4831 - val_accuracy: 0.4138\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1059 - accuracy: 0.9913 - val_loss: 16.5969 - val_accuracy: 0.4828\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0379 - accuracy: 0.9913 - val_loss: 17.5103 - val_accuracy: 0.4828\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.4346e-06 - accuracy: 1.0000 - val_loss: 17.9055 - val_accuracy: 0.4828\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2953 - accuracy: 0.9826 - val_loss: 17.7983 - val_accuracy: 0.4483\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 8.2928e-09 - accuracy: 1.0000 - val_loss: 17.6294 - val_accuracy: 0.4483\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3648 - accuracy: 0.3333\n",
      "mel_spectrogram - Fold 3 Test accuracy: 0.3333\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 4.1720 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training features:   0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     40\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 42\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m history_list\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:1841\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;66;03m# Create data_handler for evaluation and cache it.\u001b[39;00m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m   1857\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1858\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1867\u001b[0m     _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1868\u001b[0m )\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1024\u001b[0m, in \u001b[0;36mKerasSequenceAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_sequence \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enqueuer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shuffle is handed in the _make_callable override.\u001b[39;49;00m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:920\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m generator_fn():\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_standardize_batch(data)\n\u001b[0;32m--> 920\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_signature\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_multiprocessing:\n\u001b[1;32m    925\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:967\u001b[0m, in \u001b[0;36mDatasetV2.from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# from_generator_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_generator_op\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_generator_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py:331\u001b[0m, in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    323\u001b[0m id_dataset \u001b[38;5;241m=\u001b[39m dataset_ops\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensors(dummy, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# A dataset that contains all of the elements generated by a\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# single iterator created from `generator`, identified by the\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;66;03m# iterator ID contained in `id_dataset`. Lifting the iteration\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# into a flat_map here enables multiple repetitions and/or nested\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# versions of the returned dataset to be created, because it forces\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# the generation of a new ID for each version.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mid_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_map_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2325\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2323\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flat_map_op\n\u001b[0;32m-> 2325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflat_map_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_FlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dataset, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m---> 33\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, dataset_ops\u001b[38;5;241m.\u001b[39mDatasetSpec):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_ops\u001b[38;5;241m.\u001b[39mget_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py:309\u001b[0m, in \u001b[0;36m_from_generator.<locals>.flat_map_fn\u001b[0;34m(dummy_arg)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflat_map_fn\u001b[39m(dummy_arg):\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;66;03m# The `get_iterator_id_fn` gets a unique ID for the current instance of\u001b[39;00m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;66;03m# of the generator.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m   \u001b[38;5;66;03m# The `generator_next_fn` gets the next element from the iterator with the\u001b[39;00m\n\u001b[1;32m    307\u001b[0m   \u001b[38;5;66;03m# given ID, and raises StopIteration when that iterator contains no\u001b[39;00m\n\u001b[1;32m    308\u001b[0m   \u001b[38;5;66;03m# more elements.\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_GeneratorDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdummy_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m      \u001b[49m\u001b[43mget_iterator_id_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgenerator_next_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfinalize_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/from_generator_op.py:370\u001b[0m, in \u001b[0;36m_GeneratorDataset.__init__\u001b[0;34m(self, init_args, init_func, next_func, finalize_func, output_signature, name)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_structure \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(init_args)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    366\u001b[0m     init_func,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[1;32m    368\u001b[0m     input_structure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_structure)\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_func\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_structure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize_func \u001b[38;5;241m=\u001b[39m structured_function\u001b[38;5;241m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    376\u001b[0m     finalize_func,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_name(),\n\u001b[1;32m    378\u001b[0m     input_structure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_func\u001b[38;5;241m.\u001b[39moutput_structure)\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_signature \u001b[38;5;241m=\u001b[39m output_signature\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1103\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1099\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39mstructured_outputs \u001b[38;5;241m=\u001b[39m func_outputs\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;66;03m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m   1102\u001b[0m       func_graph\u001b[38;5;241m.\u001b[39mcapture(x)\n\u001b[0;32m-> 1103\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1106\u001b[0m   func_graph\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m=\u001b[39m func_graph\u001b[38;5;241m.\u001b[39m_watched_variables  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_control_dependencies:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1199\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(sequence)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Like nest.flatten w/ expand_composites, but returns flow for TensorArrays.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;124;03m  A list of tensors.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m flat_sequence \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(sequence, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m   1200\u001b[0m     item\u001b[38;5;241m.\u001b[39mflow \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, tensor_array_ops\u001b[38;5;241m.\u001b[39mTensorArray) \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m flat_sequence\n\u001b[1;32m   1202\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for feature_type in tqdm(FEATURE_TYPES, desc=\"Training features\"):\n",
    "    print(f\"\\n{'='*40}\\nTraining model for {feature_type}\\n{'='*40}\")\n",
    "\n",
    "    feature_col = feature_type\n",
    "    feature_df = processed_df.dropna(subset=[feature_col])\n",
    "    \n",
    "    # Global label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(feature_df['instrumentID'])\n",
    "\n",
    "    feature_df = feature_df.copy()\n",
    "    feature_df['instrumentID'] = label_encoder.transform(feature_df['instrumentID'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    input_shape = get_input_shape(feature_type, feature_df)\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    accuracy_list, loss_list, history_list = [], [], []\n",
    "    classification_reports, confusion_matrices = [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(feature_df)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{KFOLD_SPLITS} ---\")\n",
    "        train_df = feature_df.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = feature_df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df, test_size=0.2, random_state=42, stratify=train_df['instrumentID'])\n",
    "\n",
    "        # Generators (labels are already encoded)\n",
    "        train_gen = SingleFeatureDataGenerator(train_df, feature_col, BATCH_SIZE, shuffle=True, num_classes=num_classes)\n",
    "        val_gen   = SingleFeatureDataGenerator(val_df,   feature_col, BATCH_SIZE, shuffle=False, num_classes=num_classes)\n",
    "        test_gen  = SingleFeatureDataGenerator(test_df,  feature_col, BATCH_SIZE, shuffle=False, num_classes=num_classes)\n",
    "\n",
    "        # Model\n",
    "        model = create_simple_model(input_shape, num_classes, model_name=feature_type)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[early_stopping])\n",
    "        history_list.append(history.history)\n",
    "\n",
    "        # Evaluation\n",
    "        loss, acc = model.evaluate(test_gen)\n",
    "        loss_list.append(loss)\n",
    "        accuracy_list.append(acc)\n",
    "        print(f\"{feature_type} - Fold {fold+1} Test accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Predictions & Reports\n",
    "        y_pred = model.predict(test_gen)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = []\n",
    "        for _, labels in test_gen:\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "        y_true = np.array(y_true)\n",
    "\n",
    "        report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "        classification_reports.append(report)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_classes).tolist()\n",
    "        confusion_matrices.append(conf_matrix)\n",
    "\n",
    "        # Save model\n",
    "        os.makedirs(f\"models/{feature_type}\", exist_ok=True)\n",
    "        model.save(f\"models/{feature_type}/model_fold{fold+1}.keras\")\n",
    "\n",
    "    # Save results\n",
    "    results[feature_type] = {\n",
    "        \"accuracy_list\": accuracy_list,\n",
    "        \"loss_list\": loss_list,\n",
    "        \"histories\": history_list,\n",
    "        \"classification_reports\": classification_reports,\n",
    "        \"confusion_matrices\": confusion_matrices,\n",
    "    }\n",
    "\n",
    "    with open(f\"models/{feature_type}/results.json\", \"w\") as f:\n",
    "        json.dump(results[feature_type], f, indent=2)\n",
    "\n",
    "print(\"\\nAll training complete. Models and results saved in 'models/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Creating Ensemble Predictions\n",
      "==================================================\n",
      "\n",
      "--- Ensemble Fold 1/5 ---\n",
      "Ensemble Accuracy: 0.8333\n",
      "\n",
      "--- Ensemble Fold 2/5 ---\n",
      "Ensemble Accuracy: 0.7222\n",
      "\n",
      "--- Ensemble Fold 3/5 ---\n",
      "Ensemble Accuracy: 0.7593\n",
      "\n",
      "--- Ensemble Fold 4/5 ---\n",
      "Ensemble Accuracy: 0.8704\n",
      "\n",
      "--- Ensemble Fold 5/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8704\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Ensemble Predictions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "processed_df['instrumentID'] = processed_df['instrumentID'] - 1\n",
    "\n",
    "ensemble_accuracies = []\n",
    "ensemble_reports = []\n",
    "ensemble_conf_matrices = []\n",
    "\n",
    "for fold in range(KFOLD_SPLITS):\n",
    "    print(f\"\\n--- Ensemble Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "    fold_preds = []\n",
    "    y_true = None\n",
    "\n",
    "    for feature_type in FEATURE_TYPES:\n",
    "        # Load model for this fold\n",
    "        model_path = f\"models/{feature_type}/model_fold{fold+1}.keras\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model not found: {model_path}\")\n",
    "            continue\n",
    "        model = keras.models.load_model(model_path)\n",
    "\n",
    "        # Get test data for this fold\n",
    "        feature_df = processed_df[[feature_type, 'instrumentID']].dropna().reset_index(drop=True)\n",
    "        kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "        train_idx, test_idx = list(kf.split(feature_df))[fold]\n",
    "        test_df = feature_df.iloc[test_idx].reset_index(drop=True)\n",
    "        test_gen = SingleFeatureDataGenerator(test_df, feature_type, batch_size=BATCH_SIZE, shuffle=False, num_classes=num_classes)\n",
    "        preds = model.predict(test_gen, verbose=0)\n",
    "        fold_preds.append(preds)\n",
    "        if y_true is None:\n",
    "            # Get true labels from generator\n",
    "            y_true = []\n",
    "            for _, labels in test_gen:\n",
    "                y_true.extend(np.argmax(labels, axis=1))\n",
    "            y_true = np.array(y_true)\n",
    "\n",
    "    if fold_preds:\n",
    "        ensemble_pred = np.mean(fold_preds, axis=0)\n",
    "        ensemble_pred_classes = np.argmax(ensemble_pred, axis=1)\n",
    "        acc = accuracy_score(y_true, ensemble_pred_classes)\n",
    "        ensemble_accuracies.append(acc)\n",
    "        print(f\"Ensemble Accuracy: {acc:.4f}\")\n",
    "        report = classification_report(y_true, ensemble_pred_classes, output_dict=True)\n",
    "        ensemble_reports.append(report)\n",
    "        conf_matrix = confusion_matrix(y_true, ensemble_pred_classes).tolist()\n",
    "        ensemble_conf_matrices.append(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble results saved to: ensemble_results/ensemble_results_2025_07_09.json\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"ensemble_results\", exist_ok=True)\n",
    "date_part = datetime.now().date().__str__().replace('-', '_')\n",
    "results_path = os.path.join(\"ensemble_results\", f\"ensemble_results_{date_part}.json\")\n",
    "ensemble_results = {\n",
    "    \"accuracy_list\": ensemble_accuracies,\n",
    "    \"classification_reports\": ensemble_reports,\n",
    "    \"confusion_matrices\": ensemble_conf_matrices,\n",
    "}\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(ensemble_results, f, indent=2)\n",
    "print(f\"\\nEnsemble results saved to: {results_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ensemble Keras model for fold 1 to ensemble_results/ensemble_model_fold1_2025_07_09.keras\n",
      "Saved ensemble Keras model for fold 2 to ensemble_results/ensemble_model_fold2_2025_07_09.keras\n",
      "Saved ensemble Keras model for fold 3 to ensemble_results/ensemble_model_fold3_2025_07_09.keras\n",
      "Saved ensemble Keras model for fold 4 to ensemble_results/ensemble_model_fold4_2025_07_09.keras\n",
      "Saved ensemble Keras model for fold 5 to ensemble_results/ensemble_model_fold5_2025_07_09.keras\n"
     ]
    }
   ],
   "source": [
    "for fold in range(KFOLD_SPLITS):\n",
    "    models_fold = []\n",
    "    inputs = []\n",
    "    input_names = []\n",
    "    for feature_type in FEATURE_TYPES:\n",
    "        model_path = f\"models/{feature_type}/model_fold{fold+1}.keras\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Model not found for ensemble: {model_path}\")\n",
    "            continue\n",
    "        model = keras.models.load_model(model_path)\n",
    "        models_fold.append(model)\n",
    "        inp = model.input\n",
    "        inputs.append(inp)\n",
    "        input_names.append(feature_type)\n",
    "    if not models_fold:\n",
    "        print(f\"No models found for fold {fold+1}, skipping ensemble model save.\")\n",
    "        continue\n",
    "    # If all input shapes are the same, use a single input\n",
    "    input_shapes = [tuple(inp.shape) for inp in inputs]\n",
    "    if all(s == input_shapes[0] for s in input_shapes):\n",
    "        ensemble_input = keras.Input(shape=input_shapes[0][1:], name=\"ensemble_input\")\n",
    "        model_outputs = [m(ensemble_input) for m in models_fold]\n",
    "        avg = Average()(model_outputs)\n",
    "        ensemble_model = Model(inputs=ensemble_input, outputs=avg, name=f\"ensemble_model_fold{fold+1}\")\n",
    "    else:\n",
    "        # Multi-input ensemble\n",
    "        ensemble_inputs = [keras.Input(shape=inp.shape[1:], name=f\"{name}_input\") for inp, name in zip(inputs, input_names)]\n",
    "        model_outputs = [m(inp) for m, inp in zip(models_fold, ensemble_inputs)]\n",
    "        avg = Average()(model_outputs)\n",
    "        ensemble_model = Model(inputs=ensemble_inputs, outputs=avg, name=f\"ensemble_model_fold{fold+1}\")\n",
    "    # Save the ensemble model\n",
    "    ensemble_model_path = os.path.join(\"ensemble_results\", f\"ensemble_model_fold{fold+1}_{date_part}.keras\")\n",
    "    ensemble_model.save(ensemble_model_path)\n",
    "    print(f\"Saved ensemble Keras model for fold {fold+1} to {ensemble_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Individual Model Performance:\n",
      "  mel_spectrogram: 0.6000 ± 0.1583\n",
      "  mfcc: 0.7370 ± 0.1999\n",
      "  chromagram: 0.2556 ± 0.0806\n",
      "  spectral_contrast: 0.3593 ± 0.1018\n",
      "  tonnetz: 0.1778 ± 0.0432\n",
      "  constant_q: 0.7111 ± 0.0912\n",
      "  cqt: 0.7037 ± 0.0759\n",
      "  stft: 0.2778 ± 0.0586\n",
      "  harmonic_percussive: 0.5000 ± 0.1665\n",
      "  onset_strength: 0.1704 ± 0.0590\n",
      "\n",
      "Ensemble Performance:\n",
      "  Ensemble: 0.8111 ± 0.0602\n",
      "\n",
      "Best Individual Model: mfcc (0.7370)\n",
      "Ensemble Improvement: 0.0741 (7.41%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nIndividual Model Performance:\")\n",
    "for feature_type in FEATURE_TYPES:\n",
    "    if feature_type in results:\n",
    "        accuracies = results[feature_type]['accuracy_list']\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        print(f\"  {feature_type}: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble Performance:\")\n",
    "ensemble_mean = np.mean(ensemble_accuracies)\n",
    "ensemble_std = np.std(ensemble_accuracies)\n",
    "print(f\"  Ensemble: {ensemble_mean:.4f} ± {ensemble_std:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "best_individual = max(\n",
    "    [(ft, np.mean(results[ft]['accuracy_list'])) for ft in FEATURE_TYPES if ft in results],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "improvement = ensemble_mean - best_individual[1]\n",
    "print(f\"\\nBest Individual Model: {best_individual[0]} ({best_individual[1]:.4f})\")\n",
    "print(f\"Ensemble Improvement: {improvement:.4f} ({improvement*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
