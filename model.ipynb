{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Training - Simplified Single-Branch Models\n",
    "\n",
    "This notebook trains separate simplified CNN models for each feature type and then creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 10:23:21.299207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from modules.PostgresDBHandler import PostgresDBHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 10:23:22.288928: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-07-07 10:23:22.289585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2025-07-07 10:23:22.368838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:23:22.370545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4080 SUPER computeCapability: 8.9\n",
      "coreClock: 2.61GHz coreCount: 80 deviceMemorySize: 15.59GiB deviceMemoryBandwidth: 685.51GiB/s\n",
      "2025-07-07 10:23:22.370554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-07-07 10:23:22.371580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-07-07 10:23:22.371603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-07-07 10:23:22.372652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-07-07 10:23:22.372814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-07-07 10:23:22.373857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-07-07 10:23:22.374387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-07-07 10:23:22.376563: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-07-07 10:23:22.376656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:23:22.377937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:23:22.379112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "dbParams = {\n",
    "    \"dbname\": \"mydatabase\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"host\": \"postgres_server\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "KFOLD_SPLITS = 5\n",
    "FIXED_LENGTH = 128\n",
    "\n",
    "# Feature types to train models for\n",
    "FEATURE_TYPES = [\n",
    "    'mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast',\n",
    "    'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength'\n",
    "]\n",
    "\n",
    "# Feature shapes for each type\n",
    "FEATURE_SHAPES = {\n",
    "    'mel_spectrogram': (64, 128),\n",
    "    'mfcc': (8, 128),\n",
    "    'chromagram': (8, 128),\n",
    "    'spectral_contrast': (3, 128),\n",
    "    'tonnetz': (6, 128),\n",
    "    'constant_q': (42, 128),\n",
    "    'cqt': (42, 128),\n",
    "    'stft': (512, 128),\n",
    "    'harmonic_percussive': (1025, 128),\n",
    "    'onset_strength': (1, 128)\n",
    "}\n",
    "# GPU configuration\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Number of available GPUs: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instrument classes: 9\n",
      "Instruments: ['oboe', 'sax', 'cello', 'bass', 'clarinet', 'piccolo', 'violin', 'flute', 'trumpet']\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get instrument mappings\n",
    "instruments_mappings = db.get_mappings_instruments()\n",
    "num_classes = len(instruments_mappings)\n",
    "print(f\"Number of instrument classes: {num_classes}\")\n",
    "print(\"Instruments:\", instruments_mappings['name'].tolist())\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleFeatureDataGenerator(Sequence):\n",
    "    def __init__(self, df, feature_type, label_encoder, batch_size=32, shuffle=True):\n",
    "        self.df = df.copy()  # Just to be safe\n",
    "        self.feature_type = feature_type\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # Transform labels using the external encoder (DON'T fit again!)\n",
    "        self.df['instrumentID_encoded'] = self.label_encoder.transform(self.df['instrumentID'])\n",
    "        self.num_classes = len(self.label_encoder.classes_)\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[indices]\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            feature_data = np.load(row['featurePath'])\n",
    "            X.append(feature_data)\n",
    "            y.append(row['instrumentID_encoded'])\n",
    "        \n",
    "        X = np.expand_dims(np.array(X), -1)\n",
    "        y = to_categorical(y, num_classes=self.num_classes)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.df.iloc[self.indices]['instrumentID_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(input_shape, num_classes, model_name=\"simple_cnn\"):    \n",
    "    \"\"\"Create a simplified single-branch CNN model with reduced capacity.\"\"\"\n",
    "    input_layer = Input(shape=(*input_shape, 1), name=f\"{model_name}_input\")\n",
    "    \n",
    "    # Reduced number of filters and layers compared to original\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Reduced dense layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Smaller final dense layer\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax', name=f\"{model_name}_output\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output, name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed samples: 9000\n",
      "mel_spectrogram: 900 samples\n",
      "mfcc: 900 samples\n",
      "chromagram: 900 samples\n",
      "spectral_contrast: 900 samples\n",
      "tonnetz: 900 samples\n",
      "constant_q: 900 samples\n",
      "cqt: 900 samples\n",
      "stft: 900 samples\n",
      "harmonic_percussive: 900 samples\n",
      "onset_strength: 900 samples\n",
      "\n",
      "Available feature types: ['mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast', 'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength']\n"
     ]
    }
   ],
   "source": [
    "# Load data for each feature type\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get all processed IDs\n",
    "processed_ids = db.get_all_processed_ids()\n",
    "print(f\"Total processed samples: {len(processed_ids)}\")\n",
    "\n",
    "# Create DataFrames for each feature type\n",
    "df_dict = {}\n",
    "for feature_type in FEATURE_TYPES:\n",
    "    processed_data = db.get_processed_fit_data(processed_ids, feature_type)\n",
    "    \n",
    "    if processed_data:\n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df_dict[feature_type] = df\n",
    "        print(f\"{feature_type}: {len(df)} samples\")\n",
    "    else:\n",
    "        print(f\"Warning: No data found for {feature_type}\")\n",
    "\n",
    "db.close()\n",
    "\n",
    "# Filter to only include feature types with data\n",
    "available_feature_types = list(df_dict.keys())\n",
    "print(f\"\\nAvailable feature types: {available_feature_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53f734a27934d3fb15e26c501e3fb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Feature Types:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training model for mel_spectrogram\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edacc5b832e4afaa01f29364766ff69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mel_spectrogram Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
      "X min/max: -80.0 1.9073486e-06\n",
      "y (class distribution in batch): [3. 5. 3. 3. 4. 3. 5. 2. 4.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First label (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "First label (class index): 3\n",
      "Label distribution in train_df: instrumentID\n",
      "4    71\n",
      "2    71\n",
      "6    68\n",
      "5    67\n",
      "9    66\n",
      "1    65\n",
      "3    60\n",
      "7    56\n",
      "8    52\n",
      "Name: count, dtype: int64\n",
      "Any NaNs in X? False\n",
      "All X values the same? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 10:24:10.279652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-07 10:24:10.280188: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2025-07-07 10:24:10.280355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:24:10.282771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4080 SUPER computeCapability: 8.9\n",
      "coreClock: 2.61GHz coreCount: 80 deviceMemorySize: 15.59GiB deviceMemoryBandwidth: 685.51GiB/s\n",
      "2025-07-07 10:24:10.282784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-07-07 10:24:10.282803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-07-07 10:24:10.282810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2025-07-07 10:24:10.282817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2025-07-07 10:24:10.282823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2025-07-07 10:24:10.282829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2025-07-07 10:24:10.282836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2025-07-07 10:24:10.282843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2025-07-07 10:24:10.282890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:24:10.284198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:24:10.285824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2025-07-07 10:24:10.286038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2025-07-07 10:27:47.091515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2025-07-07 10:27:47.091529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2025-07-07 10:27:47.091533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2025-07-07 10:27:47.092006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:27:47.093012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:27:47.094191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-07 10:27:47.095154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14010 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9)\n",
      "2025-07-07 10:27:47.153471: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2025-07-07 10:27:47.154285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4199990000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 10:27:47.439875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2025-07-07 10:28:41.537289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "# Training results storage\n",
    "all_results = {}\n",
    "all_models = {}\n",
    "\n",
    "# Fit on the full dataset\n",
    "global_label_encoder = LabelEncoder()\n",
    "global_label_encoder.fit(df['instrumentID'])  # Use original labels\n",
    "\n",
    "\n",
    "# Train individual models for each feature type\n",
    "for feature_type in tqdm(available_feature_types, desc = \"Feature Types\"):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training model for {feature_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = df_dict[feature_type]\n",
    "    input_shape = FEATURE_SHAPES[feature_type]\n",
    "    \n",
    "    # Initialize results storage for this feature type\n",
    "    feature_results = {\n",
    "        'accuracy_list': [],\n",
    "        'loss_list': [],\n",
    "        'classification_reports': [],\n",
    "        'confusion_matrices': [],\n",
    "        'histories': [],\n",
    "        'models': []\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(list(kf.split(df)), desc = f\"{feature_type} Folds\")):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Further split training data\n",
    "        train_indices, val_indices = train_test_split(\n",
    "            np.arange(len(train_df)), test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        val_df = train_df.iloc[val_indices].reset_index(drop=True)\n",
    "        train_df = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        # Create data generators\n",
    "        train_generator = SingleFeatureDataGenerator(train_df, feature_type, label_encoder=global_label_encoder)\n",
    "        val_generator = SingleFeatureDataGenerator(val_df, feature_type, label_encoder=global_label_encoder)\n",
    "        test_generator = SingleFeatureDataGenerator(test_df, feature_type, label_encoder=global_label_encoder)\n",
    "        \n",
    "        \n",
    "        # --- DEBUG: Inspect a batch from the generator ---\n",
    "        X, y = train_generator[0]\n",
    "        print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "        print(\"X min/max:\", np.min(X), np.max(X))\n",
    "        print(\"y (class distribution in batch):\", np.sum(y, axis=0))\n",
    "        plt.imshow(X[0, :, :, 0], aspect='auto')\n",
    "        plt.title(\"First feature image in batch\")\n",
    "        plt.show()\n",
    "        print(\"First label (one-hot):\", y[0])\n",
    "        print(\"First label (class index):\", np.argmax(y[0]))\n",
    "        # --- END DEBUG ---\n",
    "\n",
    "\n",
    "        # --- DEBUG: Check label distribution in training set ---\n",
    "        print(\"Label distribution in train_df:\", train_df['instrumentID'].value_counts())\n",
    "        print(\"Any NaNs in X?\", np.isnan(X).any())\n",
    "        print(\"All X values the same?\", np.all(X == X.flat[0]))\n",
    "        # --- END DEBUG ---\n",
    "        \n",
    "        # Create and compile model\n",
    "        model = create_simple_model(input_shape, num_classes, f\"{feature_type}_model\")\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=40, restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        feature_results['histories'].append(history.history)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(test_generator, verbose=0)\n",
    "        feature_results['accuracy_list'].append(accuracy)\n",
    "        feature_results['loss_list'].append(loss)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        # Predict and generate reports\n",
    "        y_pred = model.predict(test_generator, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = test_generator.get_labels()\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "        feature_results['classification_reports'].append(report)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_classes).tolist()\n",
    "        feature_results['confusion_matrices'].append(conf_matrix)\n",
    "        \n",
    "        # Save the best model (last one for now)\n",
    "        feature_results['models'].append(model)\n",
    "    \n",
    "    # Store results for this feature type\n",
    "    all_results[feature_type] = feature_results\n",
    "    all_models[feature_type] = feature_results['models'][-1]  # Save the last model\n",
    "    \n",
    "    # Print summary for this feature type\n",
    "    mean_acc = np.mean(feature_results['accuracy_list'])\n",
    "    std_acc = np.std(feature_results['accuracy_list'])\n",
    "    print(f\"\\n{feature_type} - Mean Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Types:  60%\n",
    " 6/10 [16:15<05:12, 78.15s/it]\n",
    "\n",
    "\n",
    "==================================================\n",
    "Training model for mel_spectrogram\n",
    "==================================================\n",
    "\n",
    "mel_spectrogram Folds: 100%\n",
    " 5/5 [13:23<00:00, 73.60s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [3. 5. 3. 3. 4. 3. 5. 2. 4.]\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 3\n",
    "Label distribution in train_df: instrumentID\n",
    "4    71\n",
    "2    71\n",
    "6    68\n",
    "5    67\n",
    "9    66\n",
    "1    65\n",
    "3    60\n",
    "7    56\n",
    "8    52\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "\n",
    "2025-07-07 10:24:10.279652: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
    "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
    "2025-07-07 10:24:10.280188: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
    "2025-07-07 10:24:10.280355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:24:10.282771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
    "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 4080 SUPER computeCapability: 8.9\n",
    "coreClock: 2.61GHz coreCount: 80 deviceMemorySize: 15.59GiB deviceMemoryBandwidth: 685.51GiB/s\n",
    "2025-07-07 10:24:10.282784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
    "2025-07-07 10:24:10.282803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
    "2025-07-07 10:24:10.282810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
    "2025-07-07 10:24:10.282817: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
    "2025-07-07 10:24:10.282823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
    "2025-07-07 10:24:10.282829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
    "2025-07-07 10:24:10.282836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
    "2025-07-07 10:24:10.282843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
    "2025-07-07 10:24:10.282890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:24:10.284198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:24:10.285824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
    "2025-07-07 10:24:10.286038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
    "2025-07-07 10:27:47.091515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2025-07-07 10:27:47.091529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
    "2025-07-07 10:27:47.091533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
    "2025-07-07 10:27:47.092006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:27:47.093012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:27:47.094191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
    "2025-07-07 10:27:47.095154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14010 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9)\n",
    "2025-07-07 10:27:47.153471: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
    "2025-07-07 10:27:47.154285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4199990000 Hz\n",
    "\n",
    "Epoch 1/200\n",
    "\n",
    "2025-07-07 10:27:47.439875: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
    "2025-07-07 10:28:41.537289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
    "\n",
    "18/18 [==============================] - 552s 13ms/step - loss: 2.2435 - accuracy: 0.1077 - val_loss: 2.2014 - val_accuracy: 0.1181\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1004 - val_loss: 2.2029 - val_accuracy: 0.1181\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1177 - val_loss: 2.2066 - val_accuracy: 0.0556\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1168 - val_loss: 2.2099 - val_accuracy: 0.0556\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.1052 - val_loss: 2.2133 - val_accuracy: 0.0556\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1403 - val_loss: 2.2142 - val_accuracy: 0.0556\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1225 - val_loss: 2.2147 - val_accuracy: 0.0556\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1920 - accuracy: 0.1347 - val_loss: 2.2152 - val_accuracy: 0.0556\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1459 - val_loss: 2.2171 - val_accuracy: 0.0556\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1992 - accuracy: 0.1039 - val_loss: 2.2166 - val_accuracy: 0.0556\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1474 - val_loss: 2.2179 - val_accuracy: 0.0556\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1912 - accuracy: 0.1259 - val_loss: 2.2185 - val_accuracy: 0.0556\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1227 - val_loss: 2.2181 - val_accuracy: 0.0556\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1899 - accuracy: 0.1328 - val_loss: 2.2195 - val_accuracy: 0.0556\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1020 - val_loss: 2.2192 - val_accuracy: 0.0556\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1262 - val_loss: 2.2187 - val_accuracy: 0.0556\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1055 - val_loss: 2.2187 - val_accuracy: 0.0556\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1090 - val_loss: 2.2211 - val_accuracy: 0.0556\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.1220 - val_loss: 2.2228 - val_accuracy: 0.0556\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1331 - val_loss: 2.2230 - val_accuracy: 0.0556\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1988 - accuracy: 0.1121 - val_loss: 2.2215 - val_accuracy: 0.0556\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1289 - val_loss: 2.2214 - val_accuracy: 0.0556\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1244 - val_loss: 2.2213 - val_accuracy: 0.0556\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.0989 - val_loss: 2.2219 - val_accuracy: 0.0556\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1926 - accuracy: 0.1161 - val_loss: 2.2217 - val_accuracy: 0.0556\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1897 - accuracy: 0.1074 - val_loss: 2.2216 - val_accuracy: 0.0556\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1904 - accuracy: 0.0952 - val_loss: 2.2206 - val_accuracy: 0.0556\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1140 - val_loss: 2.2179 - val_accuracy: 0.0556\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1930 - accuracy: 0.1044 - val_loss: 2.2185 - val_accuracy: 0.0694\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1892 - accuracy: 0.1397 - val_loss: 2.2207 - val_accuracy: 0.0694\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1157 - val_loss: 2.2216 - val_accuracy: 0.0694\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1911 - accuracy: 0.1108 - val_loss: 2.2231 - val_accuracy: 0.0694\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1980 - accuracy: 0.1097 - val_loss: 2.2211 - val_accuracy: 0.0694\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1912 - accuracy: 0.0976 - val_loss: 2.2228 - val_accuracy: 0.0556\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1938 - accuracy: 0.1276 - val_loss: 2.2238 - val_accuracy: 0.0556\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1978 - accuracy: 0.1037 - val_loss: 2.2231 - val_accuracy: 0.0694\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1815 - accuracy: 0.1396 - val_loss: 2.2283 - val_accuracy: 0.0556\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1161 - val_loss: 2.2278 - val_accuracy: 0.0694\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1899 - accuracy: 0.1081 - val_loss: 2.2279 - val_accuracy: 0.0694\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1132 - val_loss: 2.2256 - val_accuracy: 0.0556\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1921 - accuracy: 0.0954 - val_loss: 2.2255 - val_accuracy: 0.0556\n",
    "Accuracy: 0.0944, Loss: 2.1991\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [2. 4. 5. 3. 2. 4. 4. 3. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    "First label (class index): 6\n",
    "Label distribution in train_df: instrumentID\n",
    "6    69\n",
    "3    69\n",
    "1    69\n",
    "7    66\n",
    "4    65\n",
    "2    62\n",
    "9    62\n",
    "8    60\n",
    "5    54\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.1032 - val_loss: 2.1973 - val_accuracy: 0.1042\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1219 - val_loss: 2.1973 - val_accuracy: 0.1042\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1277 - val_loss: 2.1973 - val_accuracy: 0.1042\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1116 - val_loss: 2.1973 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1208 - val_loss: 2.1973 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.0907 - val_loss: 2.1973 - val_accuracy: 0.1042\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.0954 - val_loss: 2.1975 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1207 - val_loss: 2.1975 - val_accuracy: 0.1042\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1460 - val_loss: 2.1974 - val_accuracy: 0.1042\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1349 - val_loss: 2.1975 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1274 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1145 - val_loss: 2.1976 - val_accuracy: 0.1042\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1113 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1149 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1174 - val_loss: 2.1978 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1181 - val_loss: 2.1979 - val_accuracy: 0.1042\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1276 - val_loss: 2.1980 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1132 - val_loss: 2.1980 - val_accuracy: 0.1042\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1368 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1203 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1935 - accuracy: 0.1335 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1163 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1198 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1039 - val_loss: 2.1982 - val_accuracy: 0.1042\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1283 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1215 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1216 - val_loss: 2.1983 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1370 - val_loss: 2.1985 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1908 - accuracy: 0.1419 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1194 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1115 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1028 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1913 - accuracy: 0.1162 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.1362 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1149 - val_loss: 2.1988 - val_accuracy: 0.1250\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1019 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1976 - accuracy: 0.1126 - val_loss: 2.1989 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1284 - val_loss: 2.1989 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1942 - accuracy: 0.1188 - val_loss: 2.1989 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1033 - val_loss: 2.1990 - val_accuracy: 0.1042\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1141 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0889, Loss: 2.1979\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 3.8146973e-06\n",
    "y (class distribution in batch): [2. 5. 2. 8. 4. 2. 4. 2. 3.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "First label (class index): 8\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "2    67\n",
    "9    66\n",
    "8    65\n",
    "5    65\n",
    "1    64\n",
    "6    63\n",
    "3    58\n",
    "7    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0995 - val_loss: 2.1973 - val_accuracy: 0.1111\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1066 - val_loss: 2.1975 - val_accuracy: 0.1250\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.0798 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1280 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1367 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1232 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1039 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1121 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1344 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1318 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1348 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1193 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1052 - val_loss: 2.1992 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1446 - val_loss: 2.1995 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1950 - accuracy: 0.1299 - val_loss: 2.1995 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1390 - val_loss: 2.1998 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1950 - accuracy: 0.1231 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1299 - val_loss: 2.2000 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1414 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1937 - accuracy: 0.1305 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1113 - val_loss: 2.2004 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1328 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1400 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1984 - accuracy: 0.1084 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1585 - val_loss: 2.2008 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1216 - val_loss: 2.2010 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1303 - val_loss: 2.2011 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1351 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1376 - val_loss: 2.2013 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1214 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1383 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1328 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1912 - accuracy: 0.1441 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1974 - accuracy: 0.1051 - val_loss: 2.2019 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1934 - accuracy: 0.1412 - val_loss: 2.2019 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.1384 - val_loss: 2.2019 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1122 - val_loss: 2.2021 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1211 - val_loss: 2.2021 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1160 - val_loss: 2.2022 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1928 - accuracy: 0.1468 - val_loss: 2.2024 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1975 - accuracy: 0.1170 - val_loss: 2.2023 - val_accuracy: 0.0972\n",
    "Accuracy: 0.1056, Loss: 2.1977\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [4. 4. 3. 4. 4. 5. 6. 1. 1.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    "First label (class index): 6\n",
    "Label distribution in train_df: instrumentID\n",
    "2    69\n",
    "7    68\n",
    "1    66\n",
    "3    66\n",
    "8    65\n",
    "5    62\n",
    "4    61\n",
    "6    61\n",
    "9    58\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 15ms/step - loss: 2.3375 - accuracy: 0.1283 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1078 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1317 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1220 - val_loss: 2.1985 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1037 - val_loss: 2.1985 - val_accuracy: 0.1528\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1193 - val_loss: 2.1984 - val_accuracy: 0.1528\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1974 - accuracy: 0.1202 - val_loss: 2.1985 - val_accuracy: 0.1528\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1096 - val_loss: 2.1982 - val_accuracy: 0.0694\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1077 - val_loss: 2.1982 - val_accuracy: 0.1528\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1357 - val_loss: 2.1983 - val_accuracy: 0.1528\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1359 - val_loss: 2.1983 - val_accuracy: 0.0694\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1976 - accuracy: 0.0935 - val_loss: 2.1983 - val_accuracy: 0.1528\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1977 - accuracy: 0.1239 - val_loss: 2.1981 - val_accuracy: 0.0694\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1258 - val_loss: 2.1987 - val_accuracy: 0.1528\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1063 - val_loss: 2.1991 - val_accuracy: 0.1528\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1025 - val_loss: 2.1994 - val_accuracy: 0.1528\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1103 - val_loss: 2.1993 - val_accuracy: 0.1528\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1430 - val_loss: 2.1992 - val_accuracy: 0.1528\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.0871 - val_loss: 2.1990 - val_accuracy: 0.1528\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1182 - val_loss: 2.1993 - val_accuracy: 0.0694\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1350 - val_loss: 2.1993 - val_accuracy: 0.1528\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1274 - val_loss: 2.1993 - val_accuracy: 0.0694\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1194 - val_loss: 2.1992 - val_accuracy: 0.1528\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1994 - accuracy: 0.1185 - val_loss: 2.1990 - val_accuracy: 0.1528\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1126 - val_loss: 2.1994 - val_accuracy: 0.1528\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1572 - val_loss: 2.1993 - val_accuracy: 0.0694\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1696 - val_loss: 2.1992 - val_accuracy: 0.0694\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1374 - val_loss: 2.1996 - val_accuracy: 0.1528\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.0887 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1262 - val_loss: 2.2000 - val_accuracy: 0.1528\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1209 - val_loss: 2.2002 - val_accuracy: 0.1528\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1038 - val_loss: 2.1998 - val_accuracy: 0.0694\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1112 - val_loss: 2.1999 - val_accuracy: 0.1528\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.1141 - val_loss: 2.2000 - val_accuracy: 0.1528\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1039 - val_loss: 2.1996 - val_accuracy: 0.0694\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1148 - val_loss: 2.1998 - val_accuracy: 0.0694\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.1359 - val_loss: 2.1996 - val_accuracy: 0.0694\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1152 - val_loss: 2.1995 - val_accuracy: 0.0694\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1303 - val_loss: 2.1999 - val_accuracy: 0.0694\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1234 - val_loss: 2.1999 - val_accuracy: 0.0694\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1084 - val_loss: 2.2000 - val_accuracy: 0.0694\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2022 - accuracy: 0.0937 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Epoch 43/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1067 - val_loss: 2.1999 - val_accuracy: 0.0694\n",
    "Epoch 44/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1149 - val_loss: 2.1996 - val_accuracy: 0.0694\n",
    "Epoch 45/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1092 - val_loss: 2.1994 - val_accuracy: 0.0694\n",
    "Epoch 46/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1206 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Epoch 47/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1096 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Epoch 48/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1100 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Epoch 49/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1263 - val_loss: 2.2002 - val_accuracy: 0.0694\n",
    "Epoch 50/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1231 - val_loss: 2.2004 - val_accuracy: 0.0694\n",
    "Epoch 51/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1142 - val_loss: 2.1999 - val_accuracy: 0.0694\n",
    "Epoch 52/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1263 - val_loss: 2.2017 - val_accuracy: 0.0694\n",
    "Epoch 53/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1287 - val_loss: 2.1997 - val_accuracy: 0.0694\n",
    "Accuracy: 0.1167, Loss: 2.2002\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 64, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [3. 4. 5. 3. 3. 6. 2. 3. 3.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "First label (class index): 7\n",
    "Label distribution in train_df: instrumentID\n",
    "6    71\n",
    "4    71\n",
    "2    68\n",
    "3    68\n",
    "5    64\n",
    "9    63\n",
    "1    58\n",
    "8    57\n",
    "7    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0953 - val_loss: 2.1976 - val_accuracy: 0.1181\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1041 - val_loss: 2.1981 - val_accuracy: 0.1181\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1335 - val_loss: 2.1986 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1391 - val_loss: 2.1990 - val_accuracy: 0.0903\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1387 - val_loss: 2.1995 - val_accuracy: 0.0903\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1316 - val_loss: 2.2000 - val_accuracy: 0.0903\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1398 - val_loss: 2.2004 - val_accuracy: 0.0903\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1210 - val_loss: 2.2008 - val_accuracy: 0.0833\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.1143 - val_loss: 2.2011 - val_accuracy: 0.0833\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1384 - val_loss: 2.2015 - val_accuracy: 0.0833\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1269 - val_loss: 2.2020 - val_accuracy: 0.0903\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1063 - val_loss: 2.2023 - val_accuracy: 0.0833\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1009 - val_loss: 2.2026 - val_accuracy: 0.0903\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1080 - val_loss: 2.2031 - val_accuracy: 0.0833\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1942 - accuracy: 0.1311 - val_loss: 2.2033 - val_accuracy: 0.0833\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1922 - accuracy: 0.1415 - val_loss: 2.2038 - val_accuracy: 0.0833\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1057 - val_loss: 2.2039 - val_accuracy: 0.0903\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1171 - val_loss: 2.2042 - val_accuracy: 0.0833\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.0988 - val_loss: 2.2045 - val_accuracy: 0.0903\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1236 - val_loss: 2.2049 - val_accuracy: 0.0833\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1937 - accuracy: 0.1316 - val_loss: 2.2052 - val_accuracy: 0.0903\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1930 - accuracy: 0.1388 - val_loss: 2.2055 - val_accuracy: 0.0903\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1895 - accuracy: 0.1348 - val_loss: 2.2060 - val_accuracy: 0.0833\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1227 - val_loss: 2.2060 - val_accuracy: 0.0833\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1899 - accuracy: 0.1478 - val_loss: 2.2064 - val_accuracy: 0.0833\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1931 - accuracy: 0.1332 - val_loss: 2.2066 - val_accuracy: 0.0903\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1935 - accuracy: 0.1307 - val_loss: 2.2068 - val_accuracy: 0.0903\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1174 - val_loss: 2.2070 - val_accuracy: 0.0903\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1130 - val_loss: 2.2071 - val_accuracy: 0.0903\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1894 - accuracy: 0.1374 - val_loss: 2.2074 - val_accuracy: 0.0903\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1914 - accuracy: 0.1103 - val_loss: 2.2077 - val_accuracy: 0.0833\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1120 - val_loss: 2.2079 - val_accuracy: 0.0903\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1322 - val_loss: 2.2079 - val_accuracy: 0.0903\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1921 - accuracy: 0.0912 - val_loss: 2.2082 - val_accuracy: 0.0903\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1209 - val_loss: 2.2083 - val_accuracy: 0.0833\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1089 - val_loss: 2.2084 - val_accuracy: 0.0903\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1321 - val_loss: 2.2087 - val_accuracy: 0.0903\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1985 - accuracy: 0.1089 - val_loss: 2.2087 - val_accuracy: 0.0903\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1073 - val_loss: 2.2090 - val_accuracy: 0.0903\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.0950 - val_loss: 2.2090 - val_accuracy: 0.0903\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1100 - val_loss: 2.2092 - val_accuracy: 0.0833\n",
    "Accuracy: 0.0833, Loss: 2.1979\n",
    "\n",
    "mel_spectrogram - Mean Accuracy: 0.0978 ± 0.0120\n",
    "\n",
    "==================================================\n",
    "Training model for mfcc\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "mfcc Folds: 100%\n",
    " 5/5 [00:31<00:00,  6.26s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: -609.31323 200.29572\n",
    "y (class distribution in batch): [4. 5. 4. 1. 9. 1. 2. 3. 3.]\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "First label (class index): 7\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "9    69\n",
    "6    68\n",
    "2    68\n",
    "1    65\n",
    "5    65\n",
    "3    59\n",
    "7    56\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.3862 - accuracy: 0.0965 - val_loss: 6.5070 - val_accuracy: 0.1111\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4938 - accuracy: 0.1089 - val_loss: 2.3230 - val_accuracy: 0.0625\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.5310 - accuracy: 0.0963 - val_loss: 2.6722 - val_accuracy: 0.0486\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3430 - accuracy: 0.0916 - val_loss: 2.2344 - val_accuracy: 0.0486\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3172 - accuracy: 0.1156 - val_loss: 2.3255 - val_accuracy: 0.0694\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3078 - accuracy: 0.1052 - val_loss: 2.1851 - val_accuracy: 0.1389\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3521 - accuracy: 0.0940 - val_loss: 2.2444 - val_accuracy: 0.1181\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3382 - accuracy: 0.1032 - val_loss: 2.2516 - val_accuracy: 0.0833\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3026 - accuracy: 0.1273 - val_loss: 2.2207 - val_accuracy: 0.1250\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2967 - accuracy: 0.1200 - val_loss: 2.2014 - val_accuracy: 0.1181\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3369 - accuracy: 0.0943 - val_loss: 2.2052 - val_accuracy: 0.1319\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3326 - accuracy: 0.0771 - val_loss: 2.1955 - val_accuracy: 0.1111\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2798 - accuracy: 0.1426 - val_loss: 2.2020 - val_accuracy: 0.0694\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2923 - accuracy: 0.1091 - val_loss: 2.2654 - val_accuracy: 0.1181\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2703 - accuracy: 0.1434 - val_loss: 2.2134 - val_accuracy: 0.1528\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2678 - accuracy: 0.1148 - val_loss: 2.2171 - val_accuracy: 0.1250\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2528 - accuracy: 0.1388 - val_loss: 593.2265 - val_accuracy: 0.1042\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2634 - accuracy: 0.1110 - val_loss: 2.2043 - val_accuracy: 0.1250\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2702 - accuracy: 0.1105 - val_loss: 2.2048 - val_accuracy: 0.1250\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2781 - accuracy: 0.1090 - val_loss: 2.2051 - val_accuracy: 0.1250\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2110 - accuracy: 0.1481 - val_loss: 2.2054 - val_accuracy: 0.1250\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2632 - accuracy: 0.1028 - val_loss: 2.2053 - val_accuracy: 0.1250\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2929 - accuracy: 0.1003 - val_loss: 2.2053 - val_accuracy: 0.1250\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2479 - accuracy: 0.1291 - val_loss: 2.2056 - val_accuracy: 0.1250\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2189 - accuracy: 0.1297 - val_loss: 2.2056 - val_accuracy: 0.1250\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2847 - accuracy: 0.1209 - val_loss: 2.2059 - val_accuracy: 0.1250\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2629 - accuracy: 0.1519 - val_loss: 2.2056 - val_accuracy: 0.1250\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2140 - accuracy: 0.1579 - val_loss: 2.2060 - val_accuracy: 0.1250\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2249 - accuracy: 0.1041 - val_loss: 2.2060 - val_accuracy: 0.1250\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2186 - accuracy: 0.1464 - val_loss: 2.2061 - val_accuracy: 0.1250\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2123 - accuracy: 0.1360 - val_loss: 2.2063 - val_accuracy: 0.1250\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2555 - accuracy: 0.1168 - val_loss: 2.2061 - val_accuracy: 0.1250\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2263 - accuracy: 0.0957 - val_loss: 2.2064 - val_accuracy: 0.1250\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2048 - accuracy: 0.1291 - val_loss: 2.2066 - val_accuracy: 0.1250\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2094 - accuracy: 0.1306 - val_loss: 2.2067 - val_accuracy: 0.1250\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2154 - accuracy: 0.1055 - val_loss: 2.2070 - val_accuracy: 0.1250\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2382 - accuracy: 0.0919 - val_loss: 2.2073 - val_accuracy: 0.1250\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2271 - accuracy: 0.1088 - val_loss: 2.2075 - val_accuracy: 0.1250\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2077 - accuracy: 0.1175 - val_loss: 2.2081 - val_accuracy: 0.1250\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2120 - accuracy: 0.1301 - val_loss: 2.2079 - val_accuracy: 0.1250\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2241 - accuracy: 0.1029 - val_loss: 2.2082 - val_accuracy: 0.1181\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2285 - accuracy: 0.0821 - val_loss: 2.2090 - val_accuracy: 0.1250\n",
    "Epoch 43/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2418 - accuracy: 0.1092 - val_loss: 2.2095 - val_accuracy: 0.1250\n",
    "Epoch 44/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1404 - val_loss: 2.2098 - val_accuracy: 0.1250\n",
    "Epoch 45/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2041 - accuracy: 0.0949 - val_loss: 2.2100 - val_accuracy: 0.0486\n",
    "Epoch 46/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2136 - accuracy: 0.1055 - val_loss: 2.2103 - val_accuracy: 0.0486\n",
    "Accuracy: 0.0833, Loss: 4.0803\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: -596.6504 187.85594\n",
    "y (class distribution in batch): [6. 4. 1. 3. 3. 5. 4. 4. 2.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 1\n",
    "Label distribution in train_df: instrumentID\n",
    "6    69\n",
    "1    69\n",
    "4    67\n",
    "3    67\n",
    "7    65\n",
    "9    65\n",
    "2    62\n",
    "8    62\n",
    "5    50\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.1973 - accuracy: 0.0951 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1238 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1044 - val_loss: 2.1978 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1080 - val_loss: 2.1978 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1258 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1163 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1197 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1227 - val_loss: 2.1983 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1121 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1449 - val_loss: 2.1985 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1093 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1127 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1102 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1142 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1042 - val_loss: 2.1992 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1119 - val_loss: 2.1992 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1095 - val_loss: 2.1996 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1368 - val_loss: 2.1995 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1930 - accuracy: 0.1296 - val_loss: 2.1998 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1242 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1062 - val_loss: 2.1998 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1919 - accuracy: 0.1391 - val_loss: 2.2001 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1151 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1155 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1255 - val_loss: 2.2004 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1919 - accuracy: 0.1120 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1088 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.0995 - val_loss: 2.2007 - val_accuracy: 0.1250\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1348 - val_loss: 2.2008 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1185 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1440 - val_loss: 2.2010 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1245 - val_loss: 2.2011 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1924 - accuracy: 0.1211 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1911 - accuracy: 0.1262 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1288 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1924 - accuracy: 0.1211 - val_loss: 2.2014 - val_accuracy: 0.1250\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1223 - val_loss: 2.2017 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1100 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1322 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1185 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1924 - accuracy: 0.1339 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0944, Loss: 2.1977\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: -558.8268 189.6047\n",
    "y (class distribution in batch): [5. 5. 4. 4. 5. 1. 4. 2. 2.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 3\n",
    "Label distribution in train_df: instrumentID\n",
    "4    74\n",
    "9    66\n",
    "2    66\n",
    "5    65\n",
    "8    64\n",
    "1    64\n",
    "6    63\n",
    "7    58\n",
    "3    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.1973 - accuracy: 0.1035 - val_loss: 2.1976 - val_accuracy: 0.0903\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1107 - val_loss: 2.1979 - val_accuracy: 0.0903\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1418 - val_loss: 2.1983 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1227 - val_loss: 2.1986 - val_accuracy: 0.0903\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1472 - val_loss: 2.1989 - val_accuracy: 0.0903\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1240 - val_loss: 2.1992 - val_accuracy: 0.0903\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1255 - val_loss: 2.1992 - val_accuracy: 0.0903\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1084 - val_loss: 2.1996 - val_accuracy: 0.0903\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1110 - val_loss: 2.1998 - val_accuracy: 0.0903\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1165 - val_loss: 2.2001 - val_accuracy: 0.0903\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1044 - val_loss: 2.2003 - val_accuracy: 0.0903\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1274 - val_loss: 2.2005 - val_accuracy: 0.0903\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1298 - val_loss: 2.2009 - val_accuracy: 0.0903\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1192 - val_loss: 2.2011 - val_accuracy: 0.0903\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1494 - val_loss: 2.2013 - val_accuracy: 0.0903\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1409 - val_loss: 2.2015 - val_accuracy: 0.0903\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1250 - val_loss: 2.2017 - val_accuracy: 0.0903\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1977 - accuracy: 0.1145 - val_loss: 2.2019 - val_accuracy: 0.0903\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1978 - accuracy: 0.1208 - val_loss: 2.2021 - val_accuracy: 0.0903\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1159 - val_loss: 2.2024 - val_accuracy: 0.0903\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1197 - val_loss: 2.2025 - val_accuracy: 0.0903\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1241 - val_loss: 2.2026 - val_accuracy: 0.0903\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1207 - val_loss: 2.2029 - val_accuracy: 0.0903\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1330 - val_loss: 2.2031 - val_accuracy: 0.0903\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1318 - val_loss: 2.2032 - val_accuracy: 0.0903\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1385 - val_loss: 2.2033 - val_accuracy: 0.0903\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1218 - val_loss: 2.2035 - val_accuracy: 0.0903\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1124 - val_loss: 2.2037 - val_accuracy: 0.0903\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1335 - val_loss: 2.2038 - val_accuracy: 0.0903\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1109 - val_loss: 2.2040 - val_accuracy: 0.0903\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1939 - accuracy: 0.1152 - val_loss: 2.2042 - val_accuracy: 0.0903\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1068 - val_loss: 2.2043 - val_accuracy: 0.0903\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1176 - val_loss: 2.2044 - val_accuracy: 0.0903\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1975 - accuracy: 0.1151 - val_loss: 2.2044 - val_accuracy: 0.0903\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1978 - accuracy: 0.1159 - val_loss: 2.2045 - val_accuracy: 0.0903\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1213 - val_loss: 2.2046 - val_accuracy: 0.0903\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1905 - accuracy: 0.1460 - val_loss: 2.2050 - val_accuracy: 0.0903\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1278 - val_loss: 2.2051 - val_accuracy: 0.0903\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1986 - accuracy: 0.1115 - val_loss: 2.2051 - val_accuracy: 0.0903\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1364 - val_loss: 2.2053 - val_accuracy: 0.0903\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1260 - val_loss: 2.2054 - val_accuracy: 0.0903\n",
    "Accuracy: 0.0722, Loss: 2.1976\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: -560.6386 215.96014\n",
    "y (class distribution in batch): [4. 4. 1. 2. 4. 4. 7. 5. 1.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 2\n",
    "Label distribution in train_df: instrumentID\n",
    "2    70\n",
    "7    66\n",
    "1    66\n",
    "5    66\n",
    "3    66\n",
    "8    63\n",
    "6    61\n",
    "9    59\n",
    "4    59\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1832 - accuracy: 0.1458 - val_loss: 2.1979 - val_accuracy: 0.0625\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1348 - val_loss: 2.1981 - val_accuracy: 0.0625\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1020 - val_loss: 2.1990 - val_accuracy: 0.0625\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1253 - val_loss: 2.1987 - val_accuracy: 0.0625\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1985 - accuracy: 0.1126 - val_loss: 2.1979 - val_accuracy: 0.0625\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1293 - val_loss: 2.1998 - val_accuracy: 0.0625\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1141 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1977 - accuracy: 0.1069 - val_loss: 2.1998 - val_accuracy: 0.0625\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1185 - val_loss: 2.1997 - val_accuracy: 0.0625\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1190 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1271 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1154 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1154 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1986 - accuracy: 0.1008 - val_loss: 2.2004 - val_accuracy: 0.0625\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1074 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1167 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1977 - accuracy: 0.1352 - val_loss: 2.1989 - val_accuracy: 0.0625\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1256 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1324 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2002 - accuracy: 0.1040 - val_loss: 2.2001 - val_accuracy: 0.0625\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1170 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1998 - accuracy: 0.1231 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1917 - accuracy: 0.1319 - val_loss: 2.2013 - val_accuracy: 0.0625\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.1486 - val_loss: 2.2011 - val_accuracy: 0.0625\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2000 - accuracy: 0.1049 - val_loss: 2.1997 - val_accuracy: 0.0625\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1979 - accuracy: 0.0957 - val_loss: 2.2001 - val_accuracy: 0.0625\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1265 - val_loss: 2.2004 - val_accuracy: 0.0625\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1392 - val_loss: 2.2012 - val_accuracy: 0.0625\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.0906 - val_loss: 2.1997 - val_accuracy: 0.0625\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1934 - accuracy: 0.1478 - val_loss: 2.2007 - val_accuracy: 0.0625\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1975 - accuracy: 0.1247 - val_loss: 2.2002 - val_accuracy: 0.0625\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1066 - val_loss: 2.2008 - val_accuracy: 0.0625\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1979 - accuracy: 0.1057 - val_loss: 2.2009 - val_accuracy: 0.0625\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1999 - accuracy: 0.1041 - val_loss: 2.2004 - val_accuracy: 0.0625\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1095 - val_loss: 2.2003 - val_accuracy: 0.0625\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1060 - val_loss: 2.2009 - val_accuracy: 0.0625\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1981 - accuracy: 0.1050 - val_loss: 2.2007 - val_accuracy: 0.0625\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1240 - val_loss: 2.2012 - val_accuracy: 0.0625\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1219 - val_loss: 2.2010 - val_accuracy: 0.0625\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1231 - val_loss: 2.2009 - val_accuracy: 0.0625\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1134 - val_loss: 2.2008 - val_accuracy: 0.0625\n",
    "Accuracy: 0.1167, Loss: 2.1976\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: -594.3909 213.05296\n",
    "y (class distribution in batch): [3. 1. 4. 4. 1. 4. 4. 2. 9.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "First label (class index): 8\n",
    "Label distribution in train_df: instrumentID\n",
    "6    71\n",
    "4    71\n",
    "2    70\n",
    "5    66\n",
    "9    65\n",
    "3    64\n",
    "7    58\n",
    "1    58\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.2226 - accuracy: 0.0915 - val_loss: 2.1987 - val_accuracy: 0.0903\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1188 - val_loss: 2.2005 - val_accuracy: 0.0903\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1411 - val_loss: 2.2028 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1092 - val_loss: 2.2034 - val_accuracy: 0.0903\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1053 - val_loss: 2.2042 - val_accuracy: 0.0903\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1914 - accuracy: 0.1606 - val_loss: 2.2073 - val_accuracy: 0.0903\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1299 - val_loss: 2.2086 - val_accuracy: 0.0903\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1909 - accuracy: 0.1321 - val_loss: 2.2109 - val_accuracy: 0.0903\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1255 - val_loss: 2.2113 - val_accuracy: 0.0903\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.0924 - val_loss: 2.2123 - val_accuracy: 0.0764\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1160 - val_loss: 2.2114 - val_accuracy: 0.0764\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.0982 - val_loss: 2.2132 - val_accuracy: 0.0764\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1930 - accuracy: 0.1265 - val_loss: 2.2144 - val_accuracy: 0.0903\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.0964 - val_loss: 2.2143 - val_accuracy: 0.0903\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1933 - accuracy: 0.1000 - val_loss: 2.2145 - val_accuracy: 0.0903\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1939 - accuracy: 0.1212 - val_loss: 2.2153 - val_accuracy: 0.0903\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1325 - val_loss: 2.2156 - val_accuracy: 0.0764\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1899 - accuracy: 0.1319 - val_loss: 2.2177 - val_accuracy: 0.0903\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1891 - accuracy: 0.1433 - val_loss: 2.2185 - val_accuracy: 0.0903\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1876 - accuracy: 0.1341 - val_loss: 2.2192 - val_accuracy: 0.0764\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1214 - val_loss: 2.2189 - val_accuracy: 0.0903\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1460 - val_loss: 2.2195 - val_accuracy: 0.0903\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1907 - accuracy: 0.1125 - val_loss: 2.2221 - val_accuracy: 0.0764\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1908 - accuracy: 0.1135 - val_loss: 2.2216 - val_accuracy: 0.0764\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.0944 - val_loss: 2.2204 - val_accuracy: 0.0764\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1980 - accuracy: 0.0850 - val_loss: 2.2194 - val_accuracy: 0.0764\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1979 - accuracy: 0.1134 - val_loss: 2.2190 - val_accuracy: 0.0764\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1102 - val_loss: 2.2199 - val_accuracy: 0.0764\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1167 - val_loss: 2.2201 - val_accuracy: 0.0764\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1204 - val_loss: 2.2194 - val_accuracy: 0.0764\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1883 - accuracy: 0.1399 - val_loss: 2.2201 - val_accuracy: 0.0764\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1917 - accuracy: 0.1377 - val_loss: 2.2209 - val_accuracy: 0.0764\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1910 - accuracy: 0.1176 - val_loss: 2.2207 - val_accuracy: 0.0764\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1891 - accuracy: 0.1559 - val_loss: 2.2201 - val_accuracy: 0.0764\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2007 - accuracy: 0.0935 - val_loss: 2.2179 - val_accuracy: 0.0764\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1171 - val_loss: 2.2181 - val_accuracy: 0.0764\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.0843 - val_loss: 2.2190 - val_accuracy: 0.0764\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1938 - accuracy: 0.1350 - val_loss: 2.2199 - val_accuracy: 0.0903\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1299 - val_loss: 2.2196 - val_accuracy: 0.0903\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1885 - accuracy: 0.1441 - val_loss: 2.2201 - val_accuracy: 0.0903\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1212 - val_loss: 2.2181 - val_accuracy: 0.0764\n",
    "Accuracy: 0.0889, Loss: 2.1982\n",
    "\n",
    "mfcc - Mean Accuracy: 0.0911 ± 0.0147\n",
    "\n",
    "==================================================\n",
    "Training model for chromagram\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "chromagram Folds: 100%\n",
    " 5/5 [00:31<00:00,  6.21s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: 0.0 1.0\n",
    "y (class distribution in batch): [5. 3. 1. 3. 5. 4. 5. 3. 3.]\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "First label (class index): 4\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "2    69\n",
    "6    68\n",
    "9    66\n",
    "5    66\n",
    "1    65\n",
    "3    59\n",
    "7    57\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.1973 - accuracy: 0.1064 - val_loss: 2.1981 - val_accuracy: 0.0486\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1165 - val_loss: 2.1989 - val_accuracy: 0.0486\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1130 - val_loss: 2.1996 - val_accuracy: 0.0486\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1299 - val_loss: 2.2003 - val_accuracy: 0.0486\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1290 - val_loss: 2.2012 - val_accuracy: 0.0486\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1151 - val_loss: 2.2019 - val_accuracy: 0.0486\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1416 - val_loss: 2.2028 - val_accuracy: 0.0486\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1187 - val_loss: 2.2035 - val_accuracy: 0.0486\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1148 - val_loss: 2.2042 - val_accuracy: 0.0486\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1084 - val_loss: 2.2048 - val_accuracy: 0.0486\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1415 - val_loss: 2.2056 - val_accuracy: 0.0486\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1300 - val_loss: 2.2060 - val_accuracy: 0.0486\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1100 - val_loss: 2.2066 - val_accuracy: 0.0486\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1115 - val_loss: 2.2072 - val_accuracy: 0.0486\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1933 - accuracy: 0.1462 - val_loss: 2.2082 - val_accuracy: 0.0486\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1137 - val_loss: 2.2088 - val_accuracy: 0.0486\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1939 - accuracy: 0.1371 - val_loss: 2.2093 - val_accuracy: 0.0486\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.1301 - val_loss: 2.2098 - val_accuracy: 0.0486\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1938 - accuracy: 0.1416 - val_loss: 2.2104 - val_accuracy: 0.0486\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1087 - val_loss: 2.2106 - val_accuracy: 0.0486\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1239 - val_loss: 2.2112 - val_accuracy: 0.0486\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1421 - val_loss: 2.2118 - val_accuracy: 0.0486\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1947 - accuracy: 0.1123 - val_loss: 2.2122 - val_accuracy: 0.0486\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1161 - val_loss: 2.2126 - val_accuracy: 0.0486\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1020 - val_loss: 2.2130 - val_accuracy: 0.0486\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1160 - val_loss: 2.2136 - val_accuracy: 0.0486\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1139 - val_loss: 2.2140 - val_accuracy: 0.0486\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1293 - val_loss: 2.2145 - val_accuracy: 0.0486\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1225 - val_loss: 2.2149 - val_accuracy: 0.0486\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1947 - accuracy: 0.1365 - val_loss: 2.2154 - val_accuracy: 0.0486\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1349 - val_loss: 2.2156 - val_accuracy: 0.0486\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1922 - accuracy: 0.1290 - val_loss: 2.2160 - val_accuracy: 0.0486\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1891 - accuracy: 0.1483 - val_loss: 2.2166 - val_accuracy: 0.0486\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1127 - val_loss: 2.2166 - val_accuracy: 0.0486\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1147 - val_loss: 2.2171 - val_accuracy: 0.0486\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1888 - accuracy: 0.1314 - val_loss: 2.2176 - val_accuracy: 0.0486\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1894 - accuracy: 0.1541 - val_loss: 2.2179 - val_accuracy: 0.0486\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1901 - accuracy: 0.1246 - val_loss: 2.2180 - val_accuracy: 0.0486\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1354 - val_loss: 2.2182 - val_accuracy: 0.0486\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1146 - val_loss: 2.2185 - val_accuracy: 0.0486\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1295 - val_loss: 2.2186 - val_accuracy: 0.0486\n",
    "Accuracy: 0.1111, Loss: 2.1975\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: 0.0 1.0\n",
    "y (class distribution in batch): [6. 0. 2. 4. 6. 4. 2. 4. 4.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    "First label (class index): 5\n",
    "Label distribution in train_df: instrumentID\n",
    "6    69\n",
    "3    69\n",
    "1    69\n",
    "4    66\n",
    "7    65\n",
    "2    62\n",
    "9    62\n",
    "8    61\n",
    "5    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.5106 - accuracy: 0.1247 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2853 - accuracy: 0.1039 - val_loss: 2.2322 - val_accuracy: 0.1181\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2966 - accuracy: 0.1053 - val_loss: 2.2701 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3806 - accuracy: 0.1178 - val_loss: 2.4097 - val_accuracy: 0.1042\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3325 - accuracy: 0.1089 - val_loss: 3.3057 - val_accuracy: 0.1042\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2787 - accuracy: 0.1103 - val_loss: 4.2613 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2571 - accuracy: 0.1357 - val_loss: 4.8796 - val_accuracy: 0.1042\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3413 - accuracy: 0.1014 - val_loss: 6.7270 - val_accuracy: 0.0694\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3266 - accuracy: 0.0976 - val_loss: 9.5138 - val_accuracy: 0.1042\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2869 - accuracy: 0.1492 - val_loss: 9.6135 - val_accuracy: 0.1111\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3042 - accuracy: 0.1033 - val_loss: 13.8409 - val_accuracy: 0.0833\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3356 - accuracy: 0.1213 - val_loss: 9.1974 - val_accuracy: 0.1389\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3300 - accuracy: 0.0817 - val_loss: 12.4508 - val_accuracy: 0.1181\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2931 - accuracy: 0.0846 - val_loss: 14.8509 - val_accuracy: 0.1181\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3288 - accuracy: 0.1339 - val_loss: 8.5990 - val_accuracy: 0.1181\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2916 - accuracy: 0.1127 - val_loss: 6.6352 - val_accuracy: 0.0764\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2662 - accuracy: 0.1127 - val_loss: 5.1417 - val_accuracy: 0.1111\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2666 - accuracy: 0.1191 - val_loss: 9.3312 - val_accuracy: 0.1042\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2934 - accuracy: 0.1023 - val_loss: 9.4553 - val_accuracy: 0.1181\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2784 - accuracy: 0.1106 - val_loss: 10.4068 - val_accuracy: 0.1111\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2435 - accuracy: 0.1161 - val_loss: 9.7692 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2561 - accuracy: 0.1237 - val_loss: 9.0696 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2545 - accuracy: 0.0961 - val_loss: 12.0084 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2689 - accuracy: 0.1003 - val_loss: 10.4195 - val_accuracy: 0.0833\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2685 - accuracy: 0.1038 - val_loss: 8.1610 - val_accuracy: 0.0694\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2732 - accuracy: 0.1344 - val_loss: 12.5111 - val_accuracy: 0.0625\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2347 - accuracy: 0.1390 - val_loss: 11.2199 - val_accuracy: 0.0556\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2461 - accuracy: 0.1010 - val_loss: 10.9554 - val_accuracy: 0.0486\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2222 - accuracy: 0.1463 - val_loss: 8.6967 - val_accuracy: 0.0694\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2499 - accuracy: 0.0977 - val_loss: 10.2637 - val_accuracy: 0.0764\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2399 - accuracy: 0.1146 - val_loss: 13.5093 - val_accuracy: 0.0625\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2291 - accuracy: 0.1250 - val_loss: 14.5157 - val_accuracy: 0.0694\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2483 - accuracy: 0.1049 - val_loss: 9.3019 - val_accuracy: 0.0625\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2420 - accuracy: 0.1144 - val_loss: 7.9042 - val_accuracy: 0.0556\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2375 - accuracy: 0.1261 - val_loss: 6.7678 - val_accuracy: 0.0625\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2278 - accuracy: 0.0978 - val_loss: 5.9153 - val_accuracy: 0.0556\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2137 - accuracy: 0.1406 - val_loss: 7.7651 - val_accuracy: 0.1389\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2147 - accuracy: 0.1248 - val_loss: 9.4482 - val_accuracy: 0.1319\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2182 - accuracy: 0.1343 - val_loss: 9.7384 - val_accuracy: 0.1458\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2479 - accuracy: 0.0793 - val_loss: 6.4152 - val_accuracy: 0.1181\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2306 - accuracy: 0.1007 - val_loss: 5.0622 - val_accuracy: 0.1042\n",
    "Accuracy: 0.0833, Loss: 14.4980\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: 8.312639e-06 1.0\n",
    "y (class distribution in batch): [4. 6. 4. 2. 3. 6. 1. 3. 3.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 2\n",
    "Label distribution in train_df: instrumentID\n",
    "4    71\n",
    "2    69\n",
    "9    66\n",
    "1    65\n",
    "5    65\n",
    "8    64\n",
    "6    63\n",
    "3    57\n",
    "7    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 15ms/step - loss: 2.7033 - accuracy: 0.1080 - val_loss: 2.2086 - val_accuracy: 0.1111\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.6742 - accuracy: 0.0937 - val_loss: 2.2889 - val_accuracy: 0.1111\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4644 - accuracy: 0.1059 - val_loss: 2.4790 - val_accuracy: 0.1111\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4213 - accuracy: 0.0940 - val_loss: 2.8413 - val_accuracy: 0.1181\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3835 - accuracy: 0.1129 - val_loss: 3.9151 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3784 - accuracy: 0.0883 - val_loss: 4.9767 - val_accuracy: 0.1111\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3560 - accuracy: 0.1047 - val_loss: 6.8585 - val_accuracy: 0.1111\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3629 - accuracy: 0.0998 - val_loss: 8.1844 - val_accuracy: 0.1111\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3020 - accuracy: 0.1053 - val_loss: 9.1578 - val_accuracy: 0.1042\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4033 - accuracy: 0.0930 - val_loss: 7.6262 - val_accuracy: 0.1042\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3085 - accuracy: 0.1038 - val_loss: 10.8149 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2658 - accuracy: 0.1327 - val_loss: 15.2154 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2490 - accuracy: 0.1095 - val_loss: 13.3410 - val_accuracy: 0.1250\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3114 - accuracy: 0.0915 - val_loss: 13.9964 - val_accuracy: 0.1389\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2937 - accuracy: 0.1149 - val_loss: 9.5731 - val_accuracy: 0.1042\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2391 - accuracy: 0.1355 - val_loss: 9.8568 - val_accuracy: 0.1319\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2764 - accuracy: 0.1294 - val_loss: 12.6937 - val_accuracy: 0.1250\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2604 - accuracy: 0.1314 - val_loss: 15.4056 - val_accuracy: 0.1250\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2641 - accuracy: 0.1125 - val_loss: 21.5055 - val_accuracy: 0.1250\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2364 - accuracy: 0.1101 - val_loss: 24.4118 - val_accuracy: 0.1250\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2401 - accuracy: 0.1454 - val_loss: 29.9177 - val_accuracy: 0.1250\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2234 - accuracy: 0.1583 - val_loss: 27.6432 - val_accuracy: 0.1250\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2201 - accuracy: 0.1358 - val_loss: 29.6494 - val_accuracy: 0.1250\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2598 - accuracy: 0.0995 - val_loss: 32.4478 - val_accuracy: 0.1250\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2447 - accuracy: 0.0885 - val_loss: 33.8030 - val_accuracy: 0.1250\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2207 - accuracy: 0.1371 - val_loss: 40.6033 - val_accuracy: 0.1250\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2290 - accuracy: 0.1062 - val_loss: 40.8405 - val_accuracy: 0.1250\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2651 - accuracy: 0.0959 - val_loss: 33.8312 - val_accuracy: 0.1250\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2395 - accuracy: 0.1100 - val_loss: 29.3766 - val_accuracy: 0.1458\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2230 - accuracy: 0.0977 - val_loss: 29.1261 - val_accuracy: 0.1250\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2164 - accuracy: 0.1172 - val_loss: 32.8452 - val_accuracy: 0.1042\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2453 - accuracy: 0.1019 - val_loss: 28.4807 - val_accuracy: 0.1042\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2259 - accuracy: 0.1102 - val_loss: 25.3231 - val_accuracy: 0.1181\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2298 - accuracy: 0.1116 - val_loss: 23.8926 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2379 - accuracy: 0.1240 - val_loss: 33.9787 - val_accuracy: 0.1319\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1999 - accuracy: 0.1155 - val_loss: 24.3493 - val_accuracy: 0.1250\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2092 - accuracy: 0.1057 - val_loss: 18.4150 - val_accuracy: 0.1458\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2043 - accuracy: 0.1401 - val_loss: 15.8485 - val_accuracy: 0.1181\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2236 - accuracy: 0.0880 - val_loss: 17.1538 - val_accuracy: 0.1181\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2178 - accuracy: 0.1287 - val_loss: 28.9973 - val_accuracy: 0.1319\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2194 - accuracy: 0.1064 - val_loss: 31.7713 - val_accuracy: 0.1319\n",
    "Accuracy: 0.1111, Loss: 2.2007\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: 0.0 1.0\n",
    "y (class distribution in batch): [5. 5. 1. 1. 2. 5. 6. 3. 4.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 2\n",
    "Label distribution in train_df: instrumentID\n",
    "7    70\n",
    "2    69\n",
    "1    65\n",
    "8    64\n",
    "3    64\n",
    "5    64\n",
    "4    61\n",
    "6    61\n",
    "9    58\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.6607 - accuracy: 0.1130 - val_loss: 2.2763 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.6539 - accuracy: 0.1047 - val_loss: 2.4991 - val_accuracy: 0.1597\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4430 - accuracy: 0.1051 - val_loss: 3.4301 - val_accuracy: 0.1181\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4390 - accuracy: 0.0760 - val_loss: 4.2916 - val_accuracy: 0.1111\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.5118 - accuracy: 0.0935 - val_loss: 4.3844 - val_accuracy: 0.1389\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3854 - accuracy: 0.1183 - val_loss: 5.2345 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3040 - accuracy: 0.1536 - val_loss: 6.2410 - val_accuracy: 0.0764\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4174 - accuracy: 0.1327 - val_loss: 5.8373 - val_accuracy: 0.1181\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3480 - accuracy: 0.1419 - val_loss: 6.1725 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3022 - accuracy: 0.1163 - val_loss: 8.5686 - val_accuracy: 0.1111\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3736 - accuracy: 0.1211 - val_loss: 11.8771 - val_accuracy: 0.1667\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2958 - accuracy: 0.1106 - val_loss: 17.7461 - val_accuracy: 0.1111\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3117 - accuracy: 0.1232 - val_loss: 23.5023 - val_accuracy: 0.1389\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2855 - accuracy: 0.1114 - val_loss: 27.0562 - val_accuracy: 0.1111\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2497 - accuracy: 0.0975 - val_loss: 18.8428 - val_accuracy: 0.1458\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2600 - accuracy: 0.1372 - val_loss: 24.3759 - val_accuracy: 0.1042\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2953 - accuracy: 0.1558 - val_loss: 23.0700 - val_accuracy: 0.1528\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2793 - accuracy: 0.1431 - val_loss: 23.8800 - val_accuracy: 0.1181\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2785 - accuracy: 0.1171 - val_loss: 14.2372 - val_accuracy: 0.1389\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2802 - accuracy: 0.0933 - val_loss: 18.0684 - val_accuracy: 0.1319\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2439 - accuracy: 0.1258 - val_loss: 32.5229 - val_accuracy: 0.1458\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2432 - accuracy: 0.1103 - val_loss: 51.5693 - val_accuracy: 0.1250\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2452 - accuracy: 0.1150 - val_loss: 33.8905 - val_accuracy: 0.1250\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2304 - accuracy: 0.1439 - val_loss: 38.3117 - val_accuracy: 0.0764\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2618 - accuracy: 0.1058 - val_loss: 77.3498 - val_accuracy: 0.0694\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2336 - accuracy: 0.1220 - val_loss: 106.5017 - val_accuracy: 0.0903\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2660 - accuracy: 0.0959 - val_loss: 108.9484 - val_accuracy: 0.0903\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2238 - accuracy: 0.1090 - val_loss: 141.7202 - val_accuracy: 0.0764\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2417 - accuracy: 0.1229 - val_loss: 160.6172 - val_accuracy: 0.0694\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2148 - accuracy: 0.1229 - val_loss: 185.4167 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2354 - accuracy: 0.1041 - val_loss: 188.1216 - val_accuracy: 0.0694\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2224 - accuracy: 0.1177 - val_loss: 195.9043 - val_accuracy: 0.1111\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2533 - accuracy: 0.1071 - val_loss: 240.3111 - val_accuracy: 0.1111\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2533 - accuracy: 0.0996 - val_loss: 230.2206 - val_accuracy: 0.0625\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2188 - accuracy: 0.1164 - val_loss: 230.8625 - val_accuracy: 0.0833\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2278 - accuracy: 0.1046 - val_loss: 244.2347 - val_accuracy: 0.0625\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2412 - accuracy: 0.1122 - val_loss: 325.6205 - val_accuracy: 0.0764\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2312 - accuracy: 0.0896 - val_loss: 305.0583 - val_accuracy: 0.0694\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2227 - accuracy: 0.1468 - val_loss: 312.1241 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2202 - accuracy: 0.1554 - val_loss: 321.9381 - val_accuracy: 0.0694\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2174 - accuracy: 0.1171 - val_loss: 305.7570 - val_accuracy: 0.0694\n",
    "Accuracy: 0.1167, Loss: 2.2191\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 8, 128, 1) y shape: (32, 9)\n",
    "X min/max: 0.0 1.0\n",
    "y (class distribution in batch): [2. 3. 9. 2. 5. 5. 3. 3. 0.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "First label (class index): 4\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "6    71\n",
    "2    69\n",
    "3    69\n",
    "5    64\n",
    "9    63\n",
    "1    58\n",
    "8    56\n",
    "7    54\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.2448 - accuracy: 0.1336 - val_loss: 2.2274 - val_accuracy: 0.0833\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2993 - accuracy: 0.1372 - val_loss: 2.4479 - val_accuracy: 0.1111\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3117 - accuracy: 0.1067 - val_loss: 3.5423 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2882 - accuracy: 0.1092 - val_loss: 6.2215 - val_accuracy: 0.0903\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2612 - accuracy: 0.1287 - val_loss: 10.4552 - val_accuracy: 0.0903\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3157 - accuracy: 0.1163 - val_loss: 10.6387 - val_accuracy: 0.0694\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2639 - accuracy: 0.1247 - val_loss: 61.4884 - val_accuracy: 0.1319\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3301 - accuracy: 0.1077 - val_loss: 33.9862 - val_accuracy: 0.1389\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2842 - accuracy: 0.1529 - val_loss: 80.7218 - val_accuracy: 0.1597\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3865 - accuracy: 0.1099 - val_loss: 157.9235 - val_accuracy: 0.1389\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3674 - accuracy: 0.1284 - val_loss: 250.5059 - val_accuracy: 0.1250\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3725 - accuracy: 0.1069 - val_loss: 305.1918 - val_accuracy: 0.1111\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3411 - accuracy: 0.0851 - val_loss: 383.6539 - val_accuracy: 0.1319\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3302 - accuracy: 0.0958 - val_loss: 414.3886 - val_accuracy: 0.1528\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3257 - accuracy: 0.1012 - val_loss: 712.0931 - val_accuracy: 0.1528\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2676 - accuracy: 0.1118 - val_loss: 599.0233 - val_accuracy: 0.1458\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2677 - accuracy: 0.1213 - val_loss: 202.5816 - val_accuracy: 0.1250\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2734 - accuracy: 0.1216 - val_loss: 337.7581 - val_accuracy: 0.1111\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2233 - accuracy: 0.1141 - val_loss: 404.4093 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2629 - accuracy: 0.1214 - val_loss: 865.9901 - val_accuracy: 0.1458\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2721 - accuracy: 0.1126 - val_loss: 797.7527 - val_accuracy: 0.1111\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2311 - accuracy: 0.1109 - val_loss: 629.9849 - val_accuracy: 0.1319\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2729 - accuracy: 0.0998 - val_loss: 522.4120 - val_accuracy: 0.1181\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2117 - accuracy: 0.1200 - val_loss: 504.9139 - val_accuracy: 0.0764\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2698 - accuracy: 0.0861 - val_loss: 618.2752 - val_accuracy: 0.0833\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2454 - accuracy: 0.1521 - val_loss: 1010.2048 - val_accuracy: 0.1250\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2418 - accuracy: 0.1318 - val_loss: 1278.5441 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2390 - accuracy: 0.1042 - val_loss: 1512.4807 - val_accuracy: 0.1181\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2369 - accuracy: 0.1030 - val_loss: 1286.1681 - val_accuracy: 0.1597\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2397 - accuracy: 0.1100 - val_loss: 572.5662 - val_accuracy: 0.1458\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2300 - accuracy: 0.1141 - val_loss: 7.9890 - val_accuracy: 0.1528\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2332 - accuracy: 0.1065 - val_loss: 228.0837 - val_accuracy: 0.1250\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2164 - accuracy: 0.1432 - val_loss: 229.9604 - val_accuracy: 0.1250\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2204 - accuracy: 0.1216 - val_loss: 205.0940 - val_accuracy: 0.1319\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2363 - accuracy: 0.1234 - val_loss: 551.7465 - val_accuracy: 0.1181\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2040 - accuracy: 0.1375 - val_loss: 694.1219 - val_accuracy: 0.1250\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2265 - accuracy: 0.1204 - val_loss: 628.8564 - val_accuracy: 0.1181\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2428 - accuracy: 0.0965 - val_loss: 674.7425 - val_accuracy: 0.1319\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2345 - accuracy: 0.1059 - val_loss: 771.9104 - val_accuracy: 0.1111\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2326 - accuracy: 0.1083 - val_loss: 906.2668 - val_accuracy: 0.1319\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2064 - accuracy: 0.1001 - val_loss: 1127.6929 - val_accuracy: 0.1319\n",
    "Accuracy: 0.1056, Loss: 2.1971\n",
    "\n",
    "chromagram - Mean Accuracy: 0.1056 ± 0.0117\n",
    "\n",
    "==================================================\n",
    "Training model for spectral_contrast\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "spectral_contrast Folds: 100%\n",
    " 5/5 [00:43<00:00, 10.33s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 3, 128, 1) y shape: (32, 9)\n",
    "X min/max: 0.37260252526396087 56.70268357126612\n",
    "y (class distribution in batch): [3. 5. 3. 4. 5. 4. 2. 1. 5.]\n",
    "\n",
    "First label (one-hot): [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 2\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "9    70\n",
    "2    69\n",
    "6    68\n",
    "5    66\n",
    "1    65\n",
    "3    58\n",
    "7    55\n",
    "8    52\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.1973 - accuracy: 0.1258 - val_loss: 2.1980 - val_accuracy: 0.0833\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1060 - val_loss: 2.1991 - val_accuracy: 0.1111\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1342 - val_loss: 2.2000 - val_accuracy: 0.1111\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1175 - val_loss: 2.2013 - val_accuracy: 0.0486\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1200 - val_loss: 2.2020 - val_accuracy: 0.0486\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.0991 - val_loss: 2.2030 - val_accuracy: 0.0486\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1162 - val_loss: 2.2039 - val_accuracy: 0.0486\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1083 - val_loss: 2.2047 - val_accuracy: 0.0486\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1452 - val_loss: 2.2057 - val_accuracy: 0.0486\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1265 - val_loss: 2.2063 - val_accuracy: 0.0486\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1348 - val_loss: 2.2073 - val_accuracy: 0.0486\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1366 - val_loss: 2.2082 - val_accuracy: 0.0486\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1201 - val_loss: 2.2089 - val_accuracy: 0.0486\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1924 - accuracy: 0.1067 - val_loss: 2.2097 - val_accuracy: 0.0486\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1924 - accuracy: 0.1380 - val_loss: 2.2105 - val_accuracy: 0.0486\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1113 - val_loss: 2.2112 - val_accuracy: 0.0486\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1917 - accuracy: 0.1329 - val_loss: 2.2121 - val_accuracy: 0.0486\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1302 - val_loss: 2.2125 - val_accuracy: 0.0486\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1938 - accuracy: 0.1129 - val_loss: 2.2132 - val_accuracy: 0.0486\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1278 - val_loss: 2.2140 - val_accuracy: 0.0486\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1912 - accuracy: 0.1238 - val_loss: 2.2146 - val_accuracy: 0.0486\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1430 - val_loss: 2.2154 - val_accuracy: 0.0486\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1915 - accuracy: 0.1279 - val_loss: 2.2158 - val_accuracy: 0.0486\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1263 - val_loss: 2.2163 - val_accuracy: 0.0486\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1286 - val_loss: 2.2168 - val_accuracy: 0.0486\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1125 - val_loss: 2.2175 - val_accuracy: 0.0486\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1231 - val_loss: 2.2180 - val_accuracy: 0.0486\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1159 - val_loss: 2.2183 - val_accuracy: 0.0486\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1910 - accuracy: 0.1158 - val_loss: 2.2190 - val_accuracy: 0.0486\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1430 - val_loss: 2.2197 - val_accuracy: 0.0486\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1194 - val_loss: 2.2200 - val_accuracy: 0.0486\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1193 - val_loss: 2.2205 - val_accuracy: 0.0486\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1891 - accuracy: 0.1430 - val_loss: 2.2212 - val_accuracy: 0.0486\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1902 - accuracy: 0.1478 - val_loss: 2.2216 - val_accuracy: 0.0486\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1074 - val_loss: 2.2217 - val_accuracy: 0.0486\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1867 - accuracy: 0.1296 - val_loss: 2.2224 - val_accuracy: 0.0486\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1863 - accuracy: 0.1460 - val_loss: 2.2228 - val_accuracy: 0.0486\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1422 - val_loss: 2.2229 - val_accuracy: 0.0486\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1152 - val_loss: 2.2232 - val_accuracy: 0.0486\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1872 - accuracy: 0.1448 - val_loss: 2.2238 - val_accuracy: 0.0486\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1898 - accuracy: 0.1261 - val_loss: 2.2242 - val_accuracy: 0.0486\n",
    "Accuracy: 0.1111, Loss: 2.1978\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 3, 128, 1) y shape: (32, 9)\n",
    "X min/max: 1.0416550929199389 58.07924881300532\n",
    "y (class distribution in batch): [8. 1. 5. 2. 2. 3. 4. 4. 3.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "First label (class index): 8\n",
    "Label distribution in train_df: instrumentID\n",
    "6    69\n",
    "1    69\n",
    "3    68\n",
    "4    66\n",
    "9    65\n",
    "7    64\n",
    "2    63\n",
    "8    63\n",
    "5    49\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 10ms/step - loss: 2.1973 - accuracy: 0.1199 - val_loss: 2.1973 - val_accuracy: 0.1250\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1051 - val_loss: 2.1975 - val_accuracy: 0.1250\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.0999 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1290 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1108 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1191 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1277 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1180 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.0900 - val_loss: 2.1990 - val_accuracy: 0.1250\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1216 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.0875 - val_loss: 2.1994 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1245 - val_loss: 2.1995 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1081 - val_loss: 2.1997 - val_accuracy: 0.1250\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.0893 - val_loss: 2.2000 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1939 - accuracy: 0.1370 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1316 - val_loss: 2.2004 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1304 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1126 - val_loss: 2.2008 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1201 - val_loss: 2.2010 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1447 - val_loss: 2.2011 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1359 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.0984 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1249 - val_loss: 2.2017 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1313 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.0867 - val_loss: 2.2020 - val_accuracy: 0.1250\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1905 - accuracy: 0.1418 - val_loss: 2.2023 - val_accuracy: 0.1250\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1895 - accuracy: 0.1183 - val_loss: 2.2024 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1222 - val_loss: 2.2026 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1906 - accuracy: 0.1214 - val_loss: 2.2027 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1908 - accuracy: 0.1091 - val_loss: 2.2028 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.0895 - val_loss: 2.2028 - val_accuracy: 0.1250\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1981 - accuracy: 0.1250 - val_loss: 2.2029 - val_accuracy: 0.1250\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1908 - accuracy: 0.1027 - val_loss: 2.2034 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1245 - val_loss: 2.2034 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1976 - accuracy: 0.1127 - val_loss: 2.2033 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1227 - val_loss: 2.2036 - val_accuracy: 0.1250\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1260 - val_loss: 2.2037 - val_accuracy: 0.1250\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1909 - accuracy: 0.1211 - val_loss: 2.2039 - val_accuracy: 0.1250\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.0988 - val_loss: 2.2039 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1279 - val_loss: 2.2042 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1991 - accuracy: 0.1151 - val_loss: 2.2042 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0722, Loss: 2.1982\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 3, 128, 1) y shape: (32, 9)\n",
    "X min/max: 1.3602788234469299 57.36006035690242\n",
    "y (class distribution in batch): [2. 3. 3. 4. 4. 5. 5. 1. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    "First label (class index): 6\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "8    68\n",
    "2    67\n",
    "9    65\n",
    "1    65\n",
    "6    63\n",
    "5    62\n",
    "7    58\n",
    "3    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0938 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1332 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1243 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1977 - accuracy: 0.1018 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1346 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1220 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1345 - val_loss: 2.1994 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1252 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1324 - val_loss: 2.2000 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1348 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1281 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1247 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1407 - val_loss: 2.2010 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1432 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1179 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1071 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1188 - val_loss: 2.2019 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1193 - val_loss: 2.2021 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1234 - val_loss: 2.2023 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1280 - val_loss: 2.2027 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1923 - accuracy: 0.1399 - val_loss: 2.2029 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1437 - val_loss: 2.2029 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1939 - accuracy: 0.1172 - val_loss: 2.2032 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1917 - accuracy: 0.1438 - val_loss: 2.2034 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1135 - val_loss: 2.2035 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1383 - val_loss: 2.2036 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1296 - val_loss: 2.6700 - val_accuracy: 0.1042\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1515 - val_loss: 4.4658 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1344 - val_loss: 2.2042 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1927 - accuracy: 0.1563 - val_loss: 2.2044 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1404 - val_loss: 2.2045 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1109 - val_loss: 2.2046 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1953 - accuracy: 0.1310 - val_loss: 2.2047 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1243 - val_loss: 3.2681 - val_accuracy: 0.1111\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1338 - val_loss: 6.2086 - val_accuracy: 0.1111\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1171 - val_loss: 2.2051 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1068 - val_loss: 2.2053 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1206 - val_loss: 2.2055 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1269 - val_loss: 2.2056 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1379 - val_loss: 2.2056 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1435 - val_loss: 2.2057 - val_accuracy: 0.0972\n",
    "Accuracy: 0.1056, Loss: 2.1973\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 3, 128, 1) y shape: (32, 9)\n",
    "X min/max: 1.1185629181837378 59.241336919007566\n",
    "y (class distribution in batch): [4. 7. 3. 3. 2. 4. 4. 2. 3.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "First label (class index): 8\n",
    "Label distribution in train_df: instrumentID\n",
    "2    69\n",
    "8    66\n",
    "7    66\n",
    "1    65\n",
    "3    65\n",
    "5    64\n",
    "6    61\n",
    "9    60\n",
    "4    60\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.3027 - accuracy: 0.1287 - val_loss: 2.1991 - val_accuracy: 0.1181\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3787 - accuracy: 0.0947 - val_loss: 2.2054 - val_accuracy: 0.1111\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.5081 - accuracy: 0.1070 - val_loss: 2.2155 - val_accuracy: 0.0833\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4045 - accuracy: 0.1131 - val_loss: 2.2150 - val_accuracy: 0.1667\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4290 - accuracy: 0.1304 - val_loss: 2.2421 - val_accuracy: 0.1111\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3901 - accuracy: 0.1160 - val_loss: 2.2102 - val_accuracy: 0.1319\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3902 - accuracy: 0.1083 - val_loss: 3.1587 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3119 - accuracy: 0.1618 - val_loss: 3.5726 - val_accuracy: 0.0625\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2935 - accuracy: 0.1398 - val_loss: 4.5294 - val_accuracy: 0.0417\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3048 - accuracy: 0.1183 - val_loss: 5.6194 - val_accuracy: 0.0556\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2595 - accuracy: 0.1327 - val_loss: 5.9206 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2459 - accuracy: 0.1386 - val_loss: 7.1080 - val_accuracy: 0.1111\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2995 - accuracy: 0.1029 - val_loss: 8.6470 - val_accuracy: 0.0764\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3189 - accuracy: 0.0902 - val_loss: 8.3413 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2921 - accuracy: 0.0955 - val_loss: 8.4849 - val_accuracy: 0.0833\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3103 - accuracy: 0.1049 - val_loss: 2.2008 - val_accuracy: 0.1597\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2786 - accuracy: 0.1380 - val_loss: 2.1959 - val_accuracy: 0.1458\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2542 - accuracy: 0.1069 - val_loss: 2.2039 - val_accuracy: 0.1042\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2143 - accuracy: 0.1045 - val_loss: 2.2021 - val_accuracy: 0.1458\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2716 - accuracy: 0.1125 - val_loss: 2.1960 - val_accuracy: 0.1597\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2393 - accuracy: 0.1265 - val_loss: 5.0263 - val_accuracy: 0.1181\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2837 - accuracy: 0.1450 - val_loss: 2.2166 - val_accuracy: 0.0903\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2218 - accuracy: 0.1403 - val_loss: 2.2128 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2413 - accuracy: 0.1032 - val_loss: 17.9468 - val_accuracy: 0.0833\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2360 - accuracy: 0.1094 - val_loss: 13.7840 - val_accuracy: 0.1111\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2439 - accuracy: 0.1455 - val_loss: 2.2133 - val_accuracy: 0.0694\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2579 - accuracy: 0.1147 - val_loss: 2.2100 - val_accuracy: 0.0694\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2353 - accuracy: 0.1487 - val_loss: 2.2048 - val_accuracy: 0.1042\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2457 - accuracy: 0.1179 - val_loss: 2.2276 - val_accuracy: 0.1319\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2159 - accuracy: 0.1171 - val_loss: 2.2319 - val_accuracy: 0.1042\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2265 - accuracy: 0.1066 - val_loss: 2.2244 - val_accuracy: 0.0625\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2456 - accuracy: 0.1204 - val_loss: 2.2082 - val_accuracy: 0.1667\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2417 - accuracy: 0.1093 - val_loss: 2.1856 - val_accuracy: 0.1250\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2407 - accuracy: 0.1226 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2065 - accuracy: 0.1197 - val_loss: 2.2061 - val_accuracy: 0.0764\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2184 - accuracy: 0.1282 - val_loss: 2.1985 - val_accuracy: 0.1111\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2059 - accuracy: 0.1319 - val_loss: 2.1703 - val_accuracy: 0.1597\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2260 - accuracy: 0.1285 - val_loss: 2.1929 - val_accuracy: 0.0903\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2327 - accuracy: 0.1196 - val_loss: 2.2012 - val_accuracy: 0.1250\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2201 - accuracy: 0.1030 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2259 - accuracy: 0.0826 - val_loss: 2.1928 - val_accuracy: 0.0903\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1983 - accuracy: 0.1087 - val_loss: 2.2830 - val_accuracy: 0.0972\n",
    "Epoch 43/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2257 - accuracy: 0.1227 - val_loss: 4.5314 - val_accuracy: 0.0972\n",
    "Epoch 44/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2288 - accuracy: 0.1221 - val_loss: 4.1440 - val_accuracy: 0.0972\n",
    "Epoch 45/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2131 - accuracy: 0.1380 - val_loss: 4.5437 - val_accuracy: 0.0972\n",
    "Epoch 46/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2112 - accuracy: 0.1010 - val_loss: 2.1998 - val_accuracy: 0.0694\n",
    "Epoch 47/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2125 - accuracy: 0.1176 - val_loss: 2.2047 - val_accuracy: 0.0833\n",
    "Epoch 48/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2131 - accuracy: 0.1066 - val_loss: 2.2010 - val_accuracy: 0.1250\n",
    "Epoch 49/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2025 - accuracy: 0.1052 - val_loss: 2.2025 - val_accuracy: 0.0972\n",
    "Epoch 50/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2202 - accuracy: 0.1025 - val_loss: 2.2051 - val_accuracy: 0.0764\n",
    "Epoch 51/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2155 - accuracy: 0.0794 - val_loss: 2.2052 - val_accuracy: 0.0625\n",
    "Epoch 52/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2115 - accuracy: 0.1232 - val_loss: 2.1983 - val_accuracy: 0.1181\n",
    "Epoch 53/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2036 - accuracy: 0.0963 - val_loss: 2.2064 - val_accuracy: 0.0764\n",
    "Epoch 54/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2003 - accuracy: 0.1171 - val_loss: 2.1968 - val_accuracy: 0.0903\n",
    "Epoch 55/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2159 - accuracy: 0.1294 - val_loss: 4.8524 - val_accuracy: 0.1389\n",
    "Epoch 56/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2090 - accuracy: 0.1285 - val_loss: 4.9878 - val_accuracy: 0.1528\n",
    "Epoch 57/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2202 - accuracy: 0.1300 - val_loss: 5.2105 - val_accuracy: 0.1111\n",
    "Epoch 58/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2152 - accuracy: 0.1097 - val_loss: 5.1310 - val_accuracy: 0.1181\n",
    "Epoch 59/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2087 - accuracy: 0.0932 - val_loss: 4.8849 - val_accuracy: 0.1111\n",
    "Epoch 60/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2144 - accuracy: 0.1038 - val_loss: 4.4959 - val_accuracy: 0.0764\n",
    "Epoch 61/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2210 - accuracy: 0.0918 - val_loss: 4.4129 - val_accuracy: 0.0556\n",
    "Epoch 62/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2045 - accuracy: 0.1445 - val_loss: 4.5198 - val_accuracy: 0.1528\n",
    "Epoch 63/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2242 - accuracy: 0.1005 - val_loss: 4.6150 - val_accuracy: 0.0903\n",
    "Epoch 64/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2081 - accuracy: 0.0909 - val_loss: 4.4285 - val_accuracy: 0.0903\n",
    "Epoch 65/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2106 - accuracy: 0.1343 - val_loss: 4.3979 - val_accuracy: 0.1111\n",
    "Epoch 66/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2114 - accuracy: 0.1014 - val_loss: 4.7586 - val_accuracy: 0.0972\n",
    "Epoch 67/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1464 - val_loss: 4.0817 - val_accuracy: 0.1042\n",
    "Epoch 68/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2152 - accuracy: 0.1295 - val_loss: 3.8778 - val_accuracy: 0.0833\n",
    "Epoch 69/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1998 - accuracy: 0.1213 - val_loss: 3.9524 - val_accuracy: 0.1042\n",
    "Epoch 70/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2075 - accuracy: 0.1183 - val_loss: 3.8950 - val_accuracy: 0.0972\n",
    "Epoch 71/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2054 - accuracy: 0.1010 - val_loss: 3.5316 - val_accuracy: 0.0972\n",
    "Epoch 72/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2044 - accuracy: 0.1170 - val_loss: 3.5798 - val_accuracy: 0.1111\n",
    "Epoch 73/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1991 - accuracy: 0.1263 - val_loss: 3.3844 - val_accuracy: 0.0833\n",
    "Epoch 74/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2062 - accuracy: 0.0981 - val_loss: 3.0853 - val_accuracy: 0.1250\n",
    "Epoch 75/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1140 - val_loss: 2.9788 - val_accuracy: 0.0833\n",
    "Epoch 76/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1995 - accuracy: 0.1338 - val_loss: 2.2012 - val_accuracy: 0.0694\n",
    "Epoch 77/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1284 - val_loss: 2.2021 - val_accuracy: 0.0556\n",
    "Accuracy: 0.1056, Loss: 2.2049\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 3, 128, 1) y shape: (32, 9)\n",
    "X min/max: 1.1437311017300715 58.96714442772701\n",
    "y (class distribution in batch): [2. 2. 7. 5. 1. 4. 2. 4. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    "First label (class index): 5\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "6    71\n",
    "2    69\n",
    "5    67\n",
    "9    66\n",
    "3    64\n",
    "1    58\n",
    "7    56\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.4562 - accuracy: 0.0924 - val_loss: 10.5861 - val_accuracy: 0.0764\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.6417 - accuracy: 0.0951 - val_loss: 11.8154 - val_accuracy: 0.1458\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3749 - accuracy: 0.0997 - val_loss: 17.0110 - val_accuracy: 0.1528\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4673 - accuracy: 0.0952 - val_loss: 17.4670 - val_accuracy: 0.1319\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4400 - accuracy: 0.0923 - val_loss: 16.5109 - val_accuracy: 0.1389\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.3850 - accuracy: 0.1336 - val_loss: 14.6323 - val_accuracy: 0.1042\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4004 - accuracy: 0.1081 - val_loss: 18.4899 - val_accuracy: 0.1389\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3859 - accuracy: 0.0942 - val_loss: 21.2515 - val_accuracy: 0.1597\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3357 - accuracy: 0.1236 - val_loss: 19.1596 - val_accuracy: 0.1250\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3438 - accuracy: 0.0901 - val_loss: 4.0994 - val_accuracy: 0.0903\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.4008 - accuracy: 0.0786 - val_loss: 5.4061 - val_accuracy: 0.0764\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3388 - accuracy: 0.1037 - val_loss: 3.2950 - val_accuracy: 0.0833\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2982 - accuracy: 0.1346 - val_loss: 6.1587 - val_accuracy: 0.1111\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2719 - accuracy: 0.1250 - val_loss: 9.4491 - val_accuracy: 0.1389\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2706 - accuracy: 0.1231 - val_loss: 10.7022 - val_accuracy: 0.0694\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.3054 - accuracy: 0.1345 - val_loss: 13.1677 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2788 - accuracy: 0.1239 - val_loss: 9.5342 - val_accuracy: 0.1042\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2742 - accuracy: 0.1203 - val_loss: 8.0048 - val_accuracy: 0.1319\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2438 - accuracy: 0.1475 - val_loss: 10.8766 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2755 - accuracy: 0.1023 - val_loss: 13.6053 - val_accuracy: 0.0903\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2828 - accuracy: 0.1140 - val_loss: 12.1875 - val_accuracy: 0.1528\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2508 - accuracy: 0.1238 - val_loss: 12.8669 - val_accuracy: 0.0833\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2835 - accuracy: 0.0857 - val_loss: 11.5020 - val_accuracy: 0.0833\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2636 - accuracy: 0.1221 - val_loss: 9.6336 - val_accuracy: 0.1458\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2008 - accuracy: 0.1501 - val_loss: 9.0741 - val_accuracy: 0.1250\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2451 - accuracy: 0.1193 - val_loss: 8.0947 - val_accuracy: 0.1181\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2187 - accuracy: 0.1163 - val_loss: 7.0803 - val_accuracy: 0.1181\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2320 - accuracy: 0.1008 - val_loss: 7.5257 - val_accuracy: 0.1250\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2507 - accuracy: 0.0943 - val_loss: 5.2323 - val_accuracy: 0.1042\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2242 - accuracy: 0.1488 - val_loss: 6.3304 - val_accuracy: 0.0903\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2103 - accuracy: 0.0962 - val_loss: 7.2194 - val_accuracy: 0.1111\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2183 - accuracy: 0.1045 - val_loss: 9.1737 - val_accuracy: 0.1319\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2397 - accuracy: 0.1301 - val_loss: 9.2574 - val_accuracy: 0.1042\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2307 - accuracy: 0.1417 - val_loss: 12.6122 - val_accuracy: 0.0764\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1989 - accuracy: 0.1120 - val_loss: 9.0201 - val_accuracy: 0.1111\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2251 - accuracy: 0.1072 - val_loss: 7.5793 - val_accuracy: 0.1458\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2197 - accuracy: 0.1203 - val_loss: 6.2054 - val_accuracy: 0.1042\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2120 - accuracy: 0.1253 - val_loss: 5.8434 - val_accuracy: 0.1042\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1190 - val_loss: 6.3240 - val_accuracy: 0.0625\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2317 - accuracy: 0.1395 - val_loss: 7.1837 - val_accuracy: 0.0764\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2188 - accuracy: 0.1414 - val_loss: 8.3356 - val_accuracy: 0.0833\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2238 - accuracy: 0.1327 - val_loss: 7.9703 - val_accuracy: 0.1042\n",
    "Epoch 43/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2146 - accuracy: 0.0964 - val_loss: 5.2700 - val_accuracy: 0.0903\n",
    "Epoch 44/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2124 - accuracy: 0.1379 - val_loss: 4.6446 - val_accuracy: 0.1181\n",
    "Epoch 45/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2262 - accuracy: 0.1055 - val_loss: 2.2290 - val_accuracy: 0.0833\n",
    "Epoch 46/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2238 - accuracy: 0.1079 - val_loss: 2.2758 - val_accuracy: 0.0694\n",
    "Epoch 47/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2204 - accuracy: 0.1112 - val_loss: 2.2547 - val_accuracy: 0.0694\n",
    "Epoch 48/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2106 - accuracy: 0.1665 - val_loss: 2.2185 - val_accuracy: 0.0903\n",
    "Epoch 49/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2187 - accuracy: 0.0815 - val_loss: 2.2096 - val_accuracy: 0.0972\n",
    "Epoch 50/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2150 - accuracy: 0.0941 - val_loss: 2.2234 - val_accuracy: 0.0972\n",
    "Epoch 51/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2266 - accuracy: 0.1096 - val_loss: 2.2280 - val_accuracy: 0.0972\n",
    "Epoch 52/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1158 - val_loss: 2.2386 - val_accuracy: 0.1042\n",
    "Epoch 53/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1913 - accuracy: 0.1208 - val_loss: 2.2240 - val_accuracy: 0.0833\n",
    "Epoch 54/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2207 - accuracy: 0.1214 - val_loss: 2.2361 - val_accuracy: 0.0694\n",
    "Epoch 55/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2211 - accuracy: 0.1116 - val_loss: 2.2234 - val_accuracy: 0.0764\n",
    "Epoch 56/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2008 - accuracy: 0.1163 - val_loss: 2.2259 - val_accuracy: 0.0833\n",
    "Epoch 57/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2144 - accuracy: 0.1285 - val_loss: 2.2087 - val_accuracy: 0.0694\n",
    "Epoch 58/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2139 - accuracy: 0.1101 - val_loss: 2.2279 - val_accuracy: 0.0764\n",
    "Epoch 59/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2055 - accuracy: 0.1329 - val_loss: 2.2326 - val_accuracy: 0.0833\n",
    "Epoch 60/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2219 - accuracy: 0.1150 - val_loss: 2.2264 - val_accuracy: 0.0764\n",
    "Epoch 61/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2016 - accuracy: 0.1195 - val_loss: 2.2306 - val_accuracy: 0.1181\n",
    "Epoch 62/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2061 - accuracy: 0.1130 - val_loss: 2.2219 - val_accuracy: 0.0903\n",
    "Epoch 63/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2049 - accuracy: 0.0942 - val_loss: 2.2204 - val_accuracy: 0.0694\n",
    "Epoch 64/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2009 - accuracy: 0.1392 - val_loss: 2.2114 - val_accuracy: 0.1042\n",
    "Epoch 65/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1985 - accuracy: 0.1126 - val_loss: 2.2244 - val_accuracy: 0.0972\n",
    "Epoch 66/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2013 - accuracy: 0.1203 - val_loss: 2.2218 - val_accuracy: 0.0694\n",
    "Epoch 67/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2029 - accuracy: 0.1088 - val_loss: 2.2379 - val_accuracy: 0.0972\n",
    "Epoch 68/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1988 - accuracy: 0.1366 - val_loss: 2.2373 - val_accuracy: 0.0694\n",
    "Epoch 69/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1145 - val_loss: 2.2114 - val_accuracy: 0.1042\n",
    "Epoch 70/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1903 - accuracy: 0.1323 - val_loss: 2.2194 - val_accuracy: 0.0625\n",
    "Epoch 71/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2051 - accuracy: 0.1175 - val_loss: 2.2248 - val_accuracy: 0.0694\n",
    "Epoch 72/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2093 - accuracy: 0.1335 - val_loss: 2.2302 - val_accuracy: 0.0833\n",
    "Epoch 73/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2095 - accuracy: 0.1224 - val_loss: 2.2243 - val_accuracy: 0.0903\n",
    "Epoch 74/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2095 - accuracy: 0.1097 - val_loss: 2.2243 - val_accuracy: 0.1042\n",
    "Epoch 75/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1978 - accuracy: 0.1397 - val_loss: 2.2404 - val_accuracy: 0.0972\n",
    "Epoch 76/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2041 - accuracy: 0.1221 - val_loss: 2.2183 - val_accuracy: 0.0903\n",
    "Epoch 77/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1999 - accuracy: 0.1319 - val_loss: 2.2491 - val_accuracy: 0.0972\n",
    "Epoch 78/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2061 - accuracy: 0.0819 - val_loss: 2.2459 - val_accuracy: 0.0764\n",
    "Epoch 79/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2034 - accuracy: 0.1231 - val_loss: 2.2541 - val_accuracy: 0.0833\n",
    "Epoch 80/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2109 - accuracy: 0.1267 - val_loss: 2.2541 - val_accuracy: 0.1181\n",
    "Epoch 81/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1995 - accuracy: 0.1392 - val_loss: 2.2727 - val_accuracy: 0.0625\n",
    "Epoch 82/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2000 - accuracy: 0.1277 - val_loss: 2.2694 - val_accuracy: 0.0556\n",
    "Epoch 83/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1976 - accuracy: 0.1372 - val_loss: 3.5660 - val_accuracy: 0.0833\n",
    "Epoch 84/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1264 - val_loss: 5.0851 - val_accuracy: 0.0903\n",
    "Epoch 85/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2018 - accuracy: 0.1271 - val_loss: 4.9577 - val_accuracy: 0.0903\n",
    "Epoch 86/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1923 - accuracy: 0.1128 - val_loss: 5.6557 - val_accuracy: 0.0833\n",
    "Epoch 87/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1823 - accuracy: 0.1488 - val_loss: 4.4820 - val_accuracy: 0.0903\n",
    "Epoch 88/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2068 - accuracy: 0.1012 - val_loss: 4.2802 - val_accuracy: 0.1042\n",
    "Epoch 89/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1032 - val_loss: 3.7259 - val_accuracy: 0.0903\n",
    "Epoch 90/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1386 - val_loss: 4.8483 - val_accuracy: 0.0764\n",
    "Epoch 91/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1991 - accuracy: 0.1206 - val_loss: 4.4317 - val_accuracy: 0.1111\n",
    "Epoch 92/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1996 - accuracy: 0.1114 - val_loss: 4.9809 - val_accuracy: 0.0833\n",
    "Epoch 93/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1414 - val_loss: 3.9746 - val_accuracy: 0.0833\n",
    "Epoch 94/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2128 - accuracy: 0.0990 - val_loss: 4.2029 - val_accuracy: 0.1111\n",
    "Epoch 95/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1994 - accuracy: 0.1112 - val_loss: 5.4607 - val_accuracy: 0.0625\n",
    "Epoch 96/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1507 - val_loss: 3.9700 - val_accuracy: 0.1181\n",
    "Epoch 97/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.2056 - accuracy: 0.1134 - val_loss: 4.9989 - val_accuracy: 0.0625\n",
    "Accuracy: 0.0944, Loss: 2.2133\n",
    "\n",
    "spectral_contrast - Mean Accuracy: 0.0978 ± 0.0139\n",
    "\n",
    "==================================================\n",
    "Training model for tonnetz\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "tonnetz Folds: 100%\n",
    " 5/5 [00:31<00:00,  6.38s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 6, 128, 1) y shape: (32, 9)\n",
    "X min/max: -0.9690126354224912 0.94446836510906\n",
    "y (class distribution in batch): [3. 5. 3. 6. 4. 2. 2. 3. 4.]\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "First label (class index): 8\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "2    69\n",
    "6    68\n",
    "9    66\n",
    "5    66\n",
    "1    65\n",
    "3    59\n",
    "7    57\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1972 - accuracy: 0.1096 - val_loss: 2.1986 - val_accuracy: 0.0833\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1358 - val_loss: 2.1995 - val_accuracy: 0.0486\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.1527 - val_loss: 2.2004 - val_accuracy: 0.0486\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1179 - val_loss: 2.2011 - val_accuracy: 0.0486\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1267 - val_loss: 2.2020 - val_accuracy: 0.0486\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1407 - val_loss: 2.2030 - val_accuracy: 0.0486\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1207 - val_loss: 2.2037 - val_accuracy: 0.0486\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1301 - val_loss: 2.2045 - val_accuracy: 0.0486\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1274 - val_loss: 2.2052 - val_accuracy: 0.0486\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1139 - val_loss: 2.2061 - val_accuracy: 0.0486\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1920 - accuracy: 0.1463 - val_loss: 2.2070 - val_accuracy: 0.0486\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1125 - val_loss: 2.2076 - val_accuracy: 0.0486\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1292 - val_loss: 2.2084 - val_accuracy: 0.0486\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1906 - accuracy: 0.1819 - val_loss: 2.2093 - val_accuracy: 0.0486\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1238 - val_loss: 2.2098 - val_accuracy: 0.0486\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1913 - accuracy: 0.1444 - val_loss: 2.2103 - val_accuracy: 0.0486\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1249 - val_loss: 2.2105 - val_accuracy: 0.0486\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1451 - val_loss: 2.2111 - val_accuracy: 0.0486\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1178 - val_loss: 2.2117 - val_accuracy: 0.0486\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.0989 - val_loss: 2.2122 - val_accuracy: 0.0486\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1909 - accuracy: 0.1280 - val_loss: 2.2131 - val_accuracy: 0.0486\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1135 - val_loss: 2.2134 - val_accuracy: 0.0486\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1935 - accuracy: 0.1480 - val_loss: 2.2138 - val_accuracy: 0.0486\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.1336 - val_loss: 2.2144 - val_accuracy: 0.0486\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1932 - accuracy: 0.1074 - val_loss: 2.2147 - val_accuracy: 0.0486\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1903 - accuracy: 0.1381 - val_loss: 2.2156 - val_accuracy: 0.0486\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1896 - accuracy: 0.1452 - val_loss: 2.2159 - val_accuracy: 0.0486\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1145 - val_loss: 2.2161 - val_accuracy: 0.0486\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1917 - accuracy: 0.1243 - val_loss: 2.2165 - val_accuracy: 0.0486\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1918 - accuracy: 0.1353 - val_loss: 2.2170 - val_accuracy: 0.0486\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1947 - accuracy: 0.1280 - val_loss: 2.2172 - val_accuracy: 0.0486\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1918 - accuracy: 0.1344 - val_loss: 2.2175 - val_accuracy: 0.0486\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1881 - accuracy: 0.1425 - val_loss: 2.2183 - val_accuracy: 0.0486\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1223 - val_loss: 2.2182 - val_accuracy: 0.0486\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1913 - accuracy: 0.1160 - val_loss: 2.2187 - val_accuracy: 0.0486\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1980 - accuracy: 0.1291 - val_loss: 2.2187 - val_accuracy: 0.0486\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1920 - accuracy: 0.1319 - val_loss: 2.2191 - val_accuracy: 0.0486\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1915 - accuracy: 0.1365 - val_loss: 2.2196 - val_accuracy: 0.0486\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1885 - accuracy: 0.1486 - val_loss: 2.2199 - val_accuracy: 0.0486\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.1127 - val_loss: 2.2201 - val_accuracy: 0.0486\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1907 - accuracy: 0.1214 - val_loss: 2.2203 - val_accuracy: 0.0486\n",
    "Accuracy: 0.1111, Loss: 2.1976\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 6, 128, 1) y shape: (32, 9)\n",
    "X min/max: -0.8960385653772394 0.9185015190159901\n",
    "y (class distribution in batch): [3. 7. 2. 3. 1. 1. 4. 5. 6.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    "First label (class index): 6\n",
    "Label distribution in train_df: instrumentID\n",
    "3    70\n",
    "6    69\n",
    "1    69\n",
    "4    66\n",
    "7    64\n",
    "2    63\n",
    "9    63\n",
    "8    63\n",
    "5    49\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.1064 - val_loss: 2.1971 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.0941 - val_loss: 2.1975 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1272 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1382 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1098 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1287 - val_loss: 2.1983 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1182 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1316 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1143 - val_loss: 2.1992 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1073 - val_loss: 2.1993 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1465 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1237 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1285 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1279 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1143 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1944 - accuracy: 0.1181 - val_loss: 2.2008 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1416 - val_loss: 2.2010 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1212 - val_loss: 2.2013 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1412 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1283 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1072 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1175 - val_loss: 2.2020 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1207 - val_loss: 2.2021 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1233 - val_loss: 2.2023 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1221 - val_loss: 2.2025 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1156 - val_loss: 2.2026 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1933 - accuracy: 0.1183 - val_loss: 2.2028 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1118 - val_loss: 2.2031 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1109 - val_loss: 2.2033 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1911 - accuracy: 0.1293 - val_loss: 2.2034 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1919 - accuracy: 0.1284 - val_loss: 2.2037 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1922 - accuracy: 0.1211 - val_loss: 2.2038 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1193 - val_loss: 2.2037 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1911 - accuracy: 0.1360 - val_loss: 2.2040 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1935 - accuracy: 0.1003 - val_loss: 2.2042 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1353 - val_loss: 2.2044 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1898 - accuracy: 0.1356 - val_loss: 2.2047 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1300 - val_loss: 2.2046 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1902 - accuracy: 0.1307 - val_loss: 2.2047 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1904 - accuracy: 0.0967 - val_loss: 2.2048 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1189 - val_loss: 2.2049 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0944, Loss: 2.1984\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 6, 128, 1) y shape: (32, 9)\n",
    "X min/max: -0.9395068660378456 0.938642525463365\n",
    "y (class distribution in batch): [4. 5. 2. 0. 4. 4. 2. 7. 4.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "First label (class index): 7\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "8    67\n",
    "2    67\n",
    "1    65\n",
    "9    63\n",
    "6    63\n",
    "5    62\n",
    "7    59\n",
    "3    58\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0995 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1282 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1041 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1166 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1251 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1315 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1294 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1144 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1351 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1036 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1174 - val_loss: 2.1992 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1216 - val_loss: 2.1994 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1181 - val_loss: 2.1994 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1204 - val_loss: 2.1996 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1059 - val_loss: 2.1996 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1194 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1171 - val_loss: 2.2001 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1357 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1140 - val_loss: 2.2004 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1259 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1430 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1389 - val_loss: 2.2008 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1075 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1221 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1601 - val_loss: 2.2011 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1235 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1299 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1164 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1227 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1937 - accuracy: 0.1429 - val_loss: 2.2017 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1428 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1596 - val_loss: 2.2018 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1938 - accuracy: 0.1397 - val_loss: 2.2019 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1279 - val_loss: 2.2020 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1926 - accuracy: 0.1565 - val_loss: 2.2020 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1335 - val_loss: 2.2022 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1289 - val_loss: 2.2022 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1539 - val_loss: 2.2022 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1399 - val_loss: 2.2024 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1210 - val_loss: 2.2024 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1973 - accuracy: 0.1165 - val_loss: 2.2025 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0778, Loss: 2.1976\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 6, 128, 1) y shape: (32, 9)\n",
    "X min/max: -0.9523786503705196 0.9082093810417841\n",
    "y (class distribution in batch): [2. 5. 3. 7. 2. 2. 5. 1. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 2\n",
    "Label distribution in train_df: instrumentID\n",
    "2    69\n",
    "7    68\n",
    "3    66\n",
    "8    65\n",
    "1    65\n",
    "5    64\n",
    "6    61\n",
    "4    60\n",
    "9    58\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.1122 - val_loss: 2.1977 - val_accuracy: 0.0764\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1070 - val_loss: 2.1976 - val_accuracy: 0.0625\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1416 - val_loss: 2.1978 - val_accuracy: 0.0625\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1161 - val_loss: 2.1977 - val_accuracy: 0.0625\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1252 - val_loss: 2.1979 - val_accuracy: 0.0625\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1197 - val_loss: 2.1980 - val_accuracy: 0.0625\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1058 - val_loss: 2.1980 - val_accuracy: 0.0625\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1083 - val_loss: 2.1980 - val_accuracy: 0.0625\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1313 - val_loss: 2.1981 - val_accuracy: 0.0625\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 14ms/step - loss: 2.1963 - accuracy: 0.1020 - val_loss: 2.1982 - val_accuracy: 0.0625\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.0998 - val_loss: 2.1982 - val_accuracy: 0.0625\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1213 - val_loss: 2.1983 - val_accuracy: 0.0625\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1203 - val_loss: 2.1985 - val_accuracy: 0.0625\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1106 - val_loss: 2.1983 - val_accuracy: 0.0625\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1978 - accuracy: 0.1177 - val_loss: 2.1985 - val_accuracy: 0.0625\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1316 - val_loss: 2.1988 - val_accuracy: 0.0625\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1199 - val_loss: 2.1987 - val_accuracy: 0.0625\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1203 - val_loss: 2.1987 - val_accuracy: 0.0625\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1239 - val_loss: 2.1987 - val_accuracy: 0.0625\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1092 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1950 - accuracy: 0.1298 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1089 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1165 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1238 - val_loss: 2.1992 - val_accuracy: 0.0625\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1193 - val_loss: 2.1993 - val_accuracy: 0.0625\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1095 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1192 - val_loss: 2.1992 - val_accuracy: 0.0625\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1978 - accuracy: 0.1056 - val_loss: 2.1991 - val_accuracy: 0.0625\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1346 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1318 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1224 - val_loss: 2.1997 - val_accuracy: 0.0625\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1066 - val_loss: 2.1997 - val_accuracy: 0.0625\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1219 - val_loss: 2.1996 - val_accuracy: 0.0625\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1305 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1172 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1153 - val_loss: 2.1998 - val_accuracy: 0.0625\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1275 - val_loss: 2.1998 - val_accuracy: 0.0625\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1038 - val_loss: 2.1998 - val_accuracy: 0.0625\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1955 - accuracy: 0.1192 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1975 - accuracy: 0.1206 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1349 - val_loss: 2.2001 - val_accuracy: 0.0625\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1041 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Accuracy: 0.1222, Loss: 2.1976\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 6, 128, 1) y shape: (32, 9)\n",
    "X min/max: -0.9187869007000702 0.9420621856115758\n",
    "y (class distribution in batch): [4. 2. 6. 5. 3. 3. 4. 4. 1.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 0\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "6    71\n",
    "2    69\n",
    "3    68\n",
    "5    67\n",
    "9    62\n",
    "1    58\n",
    "7    56\n",
    "8    53\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0931 - val_loss: 2.1979 - val_accuracy: 0.0764\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.0980 - val_loss: 2.1986 - val_accuracy: 0.0764\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.0893 - val_loss: 2.1992 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1116 - val_loss: 2.1999 - val_accuracy: 0.0764\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1116 - val_loss: 2.2006 - val_accuracy: 0.0764\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1265 - val_loss: 2.2013 - val_accuracy: 0.0764\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1968 - accuracy: 0.1347 - val_loss: 2.2019 - val_accuracy: 0.0764\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1947 - accuracy: 0.1202 - val_loss: 2.2026 - val_accuracy: 0.0764\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1091 - val_loss: 2.2032 - val_accuracy: 0.0764\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1114 - val_loss: 2.2037 - val_accuracy: 0.0764\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1299 - val_loss: 2.2044 - val_accuracy: 0.0764\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1286 - val_loss: 2.2051 - val_accuracy: 0.0764\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1918 - accuracy: 0.1403 - val_loss: 2.2057 - val_accuracy: 0.0764\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1293 - val_loss: 2.2061 - val_accuracy: 0.0764\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1384 - val_loss: 2.2067 - val_accuracy: 0.0764\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1149 - val_loss: 2.2071 - val_accuracy: 0.0764\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1260 - val_loss: 2.2076 - val_accuracy: 0.0764\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1068 - val_loss: 2.2082 - val_accuracy: 0.0764\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1931 - accuracy: 0.1369 - val_loss: 2.2087 - val_accuracy: 0.0764\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1129 - val_loss: 2.2091 - val_accuracy: 0.0764\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1927 - accuracy: 0.1268 - val_loss: 2.2098 - val_accuracy: 0.0764\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1125 - val_loss: 2.2101 - val_accuracy: 0.0764\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1123 - val_loss: 2.2106 - val_accuracy: 0.0764\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1909 - accuracy: 0.1144 - val_loss: 2.2109 - val_accuracy: 0.0764\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1896 - accuracy: 0.1253 - val_loss: 2.2115 - val_accuracy: 0.0764\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1897 - accuracy: 0.1313 - val_loss: 2.2118 - val_accuracy: 0.0764\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1276 - val_loss: 2.2120 - val_accuracy: 0.0764\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1954 - accuracy: 0.1247 - val_loss: 2.2124 - val_accuracy: 0.0764\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1052 - val_loss: 2.2129 - val_accuracy: 0.0764\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1116 - val_loss: 2.2131 - val_accuracy: 0.0764\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1915 - accuracy: 0.1288 - val_loss: 2.2135 - val_accuracy: 0.0764\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1197 - val_loss: 2.2138 - val_accuracy: 0.0764\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1952 - accuracy: 0.1250 - val_loss: 2.2142 - val_accuracy: 0.0764\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1090 - val_loss: 2.2145 - val_accuracy: 0.0764\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1910 - accuracy: 0.1342 - val_loss: 2.2149 - val_accuracy: 0.0764\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1915 - accuracy: 0.1130 - val_loss: 2.2152 - val_accuracy: 0.0764\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1938 - accuracy: 0.1233 - val_loss: 2.2154 - val_accuracy: 0.0764\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1907 - accuracy: 0.1573 - val_loss: 2.2156 - val_accuracy: 0.0764\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1189 - val_loss: 2.2159 - val_accuracy: 0.0764\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1165 - val_loss: 2.2160 - val_accuracy: 0.0764\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1928 - accuracy: 0.1290 - val_loss: 2.2164 - val_accuracy: 0.0764\n",
    "Accuracy: 0.0944, Loss: 2.1981\n",
    "\n",
    "tonnetz - Mean Accuracy: 0.1000 ± 0.0153\n",
    "\n",
    "==================================================\n",
    "Training model for constant_q\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "constant_q Folds: 100%\n",
    " 5/5 [00:32<00:00,  6.53s/it]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 42, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 9.536743e-07\n",
    "y (class distribution in batch): [2. 6. 3. 2. 3. 3. 4. 3. 6.]\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    "First label (class index): 5\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "2    69\n",
    "6    68\n",
    "9    66\n",
    "5    65\n",
    "1    65\n",
    "3    58\n",
    "7    57\n",
    "8    55\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.2918 - accuracy: 0.1040 - val_loss: 2.1991 - val_accuracy: 0.1250\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1232 - val_loss: 2.2006 - val_accuracy: 0.1250\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1328 - val_loss: 2.2028 - val_accuracy: 0.1250\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1075 - val_loss: 2.2045 - val_accuracy: 0.0764\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1285 - val_loss: 2.2053 - val_accuracy: 0.0486\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1942 - accuracy: 0.1275 - val_loss: 2.2078 - val_accuracy: 0.0486\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1258 - val_loss: 2.2084 - val_accuracy: 0.0486\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1916 - accuracy: 0.1295 - val_loss: 2.2114 - val_accuracy: 0.0486\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1314 - val_loss: 2.2110 - val_accuracy: 0.0486\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1987 - accuracy: 0.1066 - val_loss: 2.2093 - val_accuracy: 0.0486\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1114 - val_loss: 2.2098 - val_accuracy: 0.0486\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1244 - val_loss: 2.2117 - val_accuracy: 0.0486\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1045 - val_loss: 2.2130 - val_accuracy: 0.0486\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1925 - accuracy: 0.1348 - val_loss: 2.2135 - val_accuracy: 0.0486\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1261 - val_loss: 2.2139 - val_accuracy: 0.0486\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1955 - accuracy: 0.1277 - val_loss: 2.2163 - val_accuracy: 0.0486\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1918 - accuracy: 0.1398 - val_loss: 2.2175 - val_accuracy: 0.0486\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1252 - val_loss: 2.2186 - val_accuracy: 0.0486\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1492 - val_loss: 2.2184 - val_accuracy: 0.0486\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1992 - accuracy: 0.0989 - val_loss: 2.2184 - val_accuracy: 0.0486\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1913 - accuracy: 0.1236 - val_loss: 2.2191 - val_accuracy: 0.0486\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.2004 - accuracy: 0.0994 - val_loss: 2.2177 - val_accuracy: 0.0486\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1980 - accuracy: 0.1364 - val_loss: 2.2189 - val_accuracy: 0.0486\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1415 - val_loss: 2.2203 - val_accuracy: 0.0486\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1301 - val_loss: 2.2206 - val_accuracy: 0.0486\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1149 - val_loss: 2.2212 - val_accuracy: 0.0486\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1334 - val_loss: 2.2227 - val_accuracy: 0.0486\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1203 - val_loss: 2.2218 - val_accuracy: 0.0486\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1315 - val_loss: 2.2217 - val_accuracy: 0.0486\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1950 - accuracy: 0.1237 - val_loss: 2.2215 - val_accuracy: 0.0486\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1921 - accuracy: 0.1677 - val_loss: 2.2223 - val_accuracy: 0.0486\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1302 - val_loss: 2.2227 - val_accuracy: 0.0486\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1942 - accuracy: 0.1316 - val_loss: 2.2228 - val_accuracy: 0.0486\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1899 - accuracy: 0.1456 - val_loss: 2.2234 - val_accuracy: 0.0486\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1923 - accuracy: 0.1259 - val_loss: 2.2219 - val_accuracy: 0.0486\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1381 - val_loss: 2.2203 - val_accuracy: 0.0486\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1416 - val_loss: 2.2213 - val_accuracy: 0.0486\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1913 - accuracy: 0.1235 - val_loss: 2.2207 - val_accuracy: 0.0486\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1938 - accuracy: 0.1073 - val_loss: 2.2204 - val_accuracy: 0.0486\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1170 - val_loss: 2.2204 - val_accuracy: 0.0486\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1931 - accuracy: 0.1086 - val_loss: 2.2218 - val_accuracy: 0.0486\n",
    "Accuracy: 0.0889, Loss: 2.1987\n",
    "\n",
    "--- Fold 2/5 ---\n",
    "X shape: (32, 42, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [3. 4. 3. 6. 1. 4. 3. 3. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
    "First label (class index): 6\n",
    "Label distribution in train_df: instrumentID\n",
    "6    69\n",
    "1    69\n",
    "3    68\n",
    "4    66\n",
    "2    64\n",
    "7    64\n",
    "9    63\n",
    "8    57\n",
    "5    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0976 - val_loss: 2.1972 - val_accuracy: 0.1458\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1296 - val_loss: 2.1973 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1317 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1147 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.1433 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1276 - val_loss: 2.1981 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1233 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1242 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1439 - val_loss: 2.1989 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.0806 - val_loss: 2.1990 - val_accuracy: 0.1250\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1314 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1087 - val_loss: 2.1994 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1309 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1193 - val_loss: 2.1998 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1249 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1293 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1945 - accuracy: 0.1332 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1064 - val_loss: 2.2003 - val_accuracy: 0.1250\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1083 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1127 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1199 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1251 - val_loss: 2.2011 - val_accuracy: 0.1250\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.0964 - val_loss: 2.2012 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.0969 - val_loss: 2.2013 - val_accuracy: 0.1250\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1016 - val_loss: 2.2014 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1292 - val_loss: 2.2015 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1174 - val_loss: 2.2016 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1136 - val_loss: 2.2017 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1344 - val_loss: 2.2020 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1178 - val_loss: 2.2020 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1106 - val_loss: 2.2022 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.0998 - val_loss: 2.2023 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1202 - val_loss: 2.2024 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1147 - val_loss: 2.2024 - val_accuracy: 0.1250\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1133 - val_loss: 2.2025 - val_accuracy: 0.1250\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1044 - val_loss: 2.2027 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1280 - val_loss: 2.2027 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1142 - val_loss: 2.2028 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1076 - val_loss: 2.2030 - val_accuracy: 0.1250\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1984 - accuracy: 0.1114 - val_loss: 2.2031 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1150 - val_loss: 2.2032 - val_accuracy: 0.0972\n",
    "Accuracy: 0.0833, Loss: 2.1976\n",
    "\n",
    "--- Fold 3/5 ---\n",
    "X shape: (32, 42, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 4.7683716e-07\n",
    "y (class distribution in batch): [2. 7. 2. 3. 3. 2. 5. 3. 5.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
    "First label (class index): 4\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "2    66\n",
    "5    65\n",
    "1    64\n",
    "9    63\n",
    "6    63\n",
    "8    62\n",
    "7    60\n",
    "3    60\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0916 - val_loss: 2.1974 - val_accuracy: 0.1181\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.0992 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1130 - val_loss: 2.1976 - val_accuracy: 0.0972\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1971 - accuracy: 0.1253 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1414 - val_loss: 2.1979 - val_accuracy: 0.0972\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1420 - val_loss: 2.1980 - val_accuracy: 0.0972\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1435 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1250 - val_loss: 2.1983 - val_accuracy: 0.0972\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1344 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1974 - accuracy: 0.1098 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1214 - val_loss: 2.1985 - val_accuracy: 0.0972\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1449 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1491 - val_loss: 2.1987 - val_accuracy: 0.0972\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1967 - accuracy: 0.1185 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1166 - val_loss: 2.1989 - val_accuracy: 0.0972\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1216 - val_loss: 2.1990 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1978 - accuracy: 0.1217 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1472 - val_loss: 2.1993 - val_accuracy: 0.0972\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1208 - val_loss: 2.1993 - val_accuracy: 0.0972\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1134 - val_loss: 2.1993 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1126 - val_loss: 2.1995 - val_accuracy: 0.0972\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1341 - val_loss: 2.1996 - val_accuracy: 0.0972\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1403 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1139 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1244 - val_loss: 2.1998 - val_accuracy: 0.0972\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1244 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1310 - val_loss: 2.1999 - val_accuracy: 0.0972\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1142 - val_loss: 2.2000 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1246 - val_loss: 2.2001 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1083 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1334 - val_loss: 2.2002 - val_accuracy: 0.0972\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1342 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1204 - val_loss: 2.2003 - val_accuracy: 0.0972\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1937 - accuracy: 0.1379 - val_loss: 2.2004 - val_accuracy: 0.0972\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1161 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1296 - val_loss: 2.2005 - val_accuracy: 0.0972\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1294 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1351 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1130 - val_loss: 2.2006 - val_accuracy: 0.0972\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1562 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1445 - val_loss: 2.2007 - val_accuracy: 0.0972\n",
    "Accuracy: 0.1000, Loss: 2.1974\n",
    "\n",
    "--- Fold 4/5 ---\n",
    "X shape: (32, 42, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [1. 2. 3. 6. 7. 3. 3. 3. 4.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 3\n",
    "Label distribution in train_df: instrumentID\n",
    "7    68\n",
    "3    68\n",
    "2    68\n",
    "1    66\n",
    "8    65\n",
    "5    63\n",
    "6    61\n",
    "4    59\n",
    "9    58\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.0844 - val_loss: 2.1973 - val_accuracy: 0.1458\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1202 - val_loss: 2.1973 - val_accuracy: 0.1458\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1185 - val_loss: 2.1975 - val_accuracy: 0.1458\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1351 - val_loss: 2.1977 - val_accuracy: 0.0972\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1236 - val_loss: 2.1978 - val_accuracy: 0.0625\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1013 - val_loss: 2.1980 - val_accuracy: 0.0625\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1973 - accuracy: 0.1065 - val_loss: 2.1980 - val_accuracy: 0.0972\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1080 - val_loss: 2.1980 - val_accuracy: 0.1458\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1965 - accuracy: 0.1037 - val_loss: 2.1982 - val_accuracy: 0.0972\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1972 - accuracy: 0.1145 - val_loss: 2.1983 - val_accuracy: 0.0625\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1142 - val_loss: 2.1984 - val_accuracy: 0.0625\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1190 - val_loss: 2.1984 - val_accuracy: 0.0972\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1133 - val_loss: 2.1985 - val_accuracy: 0.0625\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1017 - val_loss: 2.1986 - val_accuracy: 0.0972\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1109 - val_loss: 2.1988 - val_accuracy: 0.0625\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.0900 - val_loss: 2.1988 - val_accuracy: 0.0972\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1055 - val_loss: 2.1988 - val_accuracy: 0.0625\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1169 - val_loss: 2.1989 - val_accuracy: 0.1458\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1159 - val_loss: 2.1990 - val_accuracy: 0.1458\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1976 - accuracy: 0.1014 - val_loss: 2.1991 - val_accuracy: 0.0972\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1976 - accuracy: 0.1083 - val_loss: 2.1989 - val_accuracy: 0.1458\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1208 - val_loss: 2.1992 - val_accuracy: 0.1458\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1195 - val_loss: 2.1993 - val_accuracy: 0.0972\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1212 - val_loss: 2.1994 - val_accuracy: 0.1458\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1032 - val_loss: 2.1995 - val_accuracy: 0.1458\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1975 - accuracy: 0.1157 - val_loss: 2.1994 - val_accuracy: 0.1458\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1304 - val_loss: 2.1997 - val_accuracy: 0.1458\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1165 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1950 - accuracy: 0.0805 - val_loss: 2.1997 - val_accuracy: 0.0972\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1057 - val_loss: 2.1999 - val_accuracy: 0.0625\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1972 - accuracy: 0.1048 - val_loss: 2.1997 - val_accuracy: 0.1458\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.0970 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1350 - val_loss: 2.2000 - val_accuracy: 0.0625\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1069 - val_loss: 2.2000 - val_accuracy: 0.1458\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1182 - val_loss: 2.2000 - val_accuracy: 0.1458\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1970 - accuracy: 0.1239 - val_loss: 2.2001 - val_accuracy: 0.1458\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1144 - val_loss: 2.2000 - val_accuracy: 0.1458\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.0993 - val_loss: 2.2001 - val_accuracy: 0.0972\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1940 - accuracy: 0.1124 - val_loss: 2.2003 - val_accuracy: 0.1458\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1959 - accuracy: 0.1233 - val_loss: 2.2004 - val_accuracy: 0.0625\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1081 - val_loss: 2.2004 - val_accuracy: 0.1458\n",
    "Epoch 42/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1121 - val_loss: 2.2004 - val_accuracy: 0.1458\n",
    "Accuracy: 0.0611, Loss: 2.1980\n",
    "\n",
    "--- Fold 5/5 ---\n",
    "X shape: (32, 42, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 1.9073486e-06\n",
    "y (class distribution in batch): [3. 2. 2. 5. 3. 2. 4. 7. 4.]\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "First label (one-hot): [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
    "First label (class index): 7\n",
    "Label distribution in train_df: instrumentID\n",
    "4    72\n",
    "6    71\n",
    "2    68\n",
    "5    67\n",
    "3    65\n",
    "9    62\n",
    "1    58\n",
    "8    57\n",
    "7    56\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.1176 - val_loss: 2.1976 - val_accuracy: 0.0903\n",
    "Epoch 2/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1267 - val_loss: 2.1982 - val_accuracy: 0.0903\n",
    "Epoch 3/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1166 - val_loss: 2.1985 - val_accuracy: 0.0903\n",
    "Epoch 4/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1242 - val_loss: 2.1990 - val_accuracy: 0.0903\n",
    "Epoch 5/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1975 - accuracy: 0.1203 - val_loss: 2.1993 - val_accuracy: 0.0903\n",
    "Epoch 6/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1961 - accuracy: 0.1301 - val_loss: 2.1997 - val_accuracy: 0.0903\n",
    "Epoch 7/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1412 - val_loss: 2.2002 - val_accuracy: 0.0903\n",
    "Epoch 8/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1079 - val_loss: 2.2004 - val_accuracy: 0.0903\n",
    "Epoch 9/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1964 - accuracy: 0.1255 - val_loss: 2.2008 - val_accuracy: 0.0903\n",
    "Epoch 10/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1144 - val_loss: 2.2012 - val_accuracy: 0.0903\n",
    "Epoch 11/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.0884 - val_loss: 2.2014 - val_accuracy: 0.0903\n",
    "Epoch 12/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1942 - accuracy: 0.1201 - val_loss: 2.2019 - val_accuracy: 0.0903\n",
    "Epoch 13/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.0918 - val_loss: 2.2021 - val_accuracy: 0.0764\n",
    "Epoch 14/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1966 - accuracy: 0.1304 - val_loss: 2.2025 - val_accuracy: 0.0903\n",
    "Epoch 15/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1127 - val_loss: 2.2029 - val_accuracy: 0.0903\n",
    "Epoch 16/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1347 - val_loss: 2.2032 - val_accuracy: 0.0903\n",
    "Epoch 17/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1187 - val_loss: 2.2034 - val_accuracy: 0.0903\n",
    "Epoch 18/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1051 - val_loss: 2.2037 - val_accuracy: 0.0903\n",
    "Epoch 19/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1289 - val_loss: 2.2041 - val_accuracy: 0.0903\n",
    "Epoch 20/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1212 - val_loss: 2.2044 - val_accuracy: 0.0903\n",
    "Epoch 21/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1925 - accuracy: 0.1276 - val_loss: 2.2047 - val_accuracy: 0.0764\n",
    "Epoch 22/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1957 - accuracy: 0.1298 - val_loss: 2.2049 - val_accuracy: 0.0764\n",
    "Epoch 23/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1923 - accuracy: 0.1243 - val_loss: 2.2052 - val_accuracy: 0.0764\n",
    "Epoch 24/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1921 - accuracy: 0.1299 - val_loss: 2.2054 - val_accuracy: 0.0764\n",
    "Epoch 25/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1945 - accuracy: 0.1238 - val_loss: 2.2055 - val_accuracy: 0.0764\n",
    "Epoch 26/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1971 - accuracy: 0.1212 - val_loss: 2.2056 - val_accuracy: 0.0764\n",
    "Epoch 27/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1956 - accuracy: 0.1162 - val_loss: 2.2060 - val_accuracy: 0.0764\n",
    "Epoch 28/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1357 - val_loss: 2.2064 - val_accuracy: 0.0764\n",
    "Epoch 29/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1196 - val_loss: 2.2064 - val_accuracy: 0.0764\n",
    "Epoch 30/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1934 - accuracy: 0.1224 - val_loss: 2.2066 - val_accuracy: 0.0764\n",
    "Epoch 31/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1931 - accuracy: 0.1266 - val_loss: 2.2069 - val_accuracy: 0.0764\n",
    "Epoch 32/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1878 - accuracy: 0.1283 - val_loss: 2.2072 - val_accuracy: 0.0764\n",
    "Epoch 33/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1923 - accuracy: 0.1285 - val_loss: 2.2073 - val_accuracy: 0.0764\n",
    "Epoch 34/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1359 - val_loss: 2.2075 - val_accuracy: 0.0764\n",
    "Epoch 35/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1936 - accuracy: 0.1206 - val_loss: 2.2076 - val_accuracy: 0.0764\n",
    "Epoch 36/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1454 - val_loss: 2.2078 - val_accuracy: 0.0764\n",
    "Epoch 37/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1167 - val_loss: 2.2079 - val_accuracy: 0.0764\n",
    "Epoch 38/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1233 - val_loss: 2.2080 - val_accuracy: 0.0764\n",
    "Epoch 39/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1906 - accuracy: 0.1241 - val_loss: 2.2083 - val_accuracy: 0.0764\n",
    "Epoch 40/200\n",
    "18/18 [==============================] - 0s 8ms/step - loss: 2.1934 - accuracy: 0.1193 - val_loss: 2.2084 - val_accuracy: 0.0764\n",
    "Epoch 41/200\n",
    "18/18 [==============================] - 0s 7ms/step - loss: 2.1908 - accuracy: 0.1373 - val_loss: 2.2085 - val_accuracy: 0.0764\n",
    "Accuracy: 0.0889, Loss: 2.1976\n",
    "\n",
    "constant_q - Mean Accuracy: 0.0844 ± 0.0129\n",
    "\n",
    "==================================================\n",
    "Training model for cqt\n",
    "==================================================\n",
    "\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, msg_start, len(result))\n",
    "\n",
    "cqt Folds:   0%\n",
    " 0/5 [00:00<?, ?it/s]\n",
    "\n",
    "\n",
    "--- Fold 1/5 ---\n",
    "X shape: (32, 84, 128, 1) y shape: (32, 9)\n",
    "X min/max: -80.0 9.536743e-07\n",
    "y (class distribution in batch): [4. 4. 1. 1. 3. 5. 3. 4. 7.]\n",
    "\n",
    "First label (one-hot): [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "First label (class index): 1\n",
    "Label distribution in train_df: instrumentID\n",
    "4    73\n",
    "2    69\n",
    "6    68\n",
    "9    66\n",
    "5    65\n",
    "1    65\n",
    "3    58\n",
    "7    57\n",
    "8    55\n",
    "Name: count, dtype: int64\n",
    "Any NaNs in X? False\n",
    "All X values the same? False\n",
    "Epoch 1/200\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "InvalidArgumentError                      Traceback (most recent call last)\n",
    "Cell In[8], line 89\n",
    "     84 early_stopping = EarlyStopping(\n",
    "     85     monitor=\"val_loss\", patience=40, restore_best_weights=True\n",
    "     86 )\n",
    "     88 # Train the model\n",
    "---> 89 history = model.fit(\n",
    "     90     train_generator,\n",
    "     91     validation_data=val_generator,\n",
    "     92     epochs=EPOCHS,\n",
    "     93     callbacks=[early_stopping],\n",
    "     94     verbose=1\n",
    "     95 )\n",
    "     97 feature_results['histories'].append(history.history)\n",
    "     99 # Evaluate the model\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100, in Model.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\n",
    "   1093 with trace.Trace(\n",
    "   1094     'train',\n",
    "   1095     epoch_num=epoch,\n",
    "   1096     step_num=step,\n",
    "   1097     batch_size=batch_size,\n",
    "   1098     _r=1):\n",
    "   1099   callbacks.on_train_batch_begin(step)\n",
    "-> 1100   tmp_logs = self.train_function(iterator)\n",
    "   1101   if data_handler.should_sync:\n",
    "   1102     context.async_wait()\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828, in Function.__call__(self, *args, **kwds)\n",
    "    826 tracing_count = self.experimental_get_tracing_count()\n",
    "    827 with trace.Trace(self._name) as tm:\n",
    "--> 828   result = self._call(*args, **kwds)\n",
    "    829   compiler = \"xla\" if self._experimental_compile else \"nonXla\"\n",
    "    830   new_tracing_count = self.experimental_get_tracing_count()\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:888, in Function._call(self, *args, **kwds)\n",
    "    884     pass  # Fall through to cond-based initialization.\n",
    "    885   else:\n",
    "    886     # Lifting succeeded, so variables are initialized and we can run the\n",
    "    887     # stateless function.\n",
    "--> 888     return self._stateless_fn(*args, **kwds)\n",
    "    889 else:\n",
    "    890   _, _, _, filtered_flat_args = \\\n",
    "    891       self._stateful_fn._function_spec.canonicalize_function_inputs(  # pylint: disable=protected-access\n",
    "    892           *args, **kwds)\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942, in Function.__call__(self, *args, **kwargs)\n",
    "   2939 with self._lock:\n",
    "   2940   (graph_function,\n",
    "   2941    filtered_flat_args) = self._maybe_define_function(args, kwargs)\n",
    "-> 2942 return graph_function._call_flat(\n",
    "   2943     filtered_flat_args, captured_inputs=graph_function.captured_inputs)\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918, in ConcreteFunction._call_flat(self, args, captured_inputs, cancellation_manager)\n",
    "   1914 possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n",
    "   1915 if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n",
    "   1916     and executing_eagerly):\n",
    "   1917   # No tape is watching; skip to running the function.\n",
    "-> 1918   return self._build_call_outputs(self._inference_function.call(\n",
    "   1919       ctx, args, cancellation_manager=cancellation_manager))\n",
    "   1920 forward_backward = self._select_forward_and_backward_functions(\n",
    "   1921     args,\n",
    "   1922     possible_gradient_type,\n",
    "   1923     executing_eagerly)\n",
    "   1924 forward_function, args_with_tangents = forward_backward.forward()\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555, in _EagerDefinedFunction.call(self, ctx, args, cancellation_manager)\n",
    "    553 with _InterpolateFunctionError(self):\n",
    "    554   if cancellation_manager is None:\n",
    "--> 555     outputs = execute.execute(\n",
    "    556         str(self.signature.name),\n",
    "    557         num_outputs=self._num_outputs,\n",
    "    558         inputs=args,\n",
    "    559         attrs=attrs,\n",
    "    560         ctx=ctx)\n",
    "    561   else:\n",
    "    562     outputs = execute.execute_with_cancellation(\n",
    "    563         str(self.signature.name),\n",
    "    564         num_outputs=self._num_outputs,\n",
    "   (...)\n",
    "    567         ctx=ctx,\n",
    "    568         cancellation_manager=cancellation_manager)\n",
    "\n",
    "File /opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\n",
    "     57 try:\n",
    "     58   ctx.ensure_initialized()\n",
    "---> 59   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
    "     60                                       inputs, attrs, num_outputs)\n",
    "     61 except core._NotOkStatusException as e:\n",
    "     62   if name is not None:\n",
    "\n",
    "InvalidArgumentError:  logits and labels must be broadcastable: logits_size=[64,9] labels_size=[32,9]\n",
    "\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at tmp/ipykernel_17869/2933601861.py:89) ]] [Op:__inference_train_function_150543]\n",
    "\n",
    "Function call stack:\n",
    "train_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble predictions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Ensemble Predictions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the last fold of each feature type for ensemble evaluation\n",
    "ensemble_results = {\n",
    "    'accuracy_list': [],\n",
    "    'loss_list': [],\n",
    "    'classification_reports': [],\n",
    "    'confusion_matrices': []\n",
    "}\n",
    "\n",
    "# For simplicity, we'll use the last fold of each feature type\n",
    "for fold in tqdm(range(KFOLD_SPLITS), desc = \"Ensemble Folds\", Leave = True):\n",
    "    print(f\"\\n--- Ensemble Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "    \n",
    "    # Get predictions from all models for this fold\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for feature_type in available_feature_types:\n",
    "        if feature_type in all_results:\n",
    "            # Get the model from this fold\n",
    "            model = all_results[feature_type]['models'][fold]\n",
    "            \n",
    "            # Get test data for this fold (we need to recreate it)\n",
    "            df = df_dict[feature_type]\n",
    "            kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "            train_idx, test_idx = list(kf.split(df))[fold]\n",
    "            test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "            \n",
    "            test_generator = SingleFeatureDataGenerator(test_df, feature_type, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred = model.predict(test_generator, verbose=0)\n",
    "            all_predictions[feature_type] = pred\n",
    "            \n",
    "            # Store true labels (should be the same for all feature types)\n",
    "            if 'y_true' not in locals():\n",
    "                y_true = test_generator.get_labels()\n",
    "    \n",
    "    # Simple averaging ensemble\n",
    "    if all_predictions:\n",
    "        ensemble_pred = np.mean(list(all_predictions.values()), axis=0)\n",
    "        ensemble_pred_classes = np.argmax(ensemble_pred, axis=1)\n",
    "        \n",
    "        # Calculate ensemble accuracy\n",
    "        ensemble_accuracy = accuracy_score(y_true, ensemble_pred_classes)\n",
    "        ensemble_results['accuracy_list'].append(ensemble_accuracy)\n",
    "        \n",
    "        print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_true, ensemble_pred_classes, output_dict=True)\n",
    "        ensemble_results['classification_reports'].append(report)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, ensemble_pred_classes).tolist()\n",
    "        ensemble_results['confusion_matrices'].append(conf_matrix)\n",
    "\n",
    "# Store ensemble results\n",
    "all_results['ensemble'] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and models\n",
    "try:\n",
    "    os.mkdir(\"ensemble_models\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists\")\n",
    "except Exception:\n",
    "    print(\"Unknown error\")\n",
    "\n",
    "# Create version folder\n",
    "date_part = datetime.now().date().__str__().replace('-', '_')\n",
    "last_version = os.listdir(path=\"ensemble_models\") if os.path.exists(\"ensemble_models\") else []\n",
    "last_version = [name.rpartition(\"_v\")[-1] for name in last_version if date_part in name]\n",
    "if len(last_version):\n",
    "    last_version = int(sorted(last_version)[-1])\n",
    "else:\n",
    "    last_version = 0\n",
    "folder_name = f\"{date_part}_v{last_version+1}\"\n",
    "\n",
    "os.makedirs(os.path.join(\"ensemble_models\", folder_name), exist_ok=True)\n",
    "\n",
    "# Save individual models\n",
    "for feature_type, model in all_models.items():\n",
    "    model_path = os.path.join(\"ensemble_models\", folder_name, f\"{feature_type}_model.h5\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Saved {feature_type} model to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "results_data = {\n",
    "    'individual_results': {ft: {k: v for k, v in res.items() if k != 'models'} \n",
    "                          for ft, res in all_results.items() if ft != 'ensemble'},\n",
    "    'ensemble_results': all_results['ensemble'],\n",
    "    'feature_types': available_feature_types,\n",
    "    'num_classes': num_classes,\n",
    "    'feature_shapes': FEATURE_SHAPES,\n",
    "    'training_config': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'kfold_splits': KFOLD_SPLITS,\n",
    "        'fixed_length': FIXED_LENGTH\n",
    "    },\n",
    "    'instrument_mappings': instruments_mappings.to_dict()\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"ensemble_models\", folder_name, \"results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_path}\")\n",
    "print(f\"Models saved to: ensemble_models/{folder_name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nIndividual Model Performance:\")\n",
    "for feature_type in available_feature_types:\n",
    "    if feature_type in all_results:\n",
    "        accuracies = all_results[feature_type]['accuracy_list']\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        print(f\"  {feature_type}: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble Performance:\")\n",
    "if 'ensemble' in all_results:\n",
    "    ensemble_accuracies = all_results['ensemble']['accuracy_list']\n",
    "    ensemble_mean = np.mean(ensemble_accuracies)\n",
    "    ensemble_std = np.std(ensemble_accuracies)\n",
    "    print(f\"  Ensemble: {ensemble_mean:.4f} ± {ensemble_std:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "best_individual = max(\n",
    "    [(ft, np.mean(all_results[ft]['accuracy_list'])) \n",
    "     for ft in available_feature_types if ft in all_results],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "improvement = ensemble_mean - best_individual[1]\n",
    "print(f\"\\nBest Individual Model: {best_individual[0]} ({best_individual[1]:.4f})\")\n",
    "print(f\"Ensemble Improvement: {improvement:.4f} ({improvement*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
