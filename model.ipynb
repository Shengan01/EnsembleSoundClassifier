{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Training - Simplified Single-Branch Models\n",
    "\n",
    "This notebook trains separate simplified CNN models for each feature type and then creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 18:04:21.014326: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-07 18:04:21.174242: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-07 18:04:21.174318: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-07 18:04:21.198741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-07 18:04:21.250971: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-07 18:04:21.702372: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from modules.PostgresDBHandler import PostgresDBHandler\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-07 18:04:22.658424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-07 18:04:22.682989: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "dbParams = {\n",
    "    \"dbname\": \"mydatabase\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"host\": \"postgres_server\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "KFOLD_SPLITS = 5\n",
    "FIXED_LENGTH = 128\n",
    "\n",
    "# Feature types to train models for\n",
    "FEATURE_TYPES = [\n",
    "    'mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast',\n",
    "    'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength'\n",
    "]\n",
    "\n",
    "# GPU configuration\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Number of available GPUs: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instrument classes: 9\n",
      "Instruments: ['clarinet', 'piccolo', 'cello', 'oboe', 'violin', 'flute', 'bass', 'trumpet', 'sax']\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get instrument mappings\n",
    "instruments_mappings = db.get_mappings_instruments()\n",
    "num_classes = len(instruments_mappings)\n",
    "print(f\"Number of instrument classes: {num_classes}\")\n",
    "print(\"Instruments:\", instruments_mappings['name'].tolist())\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbConnect = PostgresDBHandler(**dbParams)\n",
    "dbConnect.connect()\n",
    "audioIDs = dbConnect.get_all_unique_audio_ids_in_processed()\n",
    "processed_data = dbConnect.get_processed_fit_data(audioIDs)\n",
    "\n",
    "all_processed_data = []\n",
    "for audio_id in audioIDs:\n",
    "    features = dbConnect.get_all_feature_types_for_audio(audio_id)\n",
    "    feature_dict = {f['featureTypeName']: f['featurePath'] for f in features}\n",
    "    instrumentID = dbConnect.get_audio_file(audio_id)['instrumentID']\n",
    "    feature_dict['instrumentID'] = instrumentID\n",
    "    all_processed_data.append(feature_dict)\n",
    "\n",
    "dbConnect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mel_spectrogram</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>chromagram</th>\n",
       "      <th>spectral_contrast</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>constant_q</th>\n",
       "      <th>cqt</th>\n",
       "      <th>stft</th>\n",
       "      <th>harmonic_percussive</th>\n",
       "      <th>onset_strength</th>\n",
       "      <th>instrumentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/9dfbbb55-f9...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/e7df2...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/f3d964d2...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/41991...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/30d6acbd-9f7...</td>\n",
       "      <td>ensemble_intermediate_results/stft/816fb586-fb...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/bcf73ea3-4a...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/7b11a...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/834affe9...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/cbdfe...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/3f142ac1-ea2...</td>\n",
       "      <td>ensemble_intermediate_results/stft/033f004c-7e...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/3...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/457fe528-fd...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/63dd9...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/304decf7...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/56f27...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/7002caaa-566...</td>\n",
       "      <td>ensemble_intermediate_results/stft/99975081-8d...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/a88d64a3-5f...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/7a5a7...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/c96baa79...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/c0b17...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/b64fa305-b26...</td>\n",
       "      <td>ensemble_intermediate_results/stft/9d8360f8-f9...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/6...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/bd978511-62...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/1690d...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/220438d2...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/83d09...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/5f929abc-8f0...</td>\n",
       "      <td>ensemble_intermediate_results/stft/edd8790a-14...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/5ecd7480-ba...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/c137c...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/3ab4fd1c...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/0d54d...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/dc36f0a8-229...</td>\n",
       "      <td>ensemble_intermediate_results/stft/d5dd41f4-15...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/6...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/abc22b4f-98...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/78f2e...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/cdc7b184...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/5eb48...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/19bd3542-407...</td>\n",
       "      <td>ensemble_intermediate_results/stft/ac8137f2-8d...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/3...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/adb16d86-26...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/ee1bf...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/0e83ec33...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/1e20a...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/700d16fb-a8c...</td>\n",
       "      <td>ensemble_intermediate_results/stft/eaddf348-47...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/8...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/45792151-ea...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/0c73e...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/a3ca9019...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/4f597...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/fef14dae-2b0...</td>\n",
       "      <td>ensemble_intermediate_results/stft/0f460032-28...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/8...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>ensemble_intermediate_results/mel_spectrogram/...</td>\n",
       "      <td>ensemble_intermediate_results/mfcc/ac83a976-c0...</td>\n",
       "      <td>ensemble_intermediate_results/chromagram/054b4...</td>\n",
       "      <td>ensemble_intermediate_results/spectral_contras...</td>\n",
       "      <td>ensemble_intermediate_results/tonnetz/80142a8e...</td>\n",
       "      <td>ensemble_intermediate_results/constant_q/d48cb...</td>\n",
       "      <td>ensemble_intermediate_results/cqt/a8a3a9b3-3ac...</td>\n",
       "      <td>ensemble_intermediate_results/stft/7a5204a8-f7...</td>\n",
       "      <td>ensemble_intermediate_results/harmonic_percuss...</td>\n",
       "      <td>ensemble_intermediate_results/onset_strength/8...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mel_spectrogram  \\\n",
       "0    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "1    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "2    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "3    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "4    ensemble_intermediate_results/mel_spectrogram/...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "896  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "897  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "898  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "899  ensemble_intermediate_results/mel_spectrogram/...   \n",
       "\n",
       "                                                  mfcc  \\\n",
       "0    ensemble_intermediate_results/mfcc/9dfbbb55-f9...   \n",
       "1    ensemble_intermediate_results/mfcc/bcf73ea3-4a...   \n",
       "2    ensemble_intermediate_results/mfcc/457fe528-fd...   \n",
       "3    ensemble_intermediate_results/mfcc/a88d64a3-5f...   \n",
       "4    ensemble_intermediate_results/mfcc/bd978511-62...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/mfcc/5ecd7480-ba...   \n",
       "896  ensemble_intermediate_results/mfcc/abc22b4f-98...   \n",
       "897  ensemble_intermediate_results/mfcc/adb16d86-26...   \n",
       "898  ensemble_intermediate_results/mfcc/45792151-ea...   \n",
       "899  ensemble_intermediate_results/mfcc/ac83a976-c0...   \n",
       "\n",
       "                                            chromagram  \\\n",
       "0    ensemble_intermediate_results/chromagram/e7df2...   \n",
       "1    ensemble_intermediate_results/chromagram/7b11a...   \n",
       "2    ensemble_intermediate_results/chromagram/63dd9...   \n",
       "3    ensemble_intermediate_results/chromagram/7a5a7...   \n",
       "4    ensemble_intermediate_results/chromagram/1690d...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/chromagram/c137c...   \n",
       "896  ensemble_intermediate_results/chromagram/78f2e...   \n",
       "897  ensemble_intermediate_results/chromagram/ee1bf...   \n",
       "898  ensemble_intermediate_results/chromagram/0c73e...   \n",
       "899  ensemble_intermediate_results/chromagram/054b4...   \n",
       "\n",
       "                                     spectral_contrast  \\\n",
       "0    ensemble_intermediate_results/spectral_contras...   \n",
       "1    ensemble_intermediate_results/spectral_contras...   \n",
       "2    ensemble_intermediate_results/spectral_contras...   \n",
       "3    ensemble_intermediate_results/spectral_contras...   \n",
       "4    ensemble_intermediate_results/spectral_contras...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/spectral_contras...   \n",
       "896  ensemble_intermediate_results/spectral_contras...   \n",
       "897  ensemble_intermediate_results/spectral_contras...   \n",
       "898  ensemble_intermediate_results/spectral_contras...   \n",
       "899  ensemble_intermediate_results/spectral_contras...   \n",
       "\n",
       "                                               tonnetz  \\\n",
       "0    ensemble_intermediate_results/tonnetz/f3d964d2...   \n",
       "1    ensemble_intermediate_results/tonnetz/834affe9...   \n",
       "2    ensemble_intermediate_results/tonnetz/304decf7...   \n",
       "3    ensemble_intermediate_results/tonnetz/c96baa79...   \n",
       "4    ensemble_intermediate_results/tonnetz/220438d2...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/tonnetz/3ab4fd1c...   \n",
       "896  ensemble_intermediate_results/tonnetz/cdc7b184...   \n",
       "897  ensemble_intermediate_results/tonnetz/0e83ec33...   \n",
       "898  ensemble_intermediate_results/tonnetz/a3ca9019...   \n",
       "899  ensemble_intermediate_results/tonnetz/80142a8e...   \n",
       "\n",
       "                                            constant_q  \\\n",
       "0    ensemble_intermediate_results/constant_q/41991...   \n",
       "1    ensemble_intermediate_results/constant_q/cbdfe...   \n",
       "2    ensemble_intermediate_results/constant_q/56f27...   \n",
       "3    ensemble_intermediate_results/constant_q/c0b17...   \n",
       "4    ensemble_intermediate_results/constant_q/83d09...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/constant_q/0d54d...   \n",
       "896  ensemble_intermediate_results/constant_q/5eb48...   \n",
       "897  ensemble_intermediate_results/constant_q/1e20a...   \n",
       "898  ensemble_intermediate_results/constant_q/4f597...   \n",
       "899  ensemble_intermediate_results/constant_q/d48cb...   \n",
       "\n",
       "                                                   cqt  \\\n",
       "0    ensemble_intermediate_results/cqt/30d6acbd-9f7...   \n",
       "1    ensemble_intermediate_results/cqt/3f142ac1-ea2...   \n",
       "2    ensemble_intermediate_results/cqt/7002caaa-566...   \n",
       "3    ensemble_intermediate_results/cqt/b64fa305-b26...   \n",
       "4    ensemble_intermediate_results/cqt/5f929abc-8f0...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/cqt/dc36f0a8-229...   \n",
       "896  ensemble_intermediate_results/cqt/19bd3542-407...   \n",
       "897  ensemble_intermediate_results/cqt/700d16fb-a8c...   \n",
       "898  ensemble_intermediate_results/cqt/fef14dae-2b0...   \n",
       "899  ensemble_intermediate_results/cqt/a8a3a9b3-3ac...   \n",
       "\n",
       "                                                  stft  \\\n",
       "0    ensemble_intermediate_results/stft/816fb586-fb...   \n",
       "1    ensemble_intermediate_results/stft/033f004c-7e...   \n",
       "2    ensemble_intermediate_results/stft/99975081-8d...   \n",
       "3    ensemble_intermediate_results/stft/9d8360f8-f9...   \n",
       "4    ensemble_intermediate_results/stft/edd8790a-14...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/stft/d5dd41f4-15...   \n",
       "896  ensemble_intermediate_results/stft/ac8137f2-8d...   \n",
       "897  ensemble_intermediate_results/stft/eaddf348-47...   \n",
       "898  ensemble_intermediate_results/stft/0f460032-28...   \n",
       "899  ensemble_intermediate_results/stft/7a5204a8-f7...   \n",
       "\n",
       "                                   harmonic_percussive  \\\n",
       "0    ensemble_intermediate_results/harmonic_percuss...   \n",
       "1    ensemble_intermediate_results/harmonic_percuss...   \n",
       "2    ensemble_intermediate_results/harmonic_percuss...   \n",
       "3    ensemble_intermediate_results/harmonic_percuss...   \n",
       "4    ensemble_intermediate_results/harmonic_percuss...   \n",
       "..                                                 ...   \n",
       "895  ensemble_intermediate_results/harmonic_percuss...   \n",
       "896  ensemble_intermediate_results/harmonic_percuss...   \n",
       "897  ensemble_intermediate_results/harmonic_percuss...   \n",
       "898  ensemble_intermediate_results/harmonic_percuss...   \n",
       "899  ensemble_intermediate_results/harmonic_percuss...   \n",
       "\n",
       "                                        onset_strength  instrumentID  \n",
       "0    ensemble_intermediate_results/onset_strength/1...             5  \n",
       "1    ensemble_intermediate_results/onset_strength/3...             8  \n",
       "2    ensemble_intermediate_results/onset_strength/1...             2  \n",
       "3    ensemble_intermediate_results/onset_strength/6...             4  \n",
       "4    ensemble_intermediate_results/onset_strength/b...             2  \n",
       "..                                                 ...           ...  \n",
       "895  ensemble_intermediate_results/onset_strength/6...             6  \n",
       "896  ensemble_intermediate_results/onset_strength/3...             6  \n",
       "897  ensemble_intermediate_results/onset_strength/8...             9  \n",
       "898  ensemble_intermediate_results/onset_strength/8...             5  \n",
       "899  ensemble_intermediate_results/onset_strength/8...             4  \n",
       "\n",
       "[900 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = pd.DataFrame(all_processed_data)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_shape(feature_type, df):\n",
    "    feature_path_col = feature_type \n",
    "    for path in df[feature_path_col]:\n",
    "        if isinstance(path, str) and os.path.exists(path):\n",
    "            arr = np.load(path)\n",
    "            return arr.shape\n",
    "    raise ValueError(f\"No valid file found for {feature_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleFeatureDataGenerator(Sequence):\n",
    "    def __init__(self, df, feature_col, batch_size=32, shuffle=True, num_classes=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_col = feature_col\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = num_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indices]\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for _, row in batch_df.iterrows():\n",
    "            try:\n",
    "                arr = np.load(row[self.feature_col])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {row[self.feature_col]}: {e}\")\n",
    "                continue\n",
    "        \n",
    "            if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "                raise ValueError(f\"Feature file {row[self.feature_col]} contains NaNs or Infs.\")\n",
    "        \n",
    "            arr = (arr - np.mean(arr)) / (np.std(arr) + 1e-8)\n",
    "            if arr.ndim == 2:\n",
    "                arr = np.expand_dims(arr, -1)  # shape: (H, W, 1)\n",
    "        \n",
    "            X.append(arr)\n",
    "            y.append(row['instrumentID'])  # already label-encoded\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y = to_categorical(np.array(y), num_classes=self.num_classes)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(input_shape, num_classes, model_name=\"simple_cnn\"):\n",
    "    input_layer = Input(shape=(*input_shape, 1), name=f\"{model_name}_input\")\n",
    "\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    output = Dense(num_classes, activation='softmax', name=f\"{model_name}_output\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output, name=model_name)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training features:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for mel_spectrogram\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 24.2725 - accuracy: 0.4531 - val_loss: 8.8255 - val_accuracy: 0.5833\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 5.5070 - accuracy: 0.8125 - val_loss: 4.1611 - val_accuracy: 0.5625\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.6623 - accuracy: 0.8767 - val_loss: 1.9545 - val_accuracy: 0.7986\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8001 - accuracy: 0.9392 - val_loss: 2.0552 - val_accuracy: 0.8125\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0501 - accuracy: 0.9566 - val_loss: 2.4383 - val_accuracy: 0.8264\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4653 - accuracy: 0.9722 - val_loss: 2.3321 - val_accuracy: 0.8472\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4563 - accuracy: 0.9653 - val_loss: 2.8307 - val_accuracy: 0.8264\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7340 - accuracy: 0.9514 - val_loss: 4.3074 - val_accuracy: 0.8194\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9342 - accuracy: 0.9531 - val_loss: 1.6912 - val_accuracy: 0.8681\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0851 - accuracy: 0.9618 - val_loss: 1.2988 - val_accuracy: 0.9097\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4237 - accuracy: 0.9757 - val_loss: 2.0831 - val_accuracy: 0.8889\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4368 - accuracy: 0.9826 - val_loss: 3.4218 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5429 - accuracy: 0.9792 - val_loss: 1.6980 - val_accuracy: 0.9167\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1713 - accuracy: 0.9878 - val_loss: 2.2727 - val_accuracy: 0.8958\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0419 - accuracy: 0.9896 - val_loss: 1.9171 - val_accuracy: 0.9097\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 0.9931 - val_loss: 1.4006 - val_accuracy: 0.9097\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0464 - accuracy: 0.9948 - val_loss: 2.1512 - val_accuracy: 0.8958\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1063 - accuracy: 0.9913 - val_loss: 1.4780 - val_accuracy: 0.9375\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9931 - val_loss: 1.5846 - val_accuracy: 0.9028\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1468 - accuracy: 0.9861 - val_loss: 1.4647 - val_accuracy: 0.9514\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1206 - accuracy: 0.9861 - val_loss: 1.4192 - val_accuracy: 0.9167\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0240 - accuracy: 0.9965 - val_loss: 1.4338 - val_accuracy: 0.9236\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0803 - accuracy: 0.9913 - val_loss: 0.6878 - val_accuracy: 0.9306\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 1.2836 - val_accuracy: 0.9236\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1019 - accuracy: 0.9931 - val_loss: 1.4784 - val_accuracy: 0.9444\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0396 - accuracy: 0.9948 - val_loss: 2.2104 - val_accuracy: 0.9306\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2053 - accuracy: 0.9878 - val_loss: 2.2798 - val_accuracy: 0.8958\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0881 - accuracy: 0.9931 - val_loss: 1.5492 - val_accuracy: 0.9167\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1145 - accuracy: 0.9965 - val_loss: 5.6572 - val_accuracy: 0.8681\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2367 - accuracy: 0.9861 - val_loss: 3.9189 - val_accuracy: 0.8958\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0485 - accuracy: 0.9913 - val_loss: 4.4194 - val_accuracy: 0.8611\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2318 - accuracy: 0.9878 - val_loss: 4.8090 - val_accuracy: 0.8681\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8357 - accuracy: 0.9722 - val_loss: 4.4583 - val_accuracy: 0.8681\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2926 - accuracy: 0.9826 - val_loss: 6.7072 - val_accuracy: 0.8819\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2176 - accuracy: 0.9774 - val_loss: 3.6580 - val_accuracy: 0.9167\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4570 - accuracy: 0.9809 - val_loss: 5.8640 - val_accuracy: 0.8333\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2050 - accuracy: 0.9878 - val_loss: 4.5719 - val_accuracy: 0.8819\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3829 - accuracy: 0.9757 - val_loss: 1.8929 - val_accuracy: 0.9375\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2293 - accuracy: 0.9861 - val_loss: 2.8706 - val_accuracy: 0.9375\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1296 - accuracy: 0.9896 - val_loss: 2.2147 - val_accuracy: 0.8958\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0906 - accuracy: 0.9931 - val_loss: 2.2942 - val_accuracy: 0.9097\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0933 - accuracy: 0.9931 - val_loss: 3.4182 - val_accuracy: 0.9097\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1753 - accuracy: 0.9913 - val_loss: 2.6999 - val_accuracy: 0.9514\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.1726 - accuracy: 0.9389\n",
      "mel_spectrogram - Fold 1 Test accuracy: 0.9389\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 25.0009 - accuracy: 0.4688 - val_loss: 10.0489 - val_accuracy: 0.4375\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 5.3601 - accuracy: 0.8090 - val_loss: 8.8720 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 3.6684 - accuracy: 0.8872 - val_loss: 3.0500 - val_accuracy: 0.7708\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9208 - accuracy: 0.9549 - val_loss: 4.0983 - val_accuracy: 0.7500\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7747 - accuracy: 0.9583 - val_loss: 3.7998 - val_accuracy: 0.8194\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3047 - accuracy: 0.9792 - val_loss: 6.6249 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2280 - accuracy: 0.9861 - val_loss: 3.7514 - val_accuracy: 0.7847\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1166 - accuracy: 0.9931 - val_loss: 4.7835 - val_accuracy: 0.7778\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0995 - accuracy: 0.9878 - val_loss: 5.0422 - val_accuracy: 0.7778\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9965 - val_loss: 4.4702 - val_accuracy: 0.7986\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0295 - accuracy: 0.9983 - val_loss: 3.5603 - val_accuracy: 0.8472\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4547e-05 - accuracy: 1.0000 - val_loss: 3.2427 - val_accuracy: 0.8819\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0397 - accuracy: 0.9948 - val_loss: 4.1188 - val_accuracy: 0.8403\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1976 - accuracy: 0.9861 - val_loss: 3.5851 - val_accuracy: 0.8889\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.9826 - val_loss: 3.3481 - val_accuracy: 0.8958\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3365 - accuracy: 0.9809 - val_loss: 3.4272 - val_accuracy: 0.8819\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9913 - val_loss: 4.3032 - val_accuracy: 0.8611\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1051 - accuracy: 0.9931 - val_loss: 3.8966 - val_accuracy: 0.8681\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1359 - accuracy: 0.9878 - val_loss: 3.5877 - val_accuracy: 0.9097\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1306 - accuracy: 0.9896 - val_loss: 4.2082 - val_accuracy: 0.8611\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3283 - accuracy: 0.9861 - val_loss: 2.6848 - val_accuracy: 0.9097\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2207 - accuracy: 0.9844 - val_loss: 3.4480 - val_accuracy: 0.9028\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3064 - accuracy: 0.9861 - val_loss: 4.7185 - val_accuracy: 0.8819\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1430 - accuracy: 0.9913 - val_loss: 4.1757 - val_accuracy: 0.8819\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0934 - accuracy: 0.9913 - val_loss: 3.6482 - val_accuracy: 0.9236\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1368 - accuracy: 0.9948 - val_loss: 3.1174 - val_accuracy: 0.9097\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4436e-05 - accuracy: 1.0000 - val_loss: 2.7520 - val_accuracy: 0.9097\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.4999e-05 - accuracy: 1.0000 - val_loss: 2.8505 - val_accuracy: 0.9097\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.3767e-05 - accuracy: 1.0000 - val_loss: 2.8869 - val_accuracy: 0.9097\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.5977e-06 - accuracy: 1.0000 - val_loss: 2.9238 - val_accuracy: 0.9097\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0632e-06 - accuracy: 1.0000 - val_loss: 2.9602 - val_accuracy: 0.9097\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.0633e-07 - accuracy: 1.0000 - val_loss: 2.9923 - val_accuracy: 0.9167\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1125e-05 - accuracy: 1.0000 - val_loss: 3.0143 - val_accuracy: 0.9167\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.6474e-07 - accuracy: 1.0000 - val_loss: 3.0358 - val_accuracy: 0.9167\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.0013e-07 - accuracy: 1.0000 - val_loss: 3.0554 - val_accuracy: 0.9167\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0451e-07 - accuracy: 1.0000 - val_loss: 3.0723 - val_accuracy: 0.9167\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.4617e-06 - accuracy: 1.0000 - val_loss: 3.0858 - val_accuracy: 0.9167\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.9454e-08 - accuracy: 1.0000 - val_loss: 3.0978 - val_accuracy: 0.9167\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.1238e-06 - accuracy: 1.0000 - val_loss: 3.1052 - val_accuracy: 0.9167\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.5232e-07 - accuracy: 1.0000 - val_loss: 3.1158 - val_accuracy: 0.9097\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.8784e-04 - accuracy: 1.0000 - val_loss: 3.5313 - val_accuracy: 0.9097\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.6783 - accuracy: 0.9111\n",
      "mel_spectrogram - Fold 2 Test accuracy: 0.9111\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 21.0999 - accuracy: 0.5503 - val_loss: 2.2528 - val_accuracy: 0.7222\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.6387 - accuracy: 0.8333 - val_loss: 4.3613 - val_accuracy: 0.6528\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4119 - accuracy: 0.9306 - val_loss: 2.3960 - val_accuracy: 0.7986\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5937 - accuracy: 0.9566 - val_loss: 2.1279 - val_accuracy: 0.8403\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3232 - accuracy: 0.9792 - val_loss: 2.1844 - val_accuracy: 0.7847\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0852 - accuracy: 0.9896 - val_loss: 3.4285 - val_accuracy: 0.7361\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.9688 - val_loss: 5.2769 - val_accuracy: 0.7292\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9578 - accuracy: 0.9479 - val_loss: 5.0034 - val_accuracy: 0.7431\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1748 - accuracy: 0.9514 - val_loss: 3.7867 - val_accuracy: 0.8194\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5227 - accuracy: 0.9601 - val_loss: 5.3878 - val_accuracy: 0.8194\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.9757 - val_loss: 3.4844 - val_accuracy: 0.8472\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1618 - accuracy: 0.9878 - val_loss: 4.7011 - val_accuracy: 0.8264\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2708 - accuracy: 0.9826 - val_loss: 4.8280 - val_accuracy: 0.8403\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2712 - accuracy: 0.9844 - val_loss: 7.4132 - val_accuracy: 0.7986\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1674 - accuracy: 0.9878 - val_loss: 5.6673 - val_accuracy: 0.8125\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1488 - accuracy: 0.9844 - val_loss: 5.3730 - val_accuracy: 0.8194\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9948 - val_loss: 5.1577 - val_accuracy: 0.8472\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.9948 - val_loss: 4.9878 - val_accuracy: 0.8472\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1388 - accuracy: 0.9896 - val_loss: 4.3710 - val_accuracy: 0.8542\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0553 - accuracy: 0.9948 - val_loss: 4.5691 - val_accuracy: 0.8611\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0605 - accuracy: 0.9913 - val_loss: 4.3623 - val_accuracy: 0.8819\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.9948 - val_loss: 3.5307 - val_accuracy: 0.8958\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0607 - accuracy: 0.9965 - val_loss: 5.3273 - val_accuracy: 0.8472\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0189 - accuracy: 0.9983 - val_loss: 5.0460 - val_accuracy: 0.8611\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0048 - accuracy: 0.9111\n",
      "mel_spectrogram - Fold 3 Test accuracy: 0.9111\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 29.0621 - accuracy: 0.4635 - val_loss: 7.1281 - val_accuracy: 0.5278\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 6.3847 - accuracy: 0.8073 - val_loss: 8.6846 - val_accuracy: 0.4653\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.7464 - accuracy: 0.8976 - val_loss: 6.0912 - val_accuracy: 0.6111\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7526 - accuracy: 0.9444 - val_loss: 4.4211 - val_accuracy: 0.7292\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7065 - accuracy: 0.9531 - val_loss: 5.4408 - val_accuracy: 0.6736\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0416 - accuracy: 0.9913 - val_loss: 2.8034 - val_accuracy: 0.8264\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1113 - accuracy: 0.9896 - val_loss: 4.6306 - val_accuracy: 0.7292\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2359 - accuracy: 0.9809 - val_loss: 2.8830 - val_accuracy: 0.8958\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2955 - accuracy: 0.9740 - val_loss: 2.4817 - val_accuracy: 0.8819\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1977 - accuracy: 0.9878 - val_loss: 3.5367 - val_accuracy: 0.8403\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4337 - accuracy: 0.9757 - val_loss: 2.6979 - val_accuracy: 0.8819\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4253 - accuracy: 0.9705 - val_loss: 3.0410 - val_accuracy: 0.8819\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1399 - accuracy: 0.9896 - val_loss: 3.6066 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0389 - accuracy: 0.9948 - val_loss: 2.9758 - val_accuracy: 0.9097\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0534 - accuracy: 0.9913 - val_loss: 2.4969 - val_accuracy: 0.9167\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1206 - accuracy: 0.9913 - val_loss: 4.0330 - val_accuracy: 0.8819\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9844 - val_loss: 4.5469 - val_accuracy: 0.8611\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2696 - accuracy: 0.9774 - val_loss: 5.1783 - val_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 0.9913 - val_loss: 5.3385 - val_accuracy: 0.8681\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.9774 - val_loss: 8.9716 - val_accuracy: 0.7847\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1141 - accuracy: 0.9531 - val_loss: 5.4761 - val_accuracy: 0.8264\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3166 - accuracy: 0.9740 - val_loss: 4.7939 - val_accuracy: 0.9028\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2527 - accuracy: 0.9826 - val_loss: 7.5765 - val_accuracy: 0.7986\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1529 - accuracy: 0.9931 - val_loss: 6.4963 - val_accuracy: 0.8681\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0259 - accuracy: 0.9983 - val_loss: 5.3864 - val_accuracy: 0.8819\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0361 - accuracy: 0.9965 - val_loss: 5.6960 - val_accuracy: 0.8889\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 0.9983 - val_loss: 5.7255 - val_accuracy: 0.8889\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 6.2613e-05 - accuracy: 1.0000 - val_loss: 5.7148 - val_accuracy: 0.8819\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.1916e-06 - accuracy: 1.0000 - val_loss: 5.6662 - val_accuracy: 0.8889\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6400 - accuracy: 0.8889\n",
      "mel_spectrogram - Fold 4 Test accuracy: 0.8889\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 13ms/step - loss: 33.7455 - accuracy: 0.4375 - val_loss: 7.4990 - val_accuracy: 0.5417\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 9.4345 - accuracy: 0.7188 - val_loss: 6.0312 - val_accuracy: 0.5347\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.5319 - accuracy: 0.8819 - val_loss: 5.8147 - val_accuracy: 0.6250\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.8086 - accuracy: 0.9479 - val_loss: 2.7568 - val_accuracy: 0.7569\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5734 - accuracy: 0.9618 - val_loss: 2.7454 - val_accuracy: 0.7917\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.9774 - val_loss: 2.6635 - val_accuracy: 0.7986\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1449 - accuracy: 0.9826 - val_loss: 2.5066 - val_accuracy: 0.8681\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1505 - accuracy: 0.9896 - val_loss: 2.0061 - val_accuracy: 0.8681\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1598 - accuracy: 0.9878 - val_loss: 2.7691 - val_accuracy: 0.7917\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1923 - accuracy: 0.9913 - val_loss: 2.5637 - val_accuracy: 0.8403\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.9948 - val_loss: 3.0740 - val_accuracy: 0.8333\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0714 - accuracy: 0.9913 - val_loss: 3.8769 - val_accuracy: 0.8403\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0465 - accuracy: 0.9913 - val_loss: 3.5739 - val_accuracy: 0.8333\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1406 - accuracy: 0.9861 - val_loss: 3.6296 - val_accuracy: 0.8542\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1658 - accuracy: 0.9878 - val_loss: 3.2858 - val_accuracy: 0.8889\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7271 - accuracy: 0.9618 - val_loss: 3.3293 - val_accuracy: 0.9167\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3979 - accuracy: 0.9705 - val_loss: 6.0608 - val_accuracy: 0.8056\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.9740 - val_loss: 5.5909 - val_accuracy: 0.8403\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6645 - accuracy: 0.9566 - val_loss: 7.9085 - val_accuracy: 0.7639\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3696 - accuracy: 0.9722 - val_loss: 5.4329 - val_accuracy: 0.8472\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2328 - accuracy: 0.9826 - val_loss: 4.5075 - val_accuracy: 0.8819\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4389 - accuracy: 0.9757 - val_loss: 5.7392 - val_accuracy: 0.8819\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5134 - accuracy: 0.9792 - val_loss: 6.8141 - val_accuracy: 0.8542\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3986 - accuracy: 0.9774 - val_loss: 5.2899 - val_accuracy: 0.8889\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2800 - accuracy: 0.9757 - val_loss: 6.3981 - val_accuracy: 0.8194\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4291 - accuracy: 0.9809 - val_loss: 8.9006 - val_accuracy: 0.8194\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9913 - val_loss: 6.7717 - val_accuracy: 0.8750\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1188 - accuracy: 0.9878 - val_loss: 6.2135 - val_accuracy: 0.9306\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.4788 - accuracy: 0.8667\n",
      "mel_spectrogram - Fold 5 Test accuracy: 0.8667\n",
      "6/6 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  10%|â–ˆ         | 1/10 [00:30<04:32, 30.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for mfcc\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.5745 - accuracy: 0.4184 - val_loss: 2.4615 - val_accuracy: 0.2083\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0823 - accuracy: 0.7118 - val_loss: 2.3235 - val_accuracy: 0.2222\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.7969 - val_loss: 1.8380 - val_accuracy: 0.2778\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.8247 - val_loss: 1.4173 - val_accuracy: 0.3958\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8628 - val_loss: 1.3682 - val_accuracy: 0.4167\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3353 - accuracy: 0.8819 - val_loss: 1.0271 - val_accuracy: 0.6389\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3010 - accuracy: 0.9097 - val_loss: 1.0600 - val_accuracy: 0.5556\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8906 - val_loss: 0.8521 - val_accuracy: 0.7153\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2815 - accuracy: 0.8993 - val_loss: 0.7982 - val_accuracy: 0.7500\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2832 - accuracy: 0.9080 - val_loss: 0.8055 - val_accuracy: 0.6944\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2504 - accuracy: 0.9045 - val_loss: 0.5869 - val_accuracy: 0.7847\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2087 - accuracy: 0.9201 - val_loss: 0.6218 - val_accuracy: 0.7917\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1666 - accuracy: 0.9444 - val_loss: 0.4231 - val_accuracy: 0.8819\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2800 - accuracy: 0.9132 - val_loss: 0.5443 - val_accuracy: 0.7986\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2556 - accuracy: 0.9201 - val_loss: 0.5745 - val_accuracy: 0.8264\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2471 - accuracy: 0.9062 - val_loss: 0.4692 - val_accuracy: 0.8472\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2342 - accuracy: 0.9253 - val_loss: 0.6203 - val_accuracy: 0.8403\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.9115 - val_loss: 0.4271 - val_accuracy: 0.8611\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2133 - accuracy: 0.9288 - val_loss: 0.4299 - val_accuracy: 0.8542\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1042 - accuracy: 0.9722 - val_loss: 0.4142 - val_accuracy: 0.8611\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 0.0977 - accuracy: 0.9618 - val_loss: 0.3290 - val_accuracy: 0.8819\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0913 - accuracy: 0.9722 - val_loss: 0.4170 - val_accuracy: 0.8611\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9826 - val_loss: 0.4519 - val_accuracy: 0.8472\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.9826 - val_loss: 0.4359 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.9618 - val_loss: 0.4789 - val_accuracy: 0.8611\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1932 - accuracy: 0.9462 - val_loss: 0.4570 - val_accuracy: 0.8542\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1342 - accuracy: 0.9566 - val_loss: 0.5050 - val_accuracy: 0.8681\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1144 - accuracy: 0.9583 - val_loss: 0.4774 - val_accuracy: 0.8750\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1069 - accuracy: 0.9566 - val_loss: 0.5114 - val_accuracy: 0.8750\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1674 - accuracy: 0.9410 - val_loss: 0.4443 - val_accuracy: 0.8819\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9774 - val_loss: 0.4531 - val_accuracy: 0.8819\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0549 - accuracy: 0.9774 - val_loss: 0.3636 - val_accuracy: 0.8819\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9878 - val_loss: 0.4194 - val_accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9931 - val_loss: 0.3775 - val_accuracy: 0.8889\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0392 - accuracy: 0.9896 - val_loss: 0.3853 - val_accuracy: 0.9167\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1341 - accuracy: 0.9740 - val_loss: 0.6855 - val_accuracy: 0.8611\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0930 - accuracy: 0.9809 - val_loss: 0.4819 - val_accuracy: 0.9097\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9896 - val_loss: 0.3482 - val_accuracy: 0.9028\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.3556 - val_accuracy: 0.9306\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.4112 - val_accuracy: 0.9167\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 0.4249 - val_accuracy: 0.9097\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8944\n",
      "mfcc - Fold 1 Test accuracy: 0.8944\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 6.3047 - accuracy: 0.3247 - val_loss: 1.6905 - val_accuracy: 0.3958\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4856 - accuracy: 0.6892 - val_loss: 2.5163 - val_accuracy: 0.4028\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9040 - accuracy: 0.7743 - val_loss: 2.1057 - val_accuracy: 0.4375\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5525 - accuracy: 0.8455 - val_loss: 1.8001 - val_accuracy: 0.4583\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8802 - val_loss: 1.0662 - val_accuracy: 0.6389\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3978 - accuracy: 0.8698 - val_loss: 0.8206 - val_accuracy: 0.6875\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2146 - accuracy: 0.9253 - val_loss: 0.6451 - val_accuracy: 0.7986\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1985 - accuracy: 0.9323 - val_loss: 0.5838 - val_accuracy: 0.8125\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9497 - val_loss: 0.5844 - val_accuracy: 0.7917\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1635 - accuracy: 0.9444 - val_loss: 0.6764 - val_accuracy: 0.7639\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1831 - accuracy: 0.9375 - val_loss: 0.8011 - val_accuracy: 0.6944\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1561 - accuracy: 0.9410 - val_loss: 0.5025 - val_accuracy: 0.8125\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.9497 - val_loss: 0.7073 - val_accuracy: 0.7500\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9635 - val_loss: 0.4665 - val_accuracy: 0.8403\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.9670 - val_loss: 0.4754 - val_accuracy: 0.8264\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1478 - accuracy: 0.9427 - val_loss: 0.7920 - val_accuracy: 0.7917\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1221 - accuracy: 0.9635 - val_loss: 0.5688 - val_accuracy: 0.8333\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1202 - accuracy: 0.9618 - val_loss: 0.6921 - val_accuracy: 0.7986\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0861 - accuracy: 0.9792 - val_loss: 0.4464 - val_accuracy: 0.8542\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.5402 - val_accuracy: 0.8472\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9722 - val_loss: 0.5570 - val_accuracy: 0.8194\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1048 - accuracy: 0.9688 - val_loss: 0.6159 - val_accuracy: 0.8194\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.6610 - val_accuracy: 0.8056\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 0.6159 - val_accuracy: 0.8194\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9896 - val_loss: 0.5411 - val_accuracy: 0.8542\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.5335 - val_accuracy: 0.8819\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9913 - val_loss: 0.5949 - val_accuracy: 0.8681\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9896 - val_loss: 0.6703 - val_accuracy: 0.8542\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9965 - val_loss: 0.6029 - val_accuracy: 0.8750\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.6122 - val_accuracy: 0.8819\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8750\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.8750\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6029 - val_accuracy: 0.8819\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.8819\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6142 - val_accuracy: 0.8819\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.6194 - val_accuracy: 0.8889\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6282 - val_accuracy: 0.8750\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.8819\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.8819\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.5566 - accuracy: 0.8333\n",
      "mfcc - Fold 2 Test accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 5.8148 - accuracy: 0.3194 - val_loss: 2.7000 - val_accuracy: 0.3681\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2915 - accuracy: 0.6823 - val_loss: 2.9797 - val_accuracy: 0.3611\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8832 - accuracy: 0.7535 - val_loss: 2.2261 - val_accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5542 - accuracy: 0.8403 - val_loss: 2.1485 - val_accuracy: 0.3889\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.8229 - val_loss: 2.0992 - val_accuracy: 0.4236\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.8194 - val_loss: 1.3521 - val_accuracy: 0.5556\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8698 - val_loss: 1.3537 - val_accuracy: 0.5972\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3229 - accuracy: 0.8924 - val_loss: 1.0972 - val_accuracy: 0.6389\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3445 - accuracy: 0.8958 - val_loss: 1.0930 - val_accuracy: 0.6389\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3096 - accuracy: 0.9045 - val_loss: 0.9901 - val_accuracy: 0.6875\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.9184 - val_loss: 1.0065 - val_accuracy: 0.6458\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2188 - accuracy: 0.9358 - val_loss: 0.9071 - val_accuracy: 0.7083\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1397 - accuracy: 0.9531 - val_loss: 0.5781 - val_accuracy: 0.7917\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.9410 - val_loss: 0.8650 - val_accuracy: 0.7292\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1248 - accuracy: 0.9583 - val_loss: 0.7875 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.9826 - val_loss: 0.5906 - val_accuracy: 0.8264\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9844 - val_loss: 0.7737 - val_accuracy: 0.7708\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9861 - val_loss: 0.7728 - val_accuracy: 0.7639\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9861 - val_loss: 0.5782 - val_accuracy: 0.8264\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0503 - accuracy: 0.9948 - val_loss: 0.7203 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.6094 - val_accuracy: 0.7986\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0819 - accuracy: 0.9635 - val_loss: 0.7050 - val_accuracy: 0.7639\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1989 - accuracy: 0.9427 - val_loss: 0.7658 - val_accuracy: 0.7431\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9583 - val_loss: 0.9418 - val_accuracy: 0.7778\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2368 - accuracy: 0.9375 - val_loss: 0.7309 - val_accuracy: 0.8403\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.9670 - val_loss: 1.0764 - val_accuracy: 0.7222\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0679 - accuracy: 0.9809 - val_loss: 2.0882 - val_accuracy: 0.6458\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9948 - val_loss: 1.3729 - val_accuracy: 0.7153\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9948 - val_loss: 1.2064 - val_accuracy: 0.7431\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9931 - val_loss: 0.5888 - val_accuracy: 0.8403\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.6682 - val_accuracy: 0.8125\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8333\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.4747 - val_accuracy: 0.8611\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.4956 - val_accuracy: 0.8472\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.4906 - val_accuracy: 0.8819\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.4532 - val_accuracy: 0.8750\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.5800 - val_accuracy: 0.8611\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8958\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.4682 - val_accuracy: 0.8819\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.5489 - val_accuracy: 0.8611\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.8889\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.8889\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.8819\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.8819\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8819\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.8750\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8819\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8750\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8819\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8750\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.8750\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.8819\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8750\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8819\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.8819\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8750\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8819\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.8819\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.7063 - accuracy: 0.8611\n",
      "mfcc - Fold 3 Test accuracy: 0.8611\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 6.5928 - accuracy: 0.3837 - val_loss: 3.4780 - val_accuracy: 0.3750\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2833 - accuracy: 0.7031 - val_loss: 4.4808 - val_accuracy: 0.1875\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8359 - accuracy: 0.7587 - val_loss: 5.8163 - val_accuracy: 0.1458\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.8247 - val_loss: 3.0514 - val_accuracy: 0.3194\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3217 - accuracy: 0.8958 - val_loss: 3.3863 - val_accuracy: 0.2847\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2673 - accuracy: 0.9062 - val_loss: 2.1340 - val_accuracy: 0.3819\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2386 - accuracy: 0.9253 - val_loss: 1.4615 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1993 - accuracy: 0.9288 - val_loss: 1.3069 - val_accuracy: 0.5972\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2062 - accuracy: 0.9375 - val_loss: 0.9165 - val_accuracy: 0.7014\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1705 - accuracy: 0.9358 - val_loss: 0.9870 - val_accuracy: 0.6806\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2331 - accuracy: 0.9288 - val_loss: 0.8146 - val_accuracy: 0.7222\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2544 - accuracy: 0.9253 - val_loss: 0.9131 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2726 - accuracy: 0.9149 - val_loss: 0.6743 - val_accuracy: 0.7431\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2743 - accuracy: 0.9097 - val_loss: 0.6753 - val_accuracy: 0.7639\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1415 - accuracy: 0.9531 - val_loss: 0.5876 - val_accuracy: 0.8056\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9497 - val_loss: 0.6563 - val_accuracy: 0.7639\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1297 - accuracy: 0.9514 - val_loss: 0.5460 - val_accuracy: 0.7917\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1283 - accuracy: 0.9531 - val_loss: 0.5855 - val_accuracy: 0.8333\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8958 - val_loss: 0.9391 - val_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3225 - accuracy: 0.9097 - val_loss: 0.9901 - val_accuracy: 0.7569\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1634 - accuracy: 0.9444 - val_loss: 0.8452 - val_accuracy: 0.7639\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9826 - val_loss: 0.5926 - val_accuracy: 0.8472\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0524 - accuracy: 0.9878 - val_loss: 0.5125 - val_accuracy: 0.8611\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9965 - val_loss: 0.5675 - val_accuracy: 0.8611\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.5654 - val_accuracy: 0.8542\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8681\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.5871 - val_accuracy: 0.8542\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.5692 - val_accuracy: 0.8472\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.6690 - val_accuracy: 0.8542\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 0.9983 - val_loss: 0.6324 - val_accuracy: 0.8611\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.6340 - val_accuracy: 0.8542\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.8446 - val_accuracy: 0.8056\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0312 - accuracy: 0.9861 - val_loss: 0.6432 - val_accuracy: 0.8542\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.6629 - val_accuracy: 0.8403\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.6483 - val_accuracy: 0.8472\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 0.9983 - val_loss: 0.7146 - val_accuracy: 0.8819\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9861 - val_loss: 0.7430 - val_accuracy: 0.8472\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.7572 - val_accuracy: 0.8542\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.6773 - val_accuracy: 0.8611\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0552 - accuracy: 0.9757 - val_loss: 1.0088 - val_accuracy: 0.8194\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0677 - accuracy: 0.9757 - val_loss: 0.9035 - val_accuracy: 0.8472\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.9700 - val_accuracy: 0.8472\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9757 - val_loss: 0.9599 - val_accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.8944\n",
      "mfcc - Fold 4 Test accuracy: 0.8944\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 4.0735 - accuracy: 0.4861 - val_loss: 1.7643 - val_accuracy: 0.3611\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2885 - accuracy: 0.7292 - val_loss: 1.6164 - val_accuracy: 0.4653\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6640 - accuracy: 0.8247 - val_loss: 1.1982 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4969 - accuracy: 0.8733 - val_loss: 1.2905 - val_accuracy: 0.5833\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3155 - accuracy: 0.8889 - val_loss: 1.0029 - val_accuracy: 0.7153\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2200 - accuracy: 0.9236 - val_loss: 0.9831 - val_accuracy: 0.7222\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2120 - accuracy: 0.9219 - val_loss: 0.9011 - val_accuracy: 0.6875\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2017 - accuracy: 0.9462 - val_loss: 0.7775 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1720 - accuracy: 0.9427 - val_loss: 0.7760 - val_accuracy: 0.7361\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9688 - val_loss: 0.8082 - val_accuracy: 0.7500\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1247 - accuracy: 0.9601 - val_loss: 0.6486 - val_accuracy: 0.7708\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1565 - accuracy: 0.9410 - val_loss: 1.0212 - val_accuracy: 0.7361\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2455 - accuracy: 0.9062 - val_loss: 0.5523 - val_accuracy: 0.8125\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1739 - accuracy: 0.9358 - val_loss: 0.6597 - val_accuracy: 0.7917\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2023 - accuracy: 0.9375 - val_loss: 0.5952 - val_accuracy: 0.8194\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2483 - accuracy: 0.9253 - val_loss: 0.7069 - val_accuracy: 0.7708\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1619 - accuracy: 0.9410 - val_loss: 0.8254 - val_accuracy: 0.8056\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9653 - val_loss: 0.8292 - val_accuracy: 0.7986\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0885 - accuracy: 0.9653 - val_loss: 0.6460 - val_accuracy: 0.8125\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9670 - val_loss: 0.5402 - val_accuracy: 0.8681\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0591 - accuracy: 0.9844 - val_loss: 0.5492 - val_accuracy: 0.8611\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0316 - accuracy: 0.9931 - val_loss: 0.5714 - val_accuracy: 0.8542\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.7615 - val_accuracy: 0.8264\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9931 - val_loss: 0.6010 - val_accuracy: 0.8681\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9983 - val_loss: 0.7093 - val_accuracy: 0.8472\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9913 - val_loss: 0.6146 - val_accuracy: 0.8819\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.6809 - val_accuracy: 0.8264\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9983 - val_loss: 0.7118 - val_accuracy: 0.8542\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9878 - val_loss: 0.6292 - val_accuracy: 0.8681\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9983 - val_loss: 0.7308 - val_accuracy: 0.8611\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9913 - val_loss: 0.6086 - val_accuracy: 0.8819\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9878 - val_loss: 0.7909 - val_accuracy: 0.8681\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1134 - accuracy: 0.9757 - val_loss: 1.0154 - val_accuracy: 0.8194\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1524 - accuracy: 0.9479 - val_loss: 0.9778 - val_accuracy: 0.8472\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1371 - accuracy: 0.9462 - val_loss: 1.2347 - val_accuracy: 0.8264\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9722 - val_loss: 1.1493 - val_accuracy: 0.8472\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9774 - val_loss: 1.2671 - val_accuracy: 0.8472\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9844 - val_loss: 1.1842 - val_accuracy: 0.8403\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9878 - val_loss: 0.8392 - val_accuracy: 0.8611\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9705 - val_loss: 1.1175 - val_accuracy: 0.8472\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.8333\n",
      "mfcc - Fold 5 Test accuracy: 0.8333\n",
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  20%|â–ˆâ–ˆ        | 2/10 [01:02<04:11, 31.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for chromagram\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 6.1374 - accuracy: 0.2170 - val_loss: 2.7607 - val_accuracy: 0.2847\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.7261 - accuracy: 0.4253 - val_loss: 2.0890 - val_accuracy: 0.3681\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4955 - accuracy: 0.6684 - val_loss: 1.8053 - val_accuracy: 0.3472\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8624 - accuracy: 0.7396 - val_loss: 1.7156 - val_accuracy: 0.3889\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.8455 - val_loss: 1.6445 - val_accuracy: 0.4167\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8976 - val_loss: 1.8182 - val_accuracy: 0.3819\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2172 - accuracy: 0.9271 - val_loss: 1.7860 - val_accuracy: 0.4306\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9757 - val_loss: 2.0336 - val_accuracy: 0.3958\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9913 - val_loss: 1.9611 - val_accuracy: 0.4167\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9983 - val_loss: 1.9707 - val_accuracy: 0.3889\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.9229 - val_accuracy: 0.4306\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.9485 - val_accuracy: 0.4375\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.9037 - val_accuracy: 0.4514\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.9702 - val_accuracy: 0.4306\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.9279 - val_accuracy: 0.4583\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9534 - val_accuracy: 0.4653\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.9710 - val_accuracy: 0.4653\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.9940 - val_accuracy: 0.4722\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.9957 - val_accuracy: 0.4931\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.5069\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.0690 - val_accuracy: 0.5069\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1053 - val_accuracy: 0.4931\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1615 - val_accuracy: 0.4861\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.2115 - val_accuracy: 0.4861\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.2558 - val_accuracy: 0.4861\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.7460 - accuracy: 0.4000\n",
      "chromagram - Fold 1 Test accuracy: 0.4000\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 7.3518 - accuracy: 0.2326 - val_loss: 2.8909 - val_accuracy: 0.2569\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.8297 - accuracy: 0.4653 - val_loss: 3.1359 - val_accuracy: 0.2569\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8377 - accuracy: 0.5608 - val_loss: 2.7501 - val_accuracy: 0.2222\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1663 - accuracy: 0.6424 - val_loss: 1.7609 - val_accuracy: 0.3611\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1085 - accuracy: 0.6788 - val_loss: 1.5568 - val_accuracy: 0.4792\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8142 - accuracy: 0.7535 - val_loss: 1.6037 - val_accuracy: 0.4306\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6065 - accuracy: 0.7882 - val_loss: 1.4986 - val_accuracy: 0.4861\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8628 - val_loss: 1.6436 - val_accuracy: 0.4444\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8924 - val_loss: 1.7341 - val_accuracy: 0.3472\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8958 - val_loss: 1.8538 - val_accuracy: 0.3472\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3048 - accuracy: 0.9010 - val_loss: 2.2523 - val_accuracy: 0.3264\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8628 - val_loss: 1.9501 - val_accuracy: 0.3819\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3125 - accuracy: 0.9132 - val_loss: 2.0259 - val_accuracy: 0.3681\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2490 - accuracy: 0.9219 - val_loss: 1.8812 - val_accuracy: 0.4444\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1870 - accuracy: 0.9410 - val_loss: 2.3409 - val_accuracy: 0.3681\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1820 - accuracy: 0.9444 - val_loss: 2.1061 - val_accuracy: 0.4028\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9635 - val_loss: 2.1091 - val_accuracy: 0.4583\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1058 - accuracy: 0.9722 - val_loss: 2.2831 - val_accuracy: 0.4444\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9826 - val_loss: 2.2572 - val_accuracy: 0.4653\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 2.3641 - val_accuracy: 0.4583\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 2.3677 - val_accuracy: 0.4514\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 2.6323 - val_accuracy: 0.4028\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9983 - val_loss: 2.6538 - val_accuracy: 0.4375\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.6031 - val_accuracy: 0.4444\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.6283 - val_accuracy: 0.4931\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.6901 - val_accuracy: 0.4931\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.7514 - val_accuracy: 0.5000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4834 - accuracy: 0.5111\n",
      "chromagram - Fold 2 Test accuracy: 0.5111\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 6.4956 - accuracy: 0.2257 - val_loss: 2.1913 - val_accuracy: 0.3056\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.7621 - accuracy: 0.4722 - val_loss: 2.1207 - val_accuracy: 0.3264\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6671 - accuracy: 0.5990 - val_loss: 1.8578 - val_accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0288 - accuracy: 0.6892 - val_loss: 1.6822 - val_accuracy: 0.3542\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6283 - accuracy: 0.7934 - val_loss: 1.6400 - val_accuracy: 0.4236\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8906 - val_loss: 1.6793 - val_accuracy: 0.3750\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2349 - accuracy: 0.9410 - val_loss: 1.7727 - val_accuracy: 0.3542\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1493 - accuracy: 0.9635 - val_loss: 1.6932 - val_accuracy: 0.4028\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1080 - accuracy: 0.9740 - val_loss: 1.7250 - val_accuracy: 0.3681\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9931 - val_loss: 1.7822 - val_accuracy: 0.3750\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0464 - accuracy: 0.9965 - val_loss: 1.7597 - val_accuracy: 0.4236\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.8160 - val_accuracy: 0.4236\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.8393 - val_accuracy: 0.4444\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.8881 - val_accuracy: 0.4375\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.9434 - val_accuracy: 0.4583\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.0081 - val_accuracy: 0.4444\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.0656 - val_accuracy: 0.4514\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.1308 - val_accuracy: 0.4583\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.2167 - val_accuracy: 0.4653\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.2841 - val_accuracy: 0.4653\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.4653\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.4573 - val_accuracy: 0.4514\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5386 - val_accuracy: 0.4583\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.6309 - val_accuracy: 0.4583\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.7301 - val_accuracy: 0.4583\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.7780 - accuracy: 0.3667\n",
      "chromagram - Fold 3 Test accuracy: 0.3667\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 7.5229 - accuracy: 0.1979 - val_loss: 2.3635 - val_accuracy: 0.2708\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.6429 - accuracy: 0.4444 - val_loss: 2.7645 - val_accuracy: 0.1875\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6476 - accuracy: 0.5903 - val_loss: 2.4762 - val_accuracy: 0.2222\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9931 - accuracy: 0.7205 - val_loss: 1.8934 - val_accuracy: 0.3056\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5851 - accuracy: 0.8125 - val_loss: 1.9170 - val_accuracy: 0.3472\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8594 - val_loss: 1.9020 - val_accuracy: 0.3472\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9132 - val_loss: 1.7921 - val_accuracy: 0.3819\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1511 - accuracy: 0.9514 - val_loss: 1.6804 - val_accuracy: 0.4514\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9757 - val_loss: 1.7619 - val_accuracy: 0.4306\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9861 - val_loss: 1.7324 - val_accuracy: 0.4375\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0572 - accuracy: 0.9931 - val_loss: 1.8312 - val_accuracy: 0.4167\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0695 - accuracy: 0.9844 - val_loss: 1.8386 - val_accuracy: 0.4583\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9913 - val_loss: 1.7428 - val_accuracy: 0.5139\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9948 - val_loss: 1.8015 - val_accuracy: 0.5139\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.8009 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 1.9685 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9035 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9042 - val_accuracy: 0.5208\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.9459 - val_accuracy: 0.4931\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.5139\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.0627 - val_accuracy: 0.5278\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1080 - val_accuracy: 0.5208\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.1692 - val_accuracy: 0.5139\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.2393 - val_accuracy: 0.5208\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2913 - val_accuracy: 0.5139\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3714 - val_accuracy: 0.5069\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4245 - val_accuracy: 0.5069\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4895 - val_accuracy: 0.5069\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6102 - accuracy: 0.4389\n",
      "chromagram - Fold 4 Test accuracy: 0.4389\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 6.3522 - accuracy: 0.1962 - val_loss: 2.9633 - val_accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.0202 - accuracy: 0.4410 - val_loss: 2.3588 - val_accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7182 - accuracy: 0.5521 - val_loss: 2.0250 - val_accuracy: 0.2639\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9835 - accuracy: 0.6962 - val_loss: 1.8572 - val_accuracy: 0.3125\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7315 - accuracy: 0.7431 - val_loss: 1.7195 - val_accuracy: 0.3472\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.8108 - val_loss: 1.6474 - val_accuracy: 0.3750\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8785 - val_loss: 1.7425 - val_accuracy: 0.3403\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2310 - accuracy: 0.9236 - val_loss: 1.9145 - val_accuracy: 0.2917\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1433 - accuracy: 0.9618 - val_loss: 1.8466 - val_accuracy: 0.3958\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1155 - accuracy: 0.9792 - val_loss: 2.0400 - val_accuracy: 0.3403\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9913 - val_loss: 2.1170 - val_accuracy: 0.3750\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9844 - val_loss: 2.0616 - val_accuracy: 0.3542\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9983 - val_loss: 2.2089 - val_accuracy: 0.3681\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 0.9983 - val_loss: 2.0980 - val_accuracy: 0.3750\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.9427 - val_accuracy: 0.4306\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.1419 - val_accuracy: 0.4097\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.0410 - val_accuracy: 0.4444\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.1109 - val_accuracy: 0.4444\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.0898 - val_accuracy: 0.4583\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1367 - val_accuracy: 0.4653\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1477 - val_accuracy: 0.4653\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.2071 - val_accuracy: 0.4722\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2593 - val_accuracy: 0.4444\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3010 - val_accuracy: 0.4514\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3864 - val_accuracy: 0.4444\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.4504 - val_accuracy: 0.4653\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.6309 - accuracy: 0.4222\n",
      "chromagram - Fold 5 Test accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:22<03:03, 26.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for spectral_contrast\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.2518 - accuracy: 0.3194 - val_loss: 1.9352 - val_accuracy: 0.3194\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4360 - accuracy: 0.5139 - val_loss: 1.8174 - val_accuracy: 0.3542\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1304 - accuracy: 0.6319 - val_loss: 1.6955 - val_accuracy: 0.3681\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9169 - accuracy: 0.6892 - val_loss: 1.4976 - val_accuracy: 0.5278\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6999 - accuracy: 0.7830 - val_loss: 1.4598 - val_accuracy: 0.5278\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5841 - accuracy: 0.8108 - val_loss: 1.5238 - val_accuracy: 0.4861\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.8403 - val_loss: 1.6950 - val_accuracy: 0.4097\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4553 - accuracy: 0.8472 - val_loss: 1.6259 - val_accuracy: 0.4583\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3165 - accuracy: 0.8993 - val_loss: 1.6535 - val_accuracy: 0.4375\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2042 - accuracy: 0.9497 - val_loss: 1.5837 - val_accuracy: 0.4931\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1307 - accuracy: 0.9774 - val_loss: 1.7427 - val_accuracy: 0.4653\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1017 - accuracy: 0.9826 - val_loss: 1.6525 - val_accuracy: 0.5208\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9913 - val_loss: 1.7356 - val_accuracy: 0.5139\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.5069\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9965 - val_loss: 1.7996 - val_accuracy: 0.5347\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.7556 - val_accuracy: 0.5625\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.8551 - val_accuracy: 0.5556\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 1.7605 - val_accuracy: 0.5417\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.9668 - val_accuracy: 0.5486\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.9206 - val_accuracy: 0.5625\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.9477 - val_accuracy: 0.5347\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.0141 - val_accuracy: 0.5417\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.0510 - val_accuracy: 0.5347\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.1215 - val_accuracy: 0.5208\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1763 - val_accuracy: 0.5417\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4920 - accuracy: 0.4222\n",
      "spectral_contrast - Fold 1 Test accuracy: 0.4222\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 2.3329 - accuracy: 0.2899 - val_loss: 2.1348 - val_accuracy: 0.1806\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4181 - accuracy: 0.4983 - val_loss: 1.8546 - val_accuracy: 0.2917\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1759 - accuracy: 0.5799 - val_loss: 1.8070 - val_accuracy: 0.3681\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9238 - accuracy: 0.7031 - val_loss: 1.6716 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7012 - accuracy: 0.7812 - val_loss: 1.5427 - val_accuracy: 0.4444\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5658 - accuracy: 0.8472 - val_loss: 1.4914 - val_accuracy: 0.4306\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.8785 - val_loss: 1.5144 - val_accuracy: 0.4097\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.8872 - val_loss: 1.5858 - val_accuracy: 0.3819\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2892 - accuracy: 0.9167 - val_loss: 1.6345 - val_accuracy: 0.3958\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 0.9358 - val_loss: 1.6855 - val_accuracy: 0.3958\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1446 - accuracy: 0.9688 - val_loss: 1.6584 - val_accuracy: 0.4236\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.9670 - val_loss: 1.7175 - val_accuracy: 0.4097\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0884 - accuracy: 0.9844 - val_loss: 1.5928 - val_accuracy: 0.4653\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9965 - val_loss: 1.7821 - val_accuracy: 0.4306\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 1.7888 - val_accuracy: 0.4375\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.7225 - val_accuracy: 0.4722\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.7953 - val_accuracy: 0.4375\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.7842 - val_accuracy: 0.4653\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.8087 - val_accuracy: 0.5069\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.8458 - val_accuracy: 0.5069\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.8838 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.8605 - val_accuracy: 0.5139\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.8528 - val_accuracy: 0.5417\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.9573 - val_accuracy: 0.5347\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.9848 - val_accuracy: 0.5486\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.5625\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5420 - accuracy: 0.4167\n",
      "spectral_contrast - Fold 2 Test accuracy: 0.4167\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 2.5293 - accuracy: 0.3038 - val_loss: 2.1266 - val_accuracy: 0.3194\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4583 - accuracy: 0.5052 - val_loss: 1.8077 - val_accuracy: 0.2986\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.2368 - accuracy: 0.5747 - val_loss: 1.7195 - val_accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0762 - accuracy: 0.6597 - val_loss: 1.5312 - val_accuracy: 0.4931\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8854 - accuracy: 0.7222 - val_loss: 1.6003 - val_accuracy: 0.4583\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7455 - accuracy: 0.7691 - val_loss: 1.4480 - val_accuracy: 0.5208\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6178 - accuracy: 0.8142 - val_loss: 1.4767 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.8524 - val_loss: 1.5154 - val_accuracy: 0.4792\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8889 - val_loss: 1.5445 - val_accuracy: 0.4583\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3151 - accuracy: 0.9184 - val_loss: 1.6532 - val_accuracy: 0.3889\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2373 - accuracy: 0.9271 - val_loss: 1.6587 - val_accuracy: 0.4514\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9479 - val_loss: 1.8055 - val_accuracy: 0.4167\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9705 - val_loss: 1.7585 - val_accuracy: 0.4306\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9948 - val_loss: 1.9555 - val_accuracy: 0.4097\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0652 - accuracy: 0.9913 - val_loss: 2.0639 - val_accuracy: 0.4167\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9913 - val_loss: 2.2837 - val_accuracy: 0.4097\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9913 - val_loss: 2.3104 - val_accuracy: 0.3958\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0438 - accuracy: 0.9913 - val_loss: 2.1284 - val_accuracy: 0.4236\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0928 - accuracy: 0.9792 - val_loss: 2.4247 - val_accuracy: 0.4236\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0899 - accuracy: 0.9757 - val_loss: 2.7593 - val_accuracy: 0.4375\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 0.9826 - val_loss: 2.6319 - val_accuracy: 0.4722\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9913 - val_loss: 3.1814 - val_accuracy: 0.4653\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9913 - val_loss: 3.0510 - val_accuracy: 0.4653\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9861 - val_loss: 2.8568 - val_accuracy: 0.5069\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9983 - val_loss: 2.8478 - val_accuracy: 0.4792\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.9794 - val_accuracy: 0.5208\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 1.3637 - accuracy: 0.5778\n",
      "spectral_contrast - Fold 3 Test accuracy: 0.5778\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 2.5120 - accuracy: 0.3142 - val_loss: 1.8932 - val_accuracy: 0.2083\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4143 - accuracy: 0.5035 - val_loss: 1.7549 - val_accuracy: 0.2431\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0507 - accuracy: 0.6354 - val_loss: 1.8129 - val_accuracy: 0.2778\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9979 - accuracy: 0.6528 - val_loss: 1.5968 - val_accuracy: 0.4722\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8351 - accuracy: 0.7135 - val_loss: 1.5696 - val_accuracy: 0.4583\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7229 - accuracy: 0.7691 - val_loss: 1.4078 - val_accuracy: 0.5347\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5899 - accuracy: 0.8056 - val_loss: 1.3262 - val_accuracy: 0.5347\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4874 - accuracy: 0.8438 - val_loss: 1.3434 - val_accuracy: 0.5208\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8924 - val_loss: 1.3097 - val_accuracy: 0.5556\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2948 - accuracy: 0.9062 - val_loss: 1.3977 - val_accuracy: 0.4653\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2196 - accuracy: 0.9444 - val_loss: 1.4676 - val_accuracy: 0.4583\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1852 - accuracy: 0.9427 - val_loss: 1.5486 - val_accuracy: 0.4306\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.9601 - val_loss: 1.6336 - val_accuracy: 0.4792\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9878 - val_loss: 1.5963 - val_accuracy: 0.4861\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0606 - accuracy: 0.9931 - val_loss: 1.5647 - val_accuracy: 0.4931\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9983 - val_loss: 1.6184 - val_accuracy: 0.5069\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.7242 - val_accuracy: 0.5069\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.7762 - val_accuracy: 0.4861\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.7229 - val_accuracy: 0.5069\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 0.9983 - val_loss: 1.7386 - val_accuracy: 0.5417\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7786 - val_accuracy: 0.5347\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.7186 - val_accuracy: 0.5694\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.7757 - val_accuracy: 0.5486\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.7992 - val_accuracy: 0.5556\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.8121 - val_accuracy: 0.5694\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.8317 - val_accuracy: 0.5903\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.8489 - val_accuracy: 0.5972\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.8698 - val_accuracy: 0.6042\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9145 - val_accuracy: 0.6042\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2783 - accuracy: 0.5500\n",
      "spectral_contrast - Fold 4 Test accuracy: 0.5500\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 3.0791 - accuracy: 0.2413 - val_loss: 2.1279 - val_accuracy: 0.2222\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4772 - accuracy: 0.4792 - val_loss: 1.7486 - val_accuracy: 0.3403\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1637 - accuracy: 0.5955 - val_loss: 1.6100 - val_accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9913 - accuracy: 0.6753 - val_loss: 1.3030 - val_accuracy: 0.5625\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8776 - accuracy: 0.6979 - val_loss: 1.3423 - val_accuracy: 0.5069\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7186 - accuracy: 0.7743 - val_loss: 1.3108 - val_accuracy: 0.5347\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6020 - accuracy: 0.7986 - val_loss: 1.4192 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.8455 - val_loss: 1.3945 - val_accuracy: 0.5556\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8767 - val_loss: 1.3034 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3082 - accuracy: 0.9115 - val_loss: 1.3859 - val_accuracy: 0.4861\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2552 - accuracy: 0.9115 - val_loss: 1.5454 - val_accuracy: 0.4861\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1868 - accuracy: 0.9514 - val_loss: 1.5607 - val_accuracy: 0.5139\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1471 - accuracy: 0.9635 - val_loss: 1.9929 - val_accuracy: 0.4167\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1148 - accuracy: 0.9688 - val_loss: 2.0881 - val_accuracy: 0.3889\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0639 - accuracy: 0.9861 - val_loss: 2.1201 - val_accuracy: 0.4444\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 0.9983 - val_loss: 2.3197 - val_accuracy: 0.4028\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 2.2664 - val_accuracy: 0.4167\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.3486 - val_accuracy: 0.4444\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 2.3277 - val_accuracy: 0.4653\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.2539 - val_accuracy: 0.4653\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.3279 - val_accuracy: 0.4722\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.2617 - val_accuracy: 0.4792\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.2888 - val_accuracy: 0.4653\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2632 - val_accuracy: 0.4653\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4691 - accuracy: 0.4611\n",
      "spectral_contrast - Fold 5 Test accuracy: 0.4611\n",
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:41<02:20, 23.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for tonnetz\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 6.5056 - accuracy: 0.1823 - val_loss: 2.2734 - val_accuracy: 0.2361\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.5736 - accuracy: 0.3125 - val_loss: 2.1533 - val_accuracy: 0.2986\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1271 - accuracy: 0.4062 - val_loss: 2.1150 - val_accuracy: 0.2569\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.7911 - accuracy: 0.4462 - val_loss: 1.9439 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4108 - accuracy: 0.5382 - val_loss: 1.8352 - val_accuracy: 0.3403\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2958 - accuracy: 0.5503 - val_loss: 2.0003 - val_accuracy: 0.2708\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2149 - accuracy: 0.5972 - val_loss: 1.8419 - val_accuracy: 0.4028\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0376 - accuracy: 0.6580 - val_loss: 1.9604 - val_accuracy: 0.3611\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0108 - accuracy: 0.6580 - val_loss: 1.9756 - val_accuracy: 0.4028\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0911 - accuracy: 0.6267 - val_loss: 1.9419 - val_accuracy: 0.3611\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9939 - accuracy: 0.6528 - val_loss: 2.2310 - val_accuracy: 0.3403\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0287 - accuracy: 0.6597 - val_loss: 2.0743 - val_accuracy: 0.3611\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9658 - accuracy: 0.6562 - val_loss: 2.2665 - val_accuracy: 0.3611\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8484 - accuracy: 0.7292 - val_loss: 2.4407 - val_accuracy: 0.3611\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7981 - accuracy: 0.7413 - val_loss: 2.2227 - val_accuracy: 0.4097\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7707 - accuracy: 0.7413 - val_loss: 2.1311 - val_accuracy: 0.3889\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8437 - accuracy: 0.7135 - val_loss: 2.3228 - val_accuracy: 0.3611\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7688 - accuracy: 0.7274 - val_loss: 2.5653 - val_accuracy: 0.3889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6861 - accuracy: 0.7569 - val_loss: 2.3565 - val_accuracy: 0.4167\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.7691 - val_loss: 2.6223 - val_accuracy: 0.4028\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7484 - accuracy: 0.7431 - val_loss: 3.0634 - val_accuracy: 0.3333\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8266 - accuracy: 0.7292 - val_loss: 2.9319 - val_accuracy: 0.3403\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7830 - accuracy: 0.7361 - val_loss: 2.7922 - val_accuracy: 0.4236\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7209 - accuracy: 0.7396 - val_loss: 2.9259 - val_accuracy: 0.3681\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.7865 - val_loss: 2.8638 - val_accuracy: 0.3819\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.8963 - accuracy: 0.3278\n",
      "tonnetz - Fold 1 Test accuracy: 0.3278\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 5.9596 - accuracy: 0.2031 - val_loss: 2.9713 - val_accuracy: 0.2014\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.2023 - accuracy: 0.3264 - val_loss: 2.3685 - val_accuracy: 0.2778\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.3253 - accuracy: 0.3924 - val_loss: 2.2749 - val_accuracy: 0.2639\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8593 - accuracy: 0.4601 - val_loss: 2.3641 - val_accuracy: 0.2153\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6393 - accuracy: 0.4653 - val_loss: 2.2050 - val_accuracy: 0.2500\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3136 - accuracy: 0.5451 - val_loss: 2.0757 - val_accuracy: 0.2778\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2566 - accuracy: 0.5833 - val_loss: 2.0294 - val_accuracy: 0.3056\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1604 - accuracy: 0.6094 - val_loss: 2.0130 - val_accuracy: 0.3056\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1480 - accuracy: 0.6198 - val_loss: 2.0819 - val_accuracy: 0.2917\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2216 - accuracy: 0.6042 - val_loss: 2.2164 - val_accuracy: 0.3056\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1284 - accuracy: 0.6267 - val_loss: 1.9730 - val_accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0380 - accuracy: 0.6632 - val_loss: 1.9942 - val_accuracy: 0.3472\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9080 - accuracy: 0.6771 - val_loss: 2.0809 - val_accuracy: 0.3750\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9581 - accuracy: 0.6649 - val_loss: 2.1004 - val_accuracy: 0.3125\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9774 - accuracy: 0.6684 - val_loss: 2.4086 - val_accuracy: 0.3194\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0158 - accuracy: 0.6632 - val_loss: 2.4637 - val_accuracy: 0.3194\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9737 - accuracy: 0.6771 - val_loss: 2.2421 - val_accuracy: 0.3681\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8357 - accuracy: 0.7188 - val_loss: 2.3721 - val_accuracy: 0.3333\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8185 - accuracy: 0.7135 - val_loss: 2.5020 - val_accuracy: 0.3403\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7641 - accuracy: 0.7361 - val_loss: 2.2064 - val_accuracy: 0.3472\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.7760 - val_loss: 2.7695 - val_accuracy: 0.2986\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6397 - accuracy: 0.7760 - val_loss: 2.6711 - val_accuracy: 0.3611\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6870 - accuracy: 0.7778 - val_loss: 2.4306 - val_accuracy: 0.4028\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.7795 - val_loss: 2.7473 - val_accuracy: 0.3403\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5269 - accuracy: 0.8316 - val_loss: 2.3522 - val_accuracy: 0.4653\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8507 - val_loss: 2.8155 - val_accuracy: 0.4028\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8507 - val_loss: 2.8667 - val_accuracy: 0.4167\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8611 - val_loss: 2.8467 - val_accuracy: 0.4306\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3406 - accuracy: 0.8889 - val_loss: 2.5319 - val_accuracy: 0.4792\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3238 - accuracy: 0.8854 - val_loss: 2.5567 - val_accuracy: 0.4444\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8715 - val_loss: 2.9386 - val_accuracy: 0.4236\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9825 - accuracy: 0.3611\n",
      "tonnetz - Fold 2 Test accuracy: 0.3611\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 6.0247 - accuracy: 0.1562 - val_loss: 3.2040 - val_accuracy: 0.1597\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.5995 - accuracy: 0.3160 - val_loss: 2.9661 - val_accuracy: 0.1597\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1672 - accuracy: 0.3889 - val_loss: 2.7197 - val_accuracy: 0.1597\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5582 - accuracy: 0.4965 - val_loss: 2.1579 - val_accuracy: 0.2222\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3605 - accuracy: 0.5347 - val_loss: 2.1956 - val_accuracy: 0.2222\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3930 - accuracy: 0.5486 - val_loss: 2.1620 - val_accuracy: 0.2431\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2554 - accuracy: 0.6042 - val_loss: 1.9937 - val_accuracy: 0.3403\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1637 - accuracy: 0.6493 - val_loss: 2.0497 - val_accuracy: 0.2986\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1345 - accuracy: 0.6233 - val_loss: 2.2438 - val_accuracy: 0.3056\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1199 - accuracy: 0.6337 - val_loss: 2.0766 - val_accuracy: 0.3264\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0976 - accuracy: 0.6406 - val_loss: 2.1892 - val_accuracy: 0.3125\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0422 - accuracy: 0.6354 - val_loss: 2.3778 - val_accuracy: 0.2639\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9546 - accuracy: 0.6927 - val_loss: 2.4053 - val_accuracy: 0.3125\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8926 - accuracy: 0.6892 - val_loss: 2.3211 - val_accuracy: 0.3472\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8951 - accuracy: 0.6979 - val_loss: 2.4906 - val_accuracy: 0.3403\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7793 - accuracy: 0.7587 - val_loss: 2.3618 - val_accuracy: 0.3403\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7583 - accuracy: 0.7604 - val_loss: 2.4089 - val_accuracy: 0.3750\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.7234 - accuracy: 0.7500 - val_loss: 3.0098 - val_accuracy: 0.2708\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.8056 - val_loss: 3.6295 - val_accuracy: 0.2431\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6517 - accuracy: 0.7917 - val_loss: 2.8596 - val_accuracy: 0.3681\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6181 - accuracy: 0.7812 - val_loss: 3.4391 - val_accuracy: 0.3194\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5507 - accuracy: 0.8038 - val_loss: 4.0650 - val_accuracy: 0.2986\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6274 - accuracy: 0.7865 - val_loss: 3.1089 - val_accuracy: 0.3542\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5927 - accuracy: 0.8090 - val_loss: 2.6104 - val_accuracy: 0.4306\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4757 - accuracy: 0.8542 - val_loss: 3.3801 - val_accuracy: 0.3264\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.8351 - val_loss: 3.7912 - val_accuracy: 0.3194\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8785 - val_loss: 3.4960 - val_accuracy: 0.3472\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 2.1206 - accuracy: 0.3222\n",
      "tonnetz - Fold 3 Test accuracy: 0.3222\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 6.1929 - accuracy: 0.1927 - val_loss: 2.9500 - val_accuracy: 0.1389\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.5902 - accuracy: 0.3472 - val_loss: 2.2344 - val_accuracy: 0.2083\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.8983 - accuracy: 0.4253 - val_loss: 2.2657 - val_accuracy: 0.2153\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.6796 - accuracy: 0.4601 - val_loss: 2.1465 - val_accuracy: 0.2986\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4348 - accuracy: 0.5417 - val_loss: 1.9707 - val_accuracy: 0.3264\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3448 - accuracy: 0.5330 - val_loss: 2.0770 - val_accuracy: 0.2708\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1477 - accuracy: 0.6198 - val_loss: 1.9911 - val_accuracy: 0.3681\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0624 - accuracy: 0.6562 - val_loss: 1.9382 - val_accuracy: 0.3611\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9172 - accuracy: 0.6875 - val_loss: 2.0185 - val_accuracy: 0.3056\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8050 - accuracy: 0.7292 - val_loss: 2.1163 - val_accuracy: 0.3403\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8186 - accuracy: 0.7326 - val_loss: 1.9651 - val_accuracy: 0.3472\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.7496 - accuracy: 0.7517 - val_loss: 2.0705 - val_accuracy: 0.3889\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6877 - accuracy: 0.7691 - val_loss: 2.2262 - val_accuracy: 0.3681\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6035 - accuracy: 0.8003 - val_loss: 1.9617 - val_accuracy: 0.4028\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5430 - accuracy: 0.8108 - val_loss: 2.1113 - val_accuracy: 0.3403\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.8507 - val_loss: 2.0461 - val_accuracy: 0.3542\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.8472 - val_loss: 2.1218 - val_accuracy: 0.4514\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8785 - val_loss: 2.2106 - val_accuracy: 0.4375\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8750 - val_loss: 2.1694 - val_accuracy: 0.4375\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2753 - accuracy: 0.9167 - val_loss: 2.0905 - val_accuracy: 0.4653\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2679 - accuracy: 0.9045 - val_loss: 2.3202 - val_accuracy: 0.4375\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2961 - accuracy: 0.8976 - val_loss: 2.4016 - val_accuracy: 0.4722\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3066 - accuracy: 0.8819 - val_loss: 2.1697 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2974 - accuracy: 0.9028 - val_loss: 2.3927 - val_accuracy: 0.4514\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2254 - accuracy: 0.9062 - val_loss: 2.5016 - val_accuracy: 0.4861\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2838 - accuracy: 0.8958 - val_loss: 2.4270 - val_accuracy: 0.4792\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2449 - accuracy: 0.9201 - val_loss: 2.6286 - val_accuracy: 0.5069\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1970 - accuracy: 0.9340 - val_loss: 2.7554 - val_accuracy: 0.5278\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9083 - accuracy: 0.3944\n",
      "tonnetz - Fold 4 Test accuracy: 0.3944\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 5.5249 - accuracy: 0.1979 - val_loss: 2.7914 - val_accuracy: 0.1667\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.9655 - accuracy: 0.3299 - val_loss: 2.3850 - val_accuracy: 0.2014\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.0653 - accuracy: 0.4097 - val_loss: 2.1602 - val_accuracy: 0.2361\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.5632 - accuracy: 0.4896 - val_loss: 2.2168 - val_accuracy: 0.2639\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3895 - accuracy: 0.5625 - val_loss: 2.1647 - val_accuracy: 0.2708\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.3424 - accuracy: 0.5556 - val_loss: 2.1048 - val_accuracy: 0.2500\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2827 - accuracy: 0.5833 - val_loss: 2.0350 - val_accuracy: 0.2847\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0950 - accuracy: 0.6250 - val_loss: 1.9094 - val_accuracy: 0.3125\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9355 - accuracy: 0.6823 - val_loss: 2.1707 - val_accuracy: 0.2986\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9098 - accuracy: 0.6858 - val_loss: 2.5205 - val_accuracy: 0.2361\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.8676 - accuracy: 0.6997 - val_loss: 2.7450 - val_accuracy: 0.2986\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6690 - accuracy: 0.7778 - val_loss: 2.8838 - val_accuracy: 0.2778\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6296 - accuracy: 0.7708 - val_loss: 3.1717 - val_accuracy: 0.3056\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5489 - accuracy: 0.8108 - val_loss: 2.8165 - val_accuracy: 0.3056\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.8038 - val_loss: 2.7302 - val_accuracy: 0.3264\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.7656 - val_loss: 2.8806 - val_accuracy: 0.3472\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5394 - accuracy: 0.8038 - val_loss: 3.3610 - val_accuracy: 0.3194\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.8212 - val_loss: 3.1741 - val_accuracy: 0.3264\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.8351 - val_loss: 2.9616 - val_accuracy: 0.3403\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5034 - accuracy: 0.8212 - val_loss: 2.6359 - val_accuracy: 0.4097\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.8316 - val_loss: 2.8942 - val_accuracy: 0.3958\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.8316 - val_loss: 3.7500 - val_accuracy: 0.3056\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3431 - accuracy: 0.8715 - val_loss: 2.8969 - val_accuracy: 0.4167\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2595 - accuracy: 0.9132 - val_loss: 2.6133 - val_accuracy: 0.4861\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.3052 - accuracy: 0.8993 - val_loss: 2.5060 - val_accuracy: 0.4722\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2393 - accuracy: 0.9167 - val_loss: 2.5629 - val_accuracy: 0.4792\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2089 - accuracy: 0.9410 - val_loss: 2.8508 - val_accuracy: 0.4583\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.9514 - val_loss: 3.1349 - val_accuracy: 0.4931\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.9805 - accuracy: 0.3333\n",
      "tonnetz - Fold 5 Test accuracy: 0.3333\n",
      "6/6 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [02:02<01:52, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for constant_q\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 12.9218 - accuracy: 0.5729 - val_loss: 8.1429 - val_accuracy: 0.4861\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.4818 - accuracy: 0.8229 - val_loss: 3.4028 - val_accuracy: 0.7083\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.9497 - val_loss: 3.4660 - val_accuracy: 0.7153\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2117 - accuracy: 0.9844 - val_loss: 2.5851 - val_accuracy: 0.7847\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.9913 - val_loss: 3.2765 - val_accuracy: 0.7708\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9948 - val_loss: 1.8376 - val_accuracy: 0.8264\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0613 - accuracy: 0.9931 - val_loss: 2.1986 - val_accuracy: 0.8194\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9948 - val_loss: 2.3330 - val_accuracy: 0.8194\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0822 - accuracy: 0.9878 - val_loss: 1.7556 - val_accuracy: 0.8611\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1576 - accuracy: 0.9896 - val_loss: 1.4238 - val_accuracy: 0.8403\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - accuracy: 0.9965 - val_loss: 1.1101 - val_accuracy: 0.8750\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9896 - val_loss: 0.8548 - val_accuracy: 0.8958\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9913 - val_loss: 1.4351 - val_accuracy: 0.8958\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2049 - accuracy: 0.9740 - val_loss: 1.7150 - val_accuracy: 0.8889\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3440 - accuracy: 0.9705 - val_loss: 1.8933 - val_accuracy: 0.8611\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.9722 - val_loss: 3.1669 - val_accuracy: 0.8056\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1388 - accuracy: 0.9792 - val_loss: 3.0231 - val_accuracy: 0.8472\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9913 - val_loss: 1.8578 - val_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9965 - val_loss: 1.8429 - val_accuracy: 0.8681\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1642 - accuracy: 0.9740 - val_loss: 3.5652 - val_accuracy: 0.8125\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8085 - accuracy: 0.9444 - val_loss: 3.0473 - val_accuracy: 0.8611\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1128 - accuracy: 0.9896 - val_loss: 1.0706 - val_accuracy: 0.9028\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0844 - accuracy: 0.9948 - val_loss: 1.5127 - val_accuracy: 0.9306\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9948 - val_loss: 1.7496 - val_accuracy: 0.9097\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 1.9542 - val_accuracy: 0.8889\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 2.0128 - val_accuracy: 0.8889\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 3.1282 - val_accuracy: 0.8819\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0386 - accuracy: 0.9983 - val_loss: 3.0208 - val_accuracy: 0.8819\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2421e-05 - accuracy: 1.0000 - val_loss: 2.9703 - val_accuracy: 0.8889\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.4643e-07 - accuracy: 1.0000 - val_loss: 2.9929 - val_accuracy: 0.8819\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.1181e-05 - accuracy: 1.0000 - val_loss: 3.0055 - val_accuracy: 0.8819\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.3189e-08 - accuracy: 1.0000 - val_loss: 2.9984 - val_accuracy: 0.8819\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0097 - accuracy: 0.9333\n",
      "constant_q - Fold 1 Test accuracy: 0.9333\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 10.9131 - accuracy: 0.5955 - val_loss: 3.4298 - val_accuracy: 0.6250\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7894 - accuracy: 0.8646 - val_loss: 3.0267 - val_accuracy: 0.7222\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9385 - accuracy: 0.9427 - val_loss: 2.2776 - val_accuracy: 0.7569\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.9635 - val_loss: 2.1526 - val_accuracy: 0.8403\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2909 - accuracy: 0.9774 - val_loss: 2.7105 - val_accuracy: 0.7986\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0546 - accuracy: 0.9896 - val_loss: 1.6257 - val_accuracy: 0.8750\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9913 - val_loss: 1.6021 - val_accuracy: 0.8611\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1931 - accuracy: 0.9774 - val_loss: 2.8601 - val_accuracy: 0.8125\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3102 - accuracy: 0.9740 - val_loss: 1.8790 - val_accuracy: 0.8750\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.9948 - val_loss: 2.2025 - val_accuracy: 0.8819\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 0.9948 - val_loss: 2.0518 - val_accuracy: 0.8750\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.5689 - val_accuracy: 0.8403\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0417 - accuracy: 0.9948 - val_loss: 2.1526 - val_accuracy: 0.8819\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 2.1209 - val_accuracy: 0.8819\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9965 - val_loss: 2.6396 - val_accuracy: 0.8750\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9983 - val_loss: 2.0223 - val_accuracy: 0.8750\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0277 - accuracy: 0.9965 - val_loss: 2.2866 - val_accuracy: 0.8958\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.1687 - val_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 0.9965 - val_loss: 2.6888 - val_accuracy: 0.8819\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 2.4887 - val_accuracy: 0.8958\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1949 - accuracy: 0.9878 - val_loss: 4.2530 - val_accuracy: 0.8681\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7423 - accuracy: 0.9601 - val_loss: 3.5289 - val_accuracy: 0.8819\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.9722 - val_loss: 3.5558 - val_accuracy: 0.8681\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.9809 - val_loss: 3.5887 - val_accuracy: 0.8681\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 3.4732 - val_accuracy: 0.8750\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0287 - accuracy: 0.9983 - val_loss: 2.6135 - val_accuracy: 0.8958\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0376 - accuracy: 0.9931 - val_loss: 3.0217 - val_accuracy: 0.8611\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.5998 - accuracy: 0.8833\n",
      "constant_q - Fold 2 Test accuracy: 0.8833\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 12.4879 - accuracy: 0.5885 - val_loss: 3.9649 - val_accuracy: 0.5625\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6678 - accuracy: 0.8854 - val_loss: 4.2188 - val_accuracy: 0.6111\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3504 - accuracy: 0.9167 - val_loss: 2.5127 - val_accuracy: 0.7014\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.9635 - val_loss: 2.8953 - val_accuracy: 0.7361\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5530 - accuracy: 0.9688 - val_loss: 2.3663 - val_accuracy: 0.7847\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0294 - accuracy: 0.9948 - val_loss: 2.8893 - val_accuracy: 0.7986\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9948 - val_loss: 2.1408 - val_accuracy: 0.8333\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.8125\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - accuracy: 0.9965 - val_loss: 2.0281 - val_accuracy: 0.8611\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 0.9931 - val_loss: 2.7387 - val_accuracy: 0.8125\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9896 - val_loss: 1.2937 - val_accuracy: 0.8889\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0602 - accuracy: 0.9913 - val_loss: 1.6127 - val_accuracy: 0.9028\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0580 - accuracy: 0.9844 - val_loss: 1.7760 - val_accuracy: 0.8681\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2213 - accuracy: 0.9792 - val_loss: 2.2124 - val_accuracy: 0.8750\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.9653 - val_loss: 2.6839 - val_accuracy: 0.8611\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.9705 - val_loss: 3.6627 - val_accuracy: 0.8958\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4792 - accuracy: 0.9601 - val_loss: 3.9347 - val_accuracy: 0.8819\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.2801 - accuracy: 0.9479 - val_loss: 4.4935 - val_accuracy: 0.8472\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2245 - accuracy: 0.9861 - val_loss: 3.2959 - val_accuracy: 0.8264\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2056 - accuracy: 0.9861 - val_loss: 2.3166 - val_accuracy: 0.8750\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 0.9792 - val_loss: 2.3504 - val_accuracy: 0.8958\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9913 - val_loss: 5.5198 - val_accuracy: 0.8264\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9931 - val_loss: 2.8976 - val_accuracy: 0.8889\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 2.9202 - val_accuracy: 0.8889\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9965 - val_loss: 2.7757 - val_accuracy: 0.9097\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 2.4944 - val_accuracy: 0.8958\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9983 - val_loss: 2.4159 - val_accuracy: 0.9028\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.6575e-09 - accuracy: 1.0000 - val_loss: 2.4534 - val_accuracy: 0.9028\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.4506e-09 - accuracy: 1.0000 - val_loss: 2.4741 - val_accuracy: 0.9028\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6557e-09 - accuracy: 1.0000 - val_loss: 2.4855 - val_accuracy: 0.9028\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.0696e-08 - accuracy: 1.0000 - val_loss: 2.4944 - val_accuracy: 0.9028\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.0359 - accuracy: 0.8889\n",
      "constant_q - Fold 3 Test accuracy: 0.8889\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 17.9384 - accuracy: 0.4948 - val_loss: 3.4788 - val_accuracy: 0.5833\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3141 - accuracy: 0.8611 - val_loss: 6.3434 - val_accuracy: 0.5139\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6256 - accuracy: 0.9479 - val_loss: 3.7961 - val_accuracy: 0.6389\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2636 - accuracy: 0.9635 - val_loss: 3.6636 - val_accuracy: 0.7153\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1899 - accuracy: 0.9826 - val_loss: 3.7905 - val_accuracy: 0.7431\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9878 - val_loss: 2.4067 - val_accuracy: 0.7986\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1253 - accuracy: 0.9774 - val_loss: 4.1921 - val_accuracy: 0.6806\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0577 - accuracy: 0.9896 - val_loss: 3.4826 - val_accuracy: 0.7778\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0641 - accuracy: 0.9931 - val_loss: 2.6014 - val_accuracy: 0.7986\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 2.5806 - val_accuracy: 0.8681\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0918 - accuracy: 0.9861 - val_loss: 3.2500 - val_accuracy: 0.7708\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.9774 - val_loss: 2.7521 - val_accuracy: 0.8333\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.9688 - val_loss: 1.5576 - val_accuracy: 0.9236\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.9809 - val_loss: 2.8640 - val_accuracy: 0.8681\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1499 - accuracy: 0.9861 - val_loss: 3.3108 - val_accuracy: 0.8819\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9913 - val_loss: 2.2286 - val_accuracy: 0.9028\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0634 - accuracy: 0.9913 - val_loss: 2.0198 - val_accuracy: 0.9167\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.9878 - val_loss: 3.4801 - val_accuracy: 0.8403\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2094 - accuracy: 0.9844 - val_loss: 2.6565 - val_accuracy: 0.8958\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1453 - accuracy: 0.9844 - val_loss: 2.9878 - val_accuracy: 0.9097\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0962 - accuracy: 0.9844 - val_loss: 3.7409 - val_accuracy: 0.8264\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9809 - val_loss: 3.1245 - val_accuracy: 0.8750\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 5.1061 - val_accuracy: 0.8194\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9913 - val_loss: 4.1276 - val_accuracy: 0.8333\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9948 - val_loss: 2.7011 - val_accuracy: 0.8889\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0825 - val_accuracy: 0.8889\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 2.5033 - val_accuracy: 0.9306\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 3.0196 - val_accuracy: 0.9097\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0390 - accuracy: 0.9965 - val_loss: 2.4733 - val_accuracy: 0.9375\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 2.8108 - val_accuracy: 0.9236\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 0.9983 - val_loss: 2.5361 - val_accuracy: 0.9028\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 2.6131 - val_accuracy: 0.8889\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.9983 - val_loss: 2.2859 - val_accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.4263 - accuracy: 0.8944\n",
      "constant_q - Fold 4 Test accuracy: 0.8944\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 12ms/step - loss: 13.2112 - accuracy: 0.5365 - val_loss: 2.8584 - val_accuracy: 0.6597\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.1169 - accuracy: 0.8351 - val_loss: 3.6045 - val_accuracy: 0.6736\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.7952 - accuracy: 0.9306 - val_loss: 4.4769 - val_accuracy: 0.6597\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.9757 - val_loss: 2.4186 - val_accuracy: 0.7847\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2482 - accuracy: 0.9705 - val_loss: 2.7930 - val_accuracy: 0.7500\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9913 - val_loss: 1.7600 - val_accuracy: 0.8889\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0683 - accuracy: 0.9931 - val_loss: 1.8759 - val_accuracy: 0.8542\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9931 - val_loss: 1.7973 - val_accuracy: 0.8611\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 0.9965 - val_loss: 2.0648 - val_accuracy: 0.8403\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0292 - accuracy: 0.9965 - val_loss: 2.0282 - val_accuracy: 0.8889\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 0.9983 - val_loss: 2.0269 - val_accuracy: 0.8819\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.0285 - val_accuracy: 0.8889\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.9768e-06 - accuracy: 1.0000 - val_loss: 2.0228 - val_accuracy: 0.8889\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.1034 - val_accuracy: 0.8958\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 0.9965 - val_loss: 1.7917 - val_accuracy: 0.8958\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.6494 - val_accuracy: 0.9236\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9896 - val_loss: 2.3930 - val_accuracy: 0.8889\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.0075e-04 - accuracy: 1.0000 - val_loss: 2.0866 - val_accuracy: 0.9028\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.5046e-05 - accuracy: 1.0000 - val_loss: 2.1592 - val_accuracy: 0.9097\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2528e-05 - accuracy: 1.0000 - val_loss: 2.2051 - val_accuracy: 0.9097\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.7505e-06 - accuracy: 1.0000 - val_loss: 2.2455 - val_accuracy: 0.9097\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.6371e-06 - accuracy: 1.0000 - val_loss: 2.2830 - val_accuracy: 0.9097\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.3541e-05 - accuracy: 1.0000 - val_loss: 2.3082 - val_accuracy: 0.9097\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.9124e-06 - accuracy: 1.0000 - val_loss: 2.3309 - val_accuracy: 0.9167\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.7340e-06 - accuracy: 1.0000 - val_loss: 2.3637 - val_accuracy: 0.9167\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.7630e-06 - accuracy: 1.0000 - val_loss: 2.3966 - val_accuracy: 0.9167\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.0159e-06 - accuracy: 1.0000 - val_loss: 2.4275 - val_accuracy: 0.9167\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1756e-06 - accuracy: 1.0000 - val_loss: 2.4562 - val_accuracy: 0.9236\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.4320e-06 - accuracy: 1.0000 - val_loss: 2.4823 - val_accuracy: 0.9236\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.6281e-06 - accuracy: 1.0000 - val_loss: 2.5057 - val_accuracy: 0.9236\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 7.0692e-07 - accuracy: 1.0000 - val_loss: 2.5269 - val_accuracy: 0.9236\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 8.8796e-07 - accuracy: 1.0000 - val_loss: 2.5459 - val_accuracy: 0.9236\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.5359e-07 - accuracy: 1.0000 - val_loss: 2.5628 - val_accuracy: 0.9236\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1667e-06 - accuracy: 1.0000 - val_loss: 2.5773 - val_accuracy: 0.9306\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3245e-06 - accuracy: 1.0000 - val_loss: 2.5902 - val_accuracy: 0.9306\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.3634e-07 - accuracy: 1.0000 - val_loss: 2.6014 - val_accuracy: 0.9306\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 1.3013 - accuracy: 0.9111\n",
      "constant_q - Fold 5 Test accuracy: 0.9111\n",
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [02:30<01:36, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for cqt\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 20.4457 - accuracy: 0.5764 - val_loss: 8.7055 - val_accuracy: 0.6181\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.5159 - accuracy: 0.9236 - val_loss: 9.0748 - val_accuracy: 0.6111\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.7723 - accuracy: 0.9635 - val_loss: 7.9474 - val_accuracy: 0.6458\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3747 - accuracy: 0.9774 - val_loss: 3.9144 - val_accuracy: 0.7639\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.8252 - accuracy: 0.9705 - val_loss: 4.0478 - val_accuracy: 0.8264\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2803 - accuracy: 0.9878 - val_loss: 4.8212 - val_accuracy: 0.8056\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1176 - accuracy: 0.9913 - val_loss: 3.9780 - val_accuracy: 0.7986\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9913 - val_loss: 2.5653 - val_accuracy: 0.9028\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6110 - accuracy: 0.9861 - val_loss: 3.1538 - val_accuracy: 0.8681\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9071 - accuracy: 0.9705 - val_loss: 1.9312 - val_accuracy: 0.8958\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.8904 - accuracy: 0.9653 - val_loss: 4.8945 - val_accuracy: 0.8125\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4557 - accuracy: 0.9809 - val_loss: 3.9636 - val_accuracy: 0.8750\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4061 - accuracy: 0.9826 - val_loss: 3.3634 - val_accuracy: 0.8889\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2411 - accuracy: 0.9844 - val_loss: 2.9757 - val_accuracy: 0.8611\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5389 - accuracy: 0.9757 - val_loss: 5.2080 - val_accuracy: 0.8611\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4390 - accuracy: 0.9826 - val_loss: 8.1401 - val_accuracy: 0.7917\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3945 - accuracy: 0.9844 - val_loss: 5.7963 - val_accuracy: 0.8611\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0520 - accuracy: 0.9948 - val_loss: 5.2976 - val_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0677 - accuracy: 0.9948 - val_loss: 5.5298 - val_accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2184 - val_accuracy: 0.9097\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0373 - accuracy: 0.9983 - val_loss: 5.4121 - val_accuracy: 0.8958\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9983 - val_loss: 4.7963 - val_accuracy: 0.9028\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.2418e-09 - accuracy: 1.0000 - val_loss: 4.5928 - val_accuracy: 0.9097\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.7134 - val_accuracy: 0.9028\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.8556 - val_accuracy: 0.9028\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.0015 - val_accuracy: 0.8958\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.1495 - val_accuracy: 0.8889\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2958 - val_accuracy: 0.8889\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.4419 - val_accuracy: 0.8958\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.5826 - val_accuracy: 0.9028\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7280 - accuracy: 0.9167\n",
      "cqt - Fold 1 Test accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 13ms/step - loss: 24.1066 - accuracy: 0.5938 - val_loss: 3.0512 - val_accuracy: 0.8194\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.1325 - accuracy: 0.9062 - val_loss: 4.3668 - val_accuracy: 0.8472\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.3688 - accuracy: 0.9566 - val_loss: 2.5371 - val_accuracy: 0.9097\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3949 - accuracy: 0.9826 - val_loss: 2.5255 - val_accuracy: 0.8819\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2014 - accuracy: 0.9896 - val_loss: 2.1927 - val_accuracy: 0.9097\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1397 - accuracy: 0.9878 - val_loss: 1.8094 - val_accuracy: 0.9236\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.9896 - val_loss: 4.3901 - val_accuracy: 0.8125\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3459 - accuracy: 0.9861 - val_loss: 2.7860 - val_accuracy: 0.9236\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0900 - accuracy: 0.9931 - val_loss: 2.0149 - val_accuracy: 0.9306\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.9878 - val_loss: 2.7520 - val_accuracy: 0.8958\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1196 - accuracy: 0.9931 - val_loss: 2.8882 - val_accuracy: 0.9028\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9948 - val_loss: 2.7335 - val_accuracy: 0.8542\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.9931 - val_loss: 2.6715 - val_accuracy: 0.8958\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1221 - accuracy: 0.9931 - val_loss: 2.4265 - val_accuracy: 0.9306\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0614 - accuracy: 0.9965 - val_loss: 2.9936 - val_accuracy: 0.9167\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1307 - accuracy: 0.9913 - val_loss: 3.1965 - val_accuracy: 0.8611\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9948 - val_loss: 2.0823 - val_accuracy: 0.9028\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 1.8092 - val_accuracy: 0.9236\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 1.7954 - val_accuracy: 0.9167\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0473 - accuracy: 0.9965 - val_loss: 3.7436 - val_accuracy: 0.8819\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2005 - accuracy: 0.9931 - val_loss: 3.1111 - val_accuracy: 0.9028\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3625 - accuracy: 0.9809 - val_loss: 5.1276 - val_accuracy: 0.8889\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.9878 - val_loss: 5.9437 - val_accuracy: 0.8958\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1898 - accuracy: 0.9913 - val_loss: 5.7965 - val_accuracy: 0.8542\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0412 - accuracy: 0.9948 - val_loss: 3.7157 - val_accuracy: 0.9097\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1348 - accuracy: 0.9965 - val_loss: 5.7095 - val_accuracy: 0.8819\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4355 - accuracy: 0.9826 - val_loss: 9.6453 - val_accuracy: 0.8750\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5482 - accuracy: 0.9792 - val_loss: 9.5477 - val_accuracy: 0.8889\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2008 - accuracy: 0.9878 - val_loss: 10.6744 - val_accuracy: 0.8889\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1693 - accuracy: 0.9913 - val_loss: 7.2762 - val_accuracy: 0.9167\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1562 - accuracy: 0.9948 - val_loss: 9.2219 - val_accuracy: 0.9028\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 0.9931 - val_loss: 4.9980 - val_accuracy: 0.9444\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2591 - val_accuracy: 0.9444\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0749 - accuracy: 0.9965 - val_loss: 5.1424 - val_accuracy: 0.9514\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0996 - accuracy: 0.9948 - val_loss: 3.9323 - val_accuracy: 0.9653\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0030 - accuracy: 0.9983 - val_loss: 5.3339 - val_accuracy: 0.9375\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.9965 - val_loss: 4.9694 - val_accuracy: 0.9306\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0762 - accuracy: 0.9983 - val_loss: 6.0488 - val_accuracy: 0.9097\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1662 - accuracy: 0.9931 - val_loss: 3.8257 - val_accuracy: 0.9444\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.3404 - accuracy: 0.9167\n",
      "cqt - Fold 2 Test accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 13ms/step - loss: 22.6932 - accuracy: 0.5972 - val_loss: 6.8730 - val_accuracy: 0.6597\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 5.3477 - accuracy: 0.8854 - val_loss: 5.4186 - val_accuracy: 0.7778\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.7828 - accuracy: 0.9288 - val_loss: 2.6402 - val_accuracy: 0.8194\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5789 - accuracy: 0.9757 - val_loss: 2.2129 - val_accuracy: 0.8403\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2884 - accuracy: 0.9826 - val_loss: 3.4042 - val_accuracy: 0.8125\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2152 - accuracy: 0.9861 - val_loss: 3.6382 - val_accuracy: 0.7986\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0582 - accuracy: 0.9965 - val_loss: 2.4707 - val_accuracy: 0.8611\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9948 - val_loss: 2.5335 - val_accuracy: 0.8958\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0604 - accuracy: 0.9948 - val_loss: 3.5282 - val_accuracy: 0.8403\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9948 - val_loss: 2.8595 - val_accuracy: 0.8819\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1077 - accuracy: 0.9965 - val_loss: 3.6457 - val_accuracy: 0.8472\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.9913 - val_loss: 3.6846 - val_accuracy: 0.8681\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9931 - val_loss: 4.5233 - val_accuracy: 0.8750\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2389 - accuracy: 0.9844 - val_loss: 3.3935 - val_accuracy: 0.8681\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3707 - accuracy: 0.9740 - val_loss: 2.2622 - val_accuracy: 0.8958\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5156 - accuracy: 0.9705 - val_loss: 7.0875 - val_accuracy: 0.7917\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6514 - accuracy: 0.9722 - val_loss: 6.5627 - val_accuracy: 0.8681\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4546 - accuracy: 0.9844 - val_loss: 6.6987 - val_accuracy: 0.8472\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1885 - accuracy: 0.9896 - val_loss: 5.7041 - val_accuracy: 0.8681\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1019 - accuracy: 0.9931 - val_loss: 4.6167 - val_accuracy: 0.8750\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 0.9913 - val_loss: 5.4239 - val_accuracy: 0.8542\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3693 - accuracy: 0.9896 - val_loss: 6.2138 - val_accuracy: 0.8403\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6819 - accuracy: 0.9688 - val_loss: 4.4473 - val_accuracy: 0.8958\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1915 - accuracy: 0.9826 - val_loss: 7.2018 - val_accuracy: 0.8750\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.0400 - accuracy: 0.8611\n",
      "cqt - Fold 3 Test accuracy: 0.8611\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 13ms/step - loss: 13.1732 - accuracy: 0.6528 - val_loss: 2.0519 - val_accuracy: 0.7569\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 3.9658 - accuracy: 0.8854 - val_loss: 1.3013 - val_accuracy: 0.8472\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.8140 - accuracy: 0.9253 - val_loss: 1.7274 - val_accuracy: 0.8472\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6524 - accuracy: 0.9688 - val_loss: 1.7676 - val_accuracy: 0.8889\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.9809 - val_loss: 2.3021 - val_accuracy: 0.8889\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1812 - accuracy: 0.9844 - val_loss: 1.6319 - val_accuracy: 0.9097\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3724 - accuracy: 0.9861 - val_loss: 1.2207 - val_accuracy: 0.9167\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0943 - accuracy: 0.9913 - val_loss: 2.6041 - val_accuracy: 0.8750\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1901 - accuracy: 0.9931 - val_loss: 1.9942 - val_accuracy: 0.9097\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0976 - accuracy: 0.9931 - val_loss: 4.9363 - val_accuracy: 0.8819\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9948 - val_loss: 1.0732 - val_accuracy: 0.9514\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0509 - accuracy: 0.9965 - val_loss: 1.1259 - val_accuracy: 0.9306\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0363 - accuracy: 0.9983 - val_loss: 1.9084 - val_accuracy: 0.9375\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1797 - accuracy: 0.9878 - val_loss: 1.5958 - val_accuracy: 0.9306\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.2554 - accuracy: 0.9861 - val_loss: 3.0999 - val_accuracy: 0.8750\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1442 - accuracy: 0.9913 - val_loss: 2.5790 - val_accuracy: 0.9028\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0253 - accuracy: 0.9983 - val_loss: 1.4996 - val_accuracy: 0.9167\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.9948 - val_loss: 2.4829 - val_accuracy: 0.9097\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9878 - val_loss: 2.7264 - val_accuracy: 0.9236\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1515 - accuracy: 0.9861 - val_loss: 7.1375 - val_accuracy: 0.8264\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5857 - accuracy: 0.9792 - val_loss: 4.5621 - val_accuracy: 0.8681\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3831 - accuracy: 0.9878 - val_loss: 6.2624 - val_accuracy: 0.8542\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0708 - accuracy: 0.9948 - val_loss: 2.8288 - val_accuracy: 0.9028\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 3.1621 - val_accuracy: 0.8889\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0200 - accuracy: 0.9983 - val_loss: 2.3679 - val_accuracy: 0.9236\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.4046 - val_accuracy: 0.9375\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 2.8352 - val_accuracy: 0.9236\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.7800e-04 - accuracy: 1.0000 - val_loss: 2.9898 - val_accuracy: 0.9167\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.4984e-04 - accuracy: 1.0000 - val_loss: 2.7799 - val_accuracy: 0.9236\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.6359e-08 - accuracy: 1.0000 - val_loss: 2.6244 - val_accuracy: 0.9236\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.7407e-05 - accuracy: 1.0000 - val_loss: 2.5459 - val_accuracy: 0.9236\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.7970 - accuracy: 0.9167\n",
      "cqt - Fold 4 Test accuracy: 0.9167\n",
      "6/6 [==============================] - 0s 6ms/step\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 13ms/step - loss: 24.4031 - accuracy: 0.5660 - val_loss: 6.8925 - val_accuracy: 0.5903\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 4.2467 - accuracy: 0.8681 - val_loss: 3.6317 - val_accuracy: 0.7917\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.1867 - accuracy: 0.9444 - val_loss: 1.4868 - val_accuracy: 0.8889\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6486 - accuracy: 0.9635 - val_loss: 1.7285 - val_accuracy: 0.9167\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1896 - accuracy: 0.9896 - val_loss: 1.3162 - val_accuracy: 0.9375\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0965 - accuracy: 0.9948 - val_loss: 1.5846 - val_accuracy: 0.9167\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0829 - accuracy: 0.9931 - val_loss: 1.6048 - val_accuracy: 0.9306\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 1.9576 - val_accuracy: 0.9167\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0707 - accuracy: 0.9931 - val_loss: 1.9717 - val_accuracy: 0.9167\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1311 - accuracy: 0.9861 - val_loss: 2.8427 - val_accuracy: 0.8681\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5807 - accuracy: 0.9722 - val_loss: 2.6872 - val_accuracy: 0.9167\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4722 - accuracy: 0.9774 - val_loss: 3.4129 - val_accuracy: 0.9236\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.2552 - accuracy: 0.9844 - val_loss: 2.3637 - val_accuracy: 0.9167\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1936 - accuracy: 0.9826 - val_loss: 4.3410 - val_accuracy: 0.8958\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.9931 - val_loss: 3.4539 - val_accuracy: 0.9375\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0514 - accuracy: 0.9965 - val_loss: 3.3797 - val_accuracy: 0.9375\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 5.2361e-05 - accuracy: 1.0000 - val_loss: 3.6357 - val_accuracy: 0.9375\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 5.2449e-05 - accuracy: 1.0000 - val_loss: 3.7725 - val_accuracy: 0.9444\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 5.8810e-07 - accuracy: 1.0000 - val_loss: 3.8538 - val_accuracy: 0.9444\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 4.5163e-05 - accuracy: 1.0000 - val_loss: 3.9237 - val_accuracy: 0.9375\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.1797e-08 - accuracy: 1.0000 - val_loss: 3.9896 - val_accuracy: 0.9375\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 2.8353e-08 - accuracy: 1.0000 - val_loss: 4.0504 - val_accuracy: 0.9375\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 6.6847e-08 - accuracy: 1.0000 - val_loss: 4.1047 - val_accuracy: 0.9375\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 2.0509e-07 - accuracy: 1.0000 - val_loss: 4.1529 - val_accuracy: 0.9375\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.4528e-07 - accuracy: 1.0000 - val_loss: 4.1951 - val_accuracy: 0.9375\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.9663 - accuracy: 0.9389\n",
      "cqt - Fold 5 Test accuracy: 0.9389\n",
      "6/6 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "Training features:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [02:59<01:18, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Training model for stft\n",
      "========================================\n",
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training features:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [03:00<01:17, 25.75s/it]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node stft/stft_output/BiasAdd defined at (most recent call last):\n  File \"/opt/conda/envs/myenv/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_5435/2621194921.py\", line 41, in <module>\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py\", line 252, in call\n\nMatrix size-incompatible: In[0]: [32,65536], In[1]: [131072,9]\n\t [[{{node stft/stft_output/BiasAdd}}]] [Op:__inference_train_function_368597]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 41\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m history_list\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node stft/stft_output/BiasAdd defined at (most recent call last):\n  File \"/opt/conda/envs/myenv/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/tmp/ipykernel_5435/2621194921.py\", line 41, in <module>\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/opt/conda/envs/myenv/lib/python3.9/site-packages/keras/src/layers/core/dense.py\", line 252, in call\n\nMatrix size-incompatible: In[0]: [32,65536], In[1]: [131072,9]\n\t [[{{node stft/stft_output/BiasAdd}}]] [Op:__inference_train_function_368597]"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for feature_type in tqdm(FEATURE_TYPES, desc=\"Training features\"):\n",
    "    print(f\"\\n{'='*40}\\nTraining model for {feature_type}\\n{'='*40}\")\n",
    "\n",
    "    feature_col = feature_type\n",
    "    feature_df = processed_df.dropna(subset=[feature_col])\n",
    "    \n",
    "    # Global label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(feature_df['instrumentID'])\n",
    "\n",
    "    feature_df = feature_df.copy()\n",
    "    feature_df['instrumentID'] = label_encoder.transform(feature_df['instrumentID'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    input_shape = get_input_shape(feature_type)\n",
    "\n",
    "    kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    accuracy_list, loss_list, history_list = [], [], []\n",
    "    classification_reports, confusion_matrices = [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(feature_df)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{KFOLD_SPLITS} ---\")\n",
    "        train_df = feature_df.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = feature_df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df, test_size=0.2, random_state=42, stratify=train_df['instrumentID'])\n",
    "\n",
    "        # Generators (labels are already encoded)\n",
    "        train_gen = SingleFeatureDataGenerator(train_df, feature_col, BATCH_SIZE, shuffle=True, num_classes=num_classes)\n",
    "        val_gen   = SingleFeatureDataGenerator(val_df,   feature_col, BATCH_SIZE, shuffle=False, num_classes=num_classes)\n",
    "        test_gen  = SingleFeatureDataGenerator(test_df,  feature_col, BATCH_SIZE, shuffle=False, num_classes=num_classes)\n",
    "\n",
    "        # Model\n",
    "        model = create_simple_model(input_shape, num_classes, model_name=feature_type)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "        history = model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS, callbacks=[early_stopping])\n",
    "        history_list.append(history.history)\n",
    "\n",
    "        # Evaluation\n",
    "        loss, acc = model.evaluate(test_gen)\n",
    "        loss_list.append(loss)\n",
    "        accuracy_list.append(acc)\n",
    "        print(f\"{feature_type} - Fold {fold+1} Test accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Predictions & Reports\n",
    "        y_pred = model.predict(test_gen)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = []\n",
    "        for _, labels in test_gen:\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "        y_true = np.array(y_true)\n",
    "\n",
    "        report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "        classification_reports.append(report)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_classes).tolist()\n",
    "        confusion_matrices.append(conf_matrix)\n",
    "\n",
    "        # Save model\n",
    "        os.makedirs(f\"models/{feature_type}\", exist_ok=True)\n",
    "        model.save(f\"models/{feature_type}/model_fold{fold+1}.h5\")\n",
    "\n",
    "    # Save results\n",
    "    results[feature_type] = {\n",
    "        \"accuracy_list\": accuracy_list,\n",
    "        \"loss_list\": loss_list,\n",
    "        \"histories\": history_list,\n",
    "        \"classification_reports\": classification_reports,\n",
    "        \"confusion_matrices\": confusion_matrices,\n",
    "    }\n",
    "\n",
    "    with open(f\"models/{feature_type}/results.json\", \"w\") as f:\n",
    "        json.dump(results[feature_type], f, indent=2)\n",
    "\n",
    "print(\"\\nAll training complete. Models and results saved in 'models/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble predictions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Ensemble Predictions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the last fold of each feature type for ensemble evaluation\n",
    "ensemble_results = {\n",
    "    'accuracy_list': [],\n",
    "    'loss_list': [],\n",
    "    'classification_reports': [],\n",
    "    'confusion_matrices': []\n",
    "}\n",
    "\n",
    "# For simplicity, we'll use the last fold of each feature type\n",
    "for fold in tqdm(range(KFOLD_SPLITS), desc = \"Ensemble Folds\", Leave = True):\n",
    "    print(f\"\\n--- Ensemble Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "    \n",
    "    # Get predictions from all models for this fold\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for feature_type in available_feature_types:\n",
    "        if feature_type in all_results:\n",
    "            # Get the model from this fold\n",
    "            model = all_results[feature_type]['models'][fold]\n",
    "            \n",
    "            # Get test data for this fold (we need to recreate it)\n",
    "            df = df_dict[feature_type]\n",
    "            kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "            train_idx, test_idx = list(kf.split(df))[fold]\n",
    "            test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "            \n",
    "            test_generator = SingleFeatureDataGenerator(test_df, feature_type, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred = model.predict(test_generator, verbose=0)\n",
    "            all_predictions[feature_type] = pred\n",
    "            \n",
    "            # Store true labels (should be the same for all feature types)\n",
    "            if 'y_true' not in locals():\n",
    "                y_true = test_generator.get_labels()\n",
    "    \n",
    "    # Simple averaging ensemble\n",
    "    if all_predictions:\n",
    "        ensemble_pred = np.mean(list(all_predictions.values()), axis=0)\n",
    "        ensemble_pred_classes = np.argmax(ensemble_pred, axis=1)\n",
    "        \n",
    "        # Calculate ensemble accuracy\n",
    "        ensemble_accuracy = accuracy_score(y_true, ensemble_pred_classes)\n",
    "        ensemble_results['accuracy_list'].append(ensemble_accuracy)\n",
    "        \n",
    "        print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_true, ensemble_pred_classes, output_dict=True)\n",
    "        ensemble_results['classification_reports'].append(report)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, ensemble_pred_classes).tolist()\n",
    "        ensemble_results['confusion_matrices'].append(conf_matrix)\n",
    "\n",
    "# Store ensemble results\n",
    "all_results['ensemble'] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and models\n",
    "try:\n",
    "    os.mkdir(\"ensemble_models\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists\")\n",
    "except Exception:\n",
    "    print(\"Unknown error\")\n",
    "\n",
    "# Create version folder\n",
    "date_part = datetime.now().date().__str__().replace('-', '_')\n",
    "last_version = os.listdir(path=\"ensemble_models\") if os.path.exists(\"ensemble_models\") else []\n",
    "last_version = [name.rpartition(\"_v\")[-1] for name in last_version if date_part in name]\n",
    "if len(last_version):\n",
    "    last_version = int(sorted(last_version)[-1])\n",
    "else:\n",
    "    last_version = 0\n",
    "folder_name = f\"{date_part}_v{last_version+1}\"\n",
    "\n",
    "os.makedirs(os.path.join(\"ensemble_models\", folder_name), exist_ok=True)\n",
    "\n",
    "# Save individual models\n",
    "for feature_type, model in all_models.items():\n",
    "    model_path = os.path.join(\"ensemble_models\", folder_name, f\"{feature_type}_model.h5\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Saved {feature_type} model to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "results_data = {\n",
    "    'individual_results': {ft: {k: v for k, v in res.items() if k != 'models'} \n",
    "                          for ft, res in all_results.items() if ft != 'ensemble'},\n",
    "    'ensemble_results': all_results['ensemble'],\n",
    "    'feature_types': available_feature_types,\n",
    "    'num_classes': num_classes,\n",
    "    'feature_shapes': FEATURE_SHAPES,\n",
    "    'training_config': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'kfold_splits': KFOLD_SPLITS,\n",
    "        'fixed_length': FIXED_LENGTH\n",
    "    },\n",
    "    'instrument_mappings': instruments_mappings.to_dict()\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"ensemble_models\", folder_name, \"results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_path}\")\n",
    "print(f\"Models saved to: ensemble_models/{folder_name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nIndividual Model Performance:\")\n",
    "for feature_type in available_feature_types:\n",
    "    if feature_type in all_results:\n",
    "        accuracies = all_results[feature_type]['accuracy_list']\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        print(f\"  {feature_type}: {mean_acc:.4f} Â± {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble Performance:\")\n",
    "if 'ensemble' in all_results:\n",
    "    ensemble_accuracies = all_results['ensemble']['accuracy_list']\n",
    "    ensemble_mean = np.mean(ensemble_accuracies)\n",
    "    ensemble_std = np.std(ensemble_accuracies)\n",
    "    print(f\"  Ensemble: {ensemble_mean:.4f} Â± {ensemble_std:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "best_individual = max(\n",
    "    [(ft, np.mean(all_results[ft]['accuracy_list'])) \n",
    "     for ft in available_feature_types if ft in all_results],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "improvement = ensemble_mean - best_individual[1]\n",
    "print(f\"\\nBest Individual Model: {best_individual[0]} ({best_individual[1]:.4f})\")\n",
    "print(f\"Ensemble Improvement: {improvement:.4f} ({improvement*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
