{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model Training - Simplified Single-Branch Models\n",
    "\n",
    "This notebook trains separate simplified CNN models for each feature type and then creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from modules.PostgresDBHandler import PostgresDBHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "dbParams = {\n",
    "    \"dbname\": \"mydatabase\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"host\": \"postgres_server\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 32\n",
    "KFOLD_SPLITS = 5\n",
    "FIXED_LENGTH = 128\n",
    "\n",
    "# Feature types to train models for\n",
    "FEATURE_TYPES = [\n",
    "    'mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast',\n",
    "    'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength'\n",
    "]\n",
    "\n",
    "# Feature shapes for each type\n",
    "FEATURE_SHAPES = {\n",
    "    'mel_spectrogram': (64, 128),\n",
    "    'mfcc': (8, 128),\n",
    "    'chromagram': (8, 128),\n",
    "    'spectral_contrast': (3, 128),\n",
    "    'tonnetz': (6, 128),\n",
    "    'constant_q': (42, 128),\n",
    "    'cqt': (42, 128),\n",
    "    'stft': (512, 128),\n",
    "    'harmonic_percussive': (1025, 128),\n",
    "    'onset_strength': (1, 128)\n",
    "}\n",
    "# GPU configuration\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Number of available GPUs: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instrument classes: 9\n",
      "Instruments: ['cello', 'bass', 'oboe', 'violin', 'flute', 'trumpet', 'piccolo', 'clarinet', 'sax']\n"
     ]
    }
   ],
   "source": [
    "# Initialize database connection\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get instrument mappings\n",
    "instruments_mappings = db.get_mappings_instruments()\n",
    "num_classes = len(instruments_mappings)\n",
    "print(f\"Number of instrument classes: {num_classes}\")\n",
    "print(\"Instruments:\", instruments_mappings['name'].tolist())\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleFeatureDataGenerator(Sequence):\n",
    "    def __init__(self, df, feature_type, label_encoder, batch_size=32, shuffle=True):\n",
    "        self.df = df.copy()  # Just to be safe\n",
    "        self.feature_type = feature_type\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "        # Transform labels using the external encoder (DON'T fit again!)\n",
    "        self.df['instrumentID_encoded'] = self.label_encoder.transform(self.df['instrumentID'])\n",
    "        self.num_classes = len(self.label_encoder.classes_)\n",
    "        self.indices = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[indices]\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for _, row in batch_df.iterrows():\n",
    "            feature_data = np.load(row['featurePath'])\n",
    "            X.append(feature_data)\n",
    "            y.append(row['instrumentID_encoded'])\n",
    "        \n",
    "        X = np.expand_dims(np.array(X), -1)\n",
    "        y = to_categorical(y, num_classes=self.num_classes)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.df.iloc[self.indices]['instrumentID_encoded'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_model(input_shape, num_classes, model_name=\"simple_cnn\"):    \n",
    "    \"\"\"Create a simplified single-branch CNN model with reduced capacity.\"\"\"\n",
    "    input_layer = Input(shape=(*input_shape, 1), name=f\"{model_name}_input\")\n",
    "    \n",
    "    # Reduced number of filters and layers compared to original\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Reduced dense layers\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Smaller final dense layer\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax', name=f\"{model_name}_output\")(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output, name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed samples: 9000\n",
      "mel_spectrogram: 900 samples\n",
      "mfcc: 900 samples\n",
      "chromagram: 900 samples\n",
      "spectral_contrast: 900 samples\n",
      "tonnetz: 900 samples\n",
      "constant_q: 900 samples\n",
      "cqt: 900 samples\n",
      "stft: 900 samples\n",
      "harmonic_percussive: 900 samples\n",
      "onset_strength: 900 samples\n",
      "\n",
      "Available feature types: ['mel_spectrogram', 'mfcc', 'chromagram', 'spectral_contrast', 'tonnetz', 'constant_q', 'cqt', 'stft', 'harmonic_percussive', 'onset_strength']\n"
     ]
    }
   ],
   "source": [
    "# Load data for each feature type\n",
    "db = PostgresDBHandler(**dbParams)\n",
    "db.connect()\n",
    "\n",
    "# Get all processed IDs\n",
    "processed_ids = db.get_all_processed_ids()\n",
    "print(f\"Total processed samples: {len(processed_ids)}\")\n",
    "\n",
    "# Create DataFrames for each feature type\n",
    "df_dict = {}\n",
    "for feature_type in FEATURE_TYPES:\n",
    "    processed_data = db.get_processed_fit_data(processed_ids, feature_type)\n",
    "    \n",
    "    if processed_data:\n",
    "        df = pd.DataFrame(processed_data)\n",
    "        df_dict[feature_type] = df\n",
    "        print(f\"{feature_type}: {len(df)} samples\")\n",
    "    else:\n",
    "        print(f\"Warning: No data found for {feature_type}\")\n",
    "\n",
    "db.close()\n",
    "\n",
    "# Filter to only include feature types with data\n",
    "available_feature_types = list(df_dict.keys())\n",
    "print(f\"\\nAvailable feature types: {available_feature_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d546609c7f4958945c39205654e31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Feature Types:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training model for mel_spectrogram\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66359954c7754dc88e392d56005b1d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mel_spectrogram Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 2.1973 - accuracy: 0.0981 - val_loss: 2.1985 - val_accuracy: 0.0903\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1304 - val_loss: 2.1995 - val_accuracy: 0.0903\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1963 - accuracy: 0.1186 - val_loss: 2.2008 - val_accuracy: 0.0903\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1367 - val_loss: 2.2018 - val_accuracy: 0.0903\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1142 - val_loss: 2.2031 - val_accuracy: 0.0903\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1152 - val_loss: 2.2041 - val_accuracy: 0.0903\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1369 - val_loss: 2.2052 - val_accuracy: 0.0903\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1027 - val_loss: 2.2064 - val_accuracy: 0.0486\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1322 - val_loss: 2.2073 - val_accuracy: 0.0903\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1181 - val_loss: 2.2082 - val_accuracy: 0.0903\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1261 - val_loss: 2.2092 - val_accuracy: 0.0903\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1928 - accuracy: 0.1232 - val_loss: 2.2102 - val_accuracy: 0.0903\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1345 - val_loss: 2.2108 - val_accuracy: 0.0903\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1919 - accuracy: 0.1367 - val_loss: 2.2117 - val_accuracy: 0.0903\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1923 - accuracy: 0.1362 - val_loss: 2.2126 - val_accuracy: 0.0903\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1407 - val_loss: 2.2133 - val_accuracy: 0.0903\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1262 - val_loss: 2.2140 - val_accuracy: 0.0903\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1932 - accuracy: 0.1223 - val_loss: 2.2149 - val_accuracy: 0.0903\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1943 - accuracy: 0.1088 - val_loss: 2.2157 - val_accuracy: 0.0903\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.1091 - val_loss: 2.2165 - val_accuracy: 0.0903\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1147 - val_loss: 2.2170 - val_accuracy: 0.0903\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1934 - accuracy: 0.1352 - val_loss: 2.2177 - val_accuracy: 0.0903\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1897 - accuracy: 0.1528 - val_loss: 2.2185 - val_accuracy: 0.0903\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1896 - accuracy: 0.1544 - val_loss: 2.2192 - val_accuracy: 0.0903\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1895 - accuracy: 0.1455 - val_loss: 2.2199 - val_accuracy: 0.0903\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1385 - val_loss: 2.2203 - val_accuracy: 0.0903\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1894 - accuracy: 0.1327 - val_loss: 2.2210 - val_accuracy: 0.0903\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1085 - val_loss: 2.2214 - val_accuracy: 0.0903\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1923 - accuracy: 0.1298 - val_loss: 2.2221 - val_accuracy: 0.0903\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1903 - accuracy: 0.1375 - val_loss: 2.2227 - val_accuracy: 0.0903\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1936 - accuracy: 0.1086 - val_loss: 2.2233 - val_accuracy: 0.0903\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1921 - accuracy: 0.1143 - val_loss: 2.2237 - val_accuracy: 0.0903\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1924 - accuracy: 0.1299 - val_loss: 2.2243 - val_accuracy: 0.0903\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1904 - accuracy: 0.1253 - val_loss: 2.2248 - val_accuracy: 0.0903\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1916 - accuracy: 0.1316 - val_loss: 2.2250 - val_accuracy: 0.0903\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1940 - accuracy: 0.1175 - val_loss: 2.2256 - val_accuracy: 0.0903\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1910 - accuracy: 0.1401 - val_loss: 2.2262 - val_accuracy: 0.0903\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1345 - val_loss: 2.2264 - val_accuracy: 0.0903\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1903 - accuracy: 0.1320 - val_loss: 2.2270 - val_accuracy: 0.0903\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1908 - accuracy: 0.1477 - val_loss: 2.2273 - val_accuracy: 0.0903\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1925 - accuracy: 0.1222 - val_loss: 2.2277 - val_accuracy: 0.0903\n",
      "Accuracy: 0.0833, Loss: 2.1977\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 2.2646 - accuracy: 0.1170 - val_loss: 2.2087 - val_accuracy: 0.0833\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.6494 - accuracy: 0.0977 - val_loss: 2.2172 - val_accuracy: 0.1181\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.5714 - accuracy: 0.1250 - val_loss: 2.2246 - val_accuracy: 0.1111\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3973 - accuracy: 0.1332 - val_loss: 2.2796 - val_accuracy: 0.0833\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3381 - accuracy: 0.1061 - val_loss: 2.4943 - val_accuracy: 0.0556\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3546 - accuracy: 0.0979 - val_loss: 2.5004 - val_accuracy: 0.0833\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4018 - accuracy: 0.1011 - val_loss: 2.5122 - val_accuracy: 0.1181\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4271 - accuracy: 0.1209 - val_loss: 2.4426 - val_accuracy: 0.1181\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3354 - accuracy: 0.0904 - val_loss: 2.3612 - val_accuracy: 0.0972\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3096 - accuracy: 0.1365 - val_loss: 2.8004 - val_accuracy: 0.1042\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3535 - accuracy: 0.1133 - val_loss: 2.6032 - val_accuracy: 0.0694\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3268 - accuracy: 0.1078 - val_loss: 2.9999 - val_accuracy: 0.1042\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2994 - accuracy: 0.1134 - val_loss: 2.7519 - val_accuracy: 0.0833\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2591 - accuracy: 0.1189 - val_loss: 4.2527 - val_accuracy: 0.0972\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3180 - accuracy: 0.1232 - val_loss: 2.8289 - val_accuracy: 0.1042\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2831 - accuracy: 0.1177 - val_loss: 2.6893 - val_accuracy: 0.1042\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2564 - accuracy: 0.1223 - val_loss: 3.0999 - val_accuracy: 0.1250\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2179 - accuracy: 0.1400 - val_loss: 2.7095 - val_accuracy: 0.1042\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2740 - accuracy: 0.1272 - val_loss: 2.6479 - val_accuracy: 0.1042\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2379 - accuracy: 0.1583 - val_loss: 2.8161 - val_accuracy: 0.0972\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2841 - accuracy: 0.1104 - val_loss: 2.9259 - val_accuracy: 0.0972\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2519 - accuracy: 0.0946 - val_loss: 3.1601 - val_accuracy: 0.0903\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2506 - accuracy: 0.1312 - val_loss: 2.4582 - val_accuracy: 0.0903\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2020 - accuracy: 0.1243 - val_loss: 2.2529 - val_accuracy: 0.1042\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2210 - accuracy: 0.1145 - val_loss: 2.2857 - val_accuracy: 0.1042\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2495 - accuracy: 0.1220 - val_loss: 2.4244 - val_accuracy: 0.1042\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2260 - accuracy: 0.1130 - val_loss: 2.2576 - val_accuracy: 0.1111\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2117 - accuracy: 0.0956 - val_loss: 2.2167 - val_accuracy: 0.1250\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2151 - accuracy: 0.0882 - val_loss: 2.3061 - val_accuracy: 0.0903\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2015 - accuracy: 0.1214 - val_loss: 2.3016 - val_accuracy: 0.1042\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2364 - accuracy: 0.1035 - val_loss: 2.2593 - val_accuracy: 0.0972\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2298 - accuracy: 0.1229 - val_loss: 2.2314 - val_accuracy: 0.0903\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2268 - accuracy: 0.1262 - val_loss: 2.2335 - val_accuracy: 0.0972\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2291 - accuracy: 0.1224 - val_loss: 2.2504 - val_accuracy: 0.1042\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2189 - accuracy: 0.1244 - val_loss: 2.2258 - val_accuracy: 0.1042\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2292 - accuracy: 0.1158 - val_loss: 2.3503 - val_accuracy: 0.0972\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2042 - accuracy: 0.1408 - val_loss: 2.3169 - val_accuracy: 0.0903\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2167 - accuracy: 0.1381 - val_loss: 2.4952 - val_accuracy: 0.0972\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2070 - accuracy: 0.1224 - val_loss: 2.5265 - val_accuracy: 0.0903\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1917 - accuracy: 0.1497 - val_loss: 2.5001 - val_accuracy: 0.0972\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2004 - accuracy: 0.1327 - val_loss: 2.5009 - val_accuracy: 0.1042\n",
      "Accuracy: 0.1389, Loss: 24.7934\n",
      "\n",
      "--- Fold 3/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 2.4261 - accuracy: 0.1053 - val_loss: 4.0921 - val_accuracy: 0.0764\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.5140 - accuracy: 0.1104 - val_loss: 2.6525 - val_accuracy: 0.0833\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4619 - accuracy: 0.0990 - val_loss: 2.3604 - val_accuracy: 0.0764\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4223 - accuracy: 0.1152 - val_loss: 2.4475 - val_accuracy: 0.1458\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4089 - accuracy: 0.1117 - val_loss: 2.2160 - val_accuracy: 0.1389\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3538 - accuracy: 0.1260 - val_loss: 2.2541 - val_accuracy: 0.1111\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3532 - accuracy: 0.1064 - val_loss: 2.2798 - val_accuracy: 0.1111\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3053 - accuracy: 0.0820 - val_loss: 2.2436 - val_accuracy: 0.0903\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3102 - accuracy: 0.1117 - val_loss: 2.2120 - val_accuracy: 0.1111\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3028 - accuracy: 0.1188 - val_loss: 2.2230 - val_accuracy: 0.0833\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2994 - accuracy: 0.1088 - val_loss: 2.2186 - val_accuracy: 0.0972\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2975 - accuracy: 0.1031 - val_loss: 2.2062 - val_accuracy: 0.1181\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2959 - accuracy: 0.1117 - val_loss: 2.2204 - val_accuracy: 0.1181\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2802 - accuracy: 0.1114 - val_loss: 2.2240 - val_accuracy: 0.0903\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2488 - accuracy: 0.1143 - val_loss: 3.9835 - val_accuracy: 0.0694\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2893 - accuracy: 0.1187 - val_loss: 2.3201 - val_accuracy: 0.1042\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2712 - accuracy: 0.1106 - val_loss: 2.3330 - val_accuracy: 0.0764\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2740 - accuracy: 0.1169 - val_loss: 2.3835 - val_accuracy: 0.1111\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2835 - accuracy: 0.0926 - val_loss: 2.3905 - val_accuracy: 0.0833\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2499 - accuracy: 0.1213 - val_loss: 2.4585 - val_accuracy: 0.1736\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2358 - accuracy: 0.1216 - val_loss: 2.3639 - val_accuracy: 0.1458\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2267 - accuracy: 0.1280 - val_loss: 2.3078 - val_accuracy: 0.0903\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2198 - accuracy: 0.1425 - val_loss: 2.2866 - val_accuracy: 0.1319\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2523 - accuracy: 0.0805 - val_loss: 2.3454 - val_accuracy: 0.1458\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2484 - accuracy: 0.1028 - val_loss: 2.7721 - val_accuracy: 0.0625\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2487 - accuracy: 0.0911 - val_loss: 2.7874 - val_accuracy: 0.1111\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2428 - accuracy: 0.0929 - val_loss: 3.1913 - val_accuracy: 0.1181\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2493 - accuracy: 0.0985 - val_loss: 2.6832 - val_accuracy: 0.0903\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2386 - accuracy: 0.1072 - val_loss: 2.5843 - val_accuracy: 0.1042\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2507 - accuracy: 0.1032 - val_loss: 2.7332 - val_accuracy: 0.0903\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2119 - accuracy: 0.1270 - val_loss: 2.5956 - val_accuracy: 0.1250\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2243 - accuracy: 0.1130 - val_loss: 2.7375 - val_accuracy: 0.1250\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2287 - accuracy: 0.1175 - val_loss: 2.7604 - val_accuracy: 0.1250\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2421 - accuracy: 0.1046 - val_loss: 2.6854 - val_accuracy: 0.1111\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2313 - accuracy: 0.1284 - val_loss: 2.3704 - val_accuracy: 0.1042\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2573 - accuracy: 0.1059 - val_loss: 2.3001 - val_accuracy: 0.1111\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2132 - accuracy: 0.1480 - val_loss: 2.3565 - val_accuracy: 0.0764\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2154 - accuracy: 0.1017 - val_loss: 2.2647 - val_accuracy: 0.0972\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2139 - accuracy: 0.1399 - val_loss: 2.3112 - val_accuracy: 0.1389\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2218 - accuracy: 0.0817 - val_loss: 2.3925 - val_accuracy: 0.0764\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2135 - accuracy: 0.1028 - val_loss: 2.5516 - val_accuracy: 0.0833\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2157 - accuracy: 0.1247 - val_loss: 2.7482 - val_accuracy: 0.1181\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.2083 - accuracy: 0.1157 - val_loss: 2.6165 - val_accuracy: 0.1389\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2122 - accuracy: 0.1185 - val_loss: 2.5972 - val_accuracy: 0.0833\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.2241 - accuracy: 0.0918 - val_loss: 2.9765 - val_accuracy: 0.0903\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2227 - accuracy: 0.1072 - val_loss: 2.6027 - val_accuracy: 0.1111\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2295 - accuracy: 0.1259 - val_loss: 3.1984 - val_accuracy: 0.0764\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2247 - accuracy: 0.1067 - val_loss: 2.8288 - val_accuracy: 0.1250\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2053 - accuracy: 0.1066 - val_loss: 2.6182 - val_accuracy: 0.1111\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2002 - accuracy: 0.0994 - val_loss: 2.5827 - val_accuracy: 0.1111\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1989 - accuracy: 0.0873 - val_loss: 2.6947 - val_accuracy: 0.1319\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2034 - accuracy: 0.1269 - val_loss: 2.8372 - val_accuracy: 0.0972\n",
      "Accuracy: 0.0889, Loss: 4.2889\n",
      "\n",
      "--- Fold 4/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 2.5434 - accuracy: 0.1081 - val_loss: 2.5675 - val_accuracy: 0.0764\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.4369 - accuracy: 0.1213 - val_loss: 2.2004 - val_accuracy: 0.0903\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3863 - accuracy: 0.1113 - val_loss: 2.5075 - val_accuracy: 0.1319\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3904 - accuracy: 0.0766 - val_loss: 2.2073 - val_accuracy: 0.1389\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3461 - accuracy: 0.0952 - val_loss: 2.5762 - val_accuracy: 0.1111\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3728 - accuracy: 0.0811 - val_loss: 2.2780 - val_accuracy: 0.1042\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3732 - accuracy: 0.0940 - val_loss: 2.3636 - val_accuracy: 0.1181\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3105 - accuracy: 0.1291 - val_loss: 21.8024 - val_accuracy: 0.1319\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2714 - accuracy: 0.1465 - val_loss: 2.5135 - val_accuracy: 0.0903\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3321 - accuracy: 0.1050 - val_loss: 2.3525 - val_accuracy: 0.0903\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3353 - accuracy: 0.1277 - val_loss: 4.7385 - val_accuracy: 0.1250\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.3011 - accuracy: 0.0921 - val_loss: 2.4844 - val_accuracy: 0.1319\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2699 - accuracy: 0.1525 - val_loss: 2.2890 - val_accuracy: 0.1250\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2762 - accuracy: 0.0956 - val_loss: 2.2715 - val_accuracy: 0.1458\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2692 - accuracy: 0.1352 - val_loss: 2.2548 - val_accuracy: 0.0972\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2617 - accuracy: 0.1089 - val_loss: 2.2065 - val_accuracy: 0.1042\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2400 - accuracy: 0.1095 - val_loss: 2.2010 - val_accuracy: 0.1111\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2807 - accuracy: 0.1016 - val_loss: 2.2018 - val_accuracy: 0.1250\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2550 - accuracy: 0.1249 - val_loss: 2.2104 - val_accuracy: 0.1042\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2658 - accuracy: 0.0906 - val_loss: 2.2533 - val_accuracy: 0.1389\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2440 - accuracy: 0.1120 - val_loss: 4.7009 - val_accuracy: 0.1042\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2456 - accuracy: 0.1465 - val_loss: 2.8958 - val_accuracy: 0.1389\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2505 - accuracy: 0.0981 - val_loss: 2.2034 - val_accuracy: 0.1181\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2476 - accuracy: 0.1044 - val_loss: 5.4209 - val_accuracy: 0.1458\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2084 - accuracy: 0.1339 - val_loss: 12.0471 - val_accuracy: 0.1389\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2452 - accuracy: 0.1353 - val_loss: 2.2086 - val_accuracy: 0.0972\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2506 - accuracy: 0.1273 - val_loss: 2.2082 - val_accuracy: 0.1042\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2335 - accuracy: 0.1142 - val_loss: 2.7748 - val_accuracy: 0.1319\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2277 - accuracy: 0.1119 - val_loss: 2.2082 - val_accuracy: 0.1250\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2204 - accuracy: 0.1546 - val_loss: 2.2095 - val_accuracy: 0.1111\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2094 - accuracy: 0.1206 - val_loss: 2.2169 - val_accuracy: 0.1250\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2432 - accuracy: 0.0969 - val_loss: 2.2082 - val_accuracy: 0.1111\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2264 - accuracy: 0.1102 - val_loss: 2.2161 - val_accuracy: 0.0764\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2210 - accuracy: 0.1410 - val_loss: 2.2070 - val_accuracy: 0.1250\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2235 - accuracy: 0.1260 - val_loss: 2.2070 - val_accuracy: 0.1389\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2122 - accuracy: 0.1567 - val_loss: 2.2218 - val_accuracy: 0.1319\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2068 - accuracy: 0.1152 - val_loss: 2.2561 - val_accuracy: 0.1181\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2037 - accuracy: 0.1426 - val_loss: 2.2028 - val_accuracy: 0.1250\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2207 - accuracy: 0.1224 - val_loss: 2.1953 - val_accuracy: 0.1181\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2076 - accuracy: 0.0849 - val_loss: 2.1962 - val_accuracy: 0.1319\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2063 - accuracy: 0.1378 - val_loss: 2.2051 - val_accuracy: 0.1319\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2052 - accuracy: 0.1321 - val_loss: 2.2007 - val_accuracy: 0.1181\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2006 - accuracy: 0.1178 - val_loss: 12.2089 - val_accuracy: 0.1042\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2016 - accuracy: 0.1266 - val_loss: 2.2109 - val_accuracy: 0.1250\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2109 - accuracy: 0.0992 - val_loss: 2.2862 - val_accuracy: 0.1111\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2020 - accuracy: 0.1103 - val_loss: 2.4183 - val_accuracy: 0.1181\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2028 - accuracy: 0.1366 - val_loss: 2.3619 - val_accuracy: 0.1389\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2014 - accuracy: 0.1176 - val_loss: 2.2815 - val_accuracy: 0.1042\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2129 - accuracy: 0.0838 - val_loss: 2.2329 - val_accuracy: 0.1250\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2037 - accuracy: 0.1135 - val_loss: 13.9313 - val_accuracy: 0.1389\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2076 - accuracy: 0.1253 - val_loss: 4.1133 - val_accuracy: 0.1389\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2069 - accuracy: 0.1164 - val_loss: 3.3601 - val_accuracy: 0.0833\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2033 - accuracy: 0.1031 - val_loss: 2.4764 - val_accuracy: 0.1319\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2013 - accuracy: 0.1113 - val_loss: 2.2608 - val_accuracy: 0.1111\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2047 - accuracy: 0.1046 - val_loss: 2.3087 - val_accuracy: 0.1042\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1987 - accuracy: 0.1217 - val_loss: 5.7060 - val_accuracy: 0.1250\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2173 - accuracy: 0.1184 - val_loss: 4.4040 - val_accuracy: 0.1111\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.2092 - accuracy: 0.0914 - val_loss: 2.4123 - val_accuracy: 0.1458\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2022 - accuracy: 0.1302 - val_loss: 2.2025 - val_accuracy: 0.1319\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2076 - accuracy: 0.1342 - val_loss: 2.1977 - val_accuracy: 0.1111\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2003 - accuracy: 0.1527 - val_loss: 2.2013 - val_accuracy: 0.1319\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1207 - val_loss: 2.2026 - val_accuracy: 0.0764\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1433 - val_loss: 2.2079 - val_accuracy: 0.0903\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2089 - accuracy: 0.1093 - val_loss: 2.2028 - val_accuracy: 0.0972\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1904 - accuracy: 0.1260 - val_loss: 2.2014 - val_accuracy: 0.0833\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2064 - accuracy: 0.1178 - val_loss: 2.1979 - val_accuracy: 0.1319\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2094 - accuracy: 0.1076 - val_loss: 2.2008 - val_accuracy: 0.1042\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2010 - accuracy: 0.1183 - val_loss: 2.2030 - val_accuracy: 0.0972\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1911 - accuracy: 0.1322 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1985 - accuracy: 0.1187 - val_loss: 2.1988 - val_accuracy: 0.1319\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2015 - accuracy: 0.0999 - val_loss: 2.2220 - val_accuracy: 0.1042\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1393 - val_loss: 35.9054 - val_accuracy: 0.1042\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2028 - accuracy: 0.1052 - val_loss: 2.2543 - val_accuracy: 0.1319\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1982 - accuracy: 0.1296 - val_loss: 197.5024 - val_accuracy: 0.1042\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2009 - accuracy: 0.1070 - val_loss: 2.2046 - val_accuracy: 0.1042\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1276 - val_loss: 2.2023 - val_accuracy: 0.1181\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.2073 - accuracy: 0.1262 - val_loss: 2.1982 - val_accuracy: 0.1597\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1299 - val_loss: 2.2033 - val_accuracy: 0.0972\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1989 - accuracy: 0.1212 - val_loss: 2.2009 - val_accuracy: 0.0972\n",
      "Accuracy: 0.0722, Loss: 2.2139\n",
      "\n",
      "--- Fold 5/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 42ms/step - loss: 2.4414 - accuracy: 0.1128 - val_loss: 2.1986 - val_accuracy: 0.1111\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1976 - accuracy: 0.1187 - val_loss: 2.1991 - val_accuracy: 0.0764\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1957 - accuracy: 0.1324 - val_loss: 2.2001 - val_accuracy: 0.0764\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1966 - accuracy: 0.1300 - val_loss: 2.2006 - val_accuracy: 0.0764\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1182 - val_loss: 2.2012 - val_accuracy: 0.0764\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1027 - val_loss: 2.2016 - val_accuracy: 0.0764\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1241 - val_loss: 2.2025 - val_accuracy: 0.0764\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1312 - val_loss: 2.2028 - val_accuracy: 0.0764\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.0966 - val_loss: 2.2022 - val_accuracy: 0.0764\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1555 - val_loss: 2.2032 - val_accuracy: 0.0764\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1142 - val_loss: 2.2042 - val_accuracy: 0.0764\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1361 - val_loss: 2.2043 - val_accuracy: 0.0764\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1956 - accuracy: 0.1304 - val_loss: 2.2041 - val_accuracy: 0.0764\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1291 - val_loss: 2.2047 - val_accuracy: 0.0764\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1935 - accuracy: 0.1359 - val_loss: 2.2052 - val_accuracy: 0.0764\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1263 - val_loss: 2.2049 - val_accuracy: 0.0764\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1401 - val_loss: 2.2046 - val_accuracy: 0.0764\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1173 - val_loss: 2.2047 - val_accuracy: 0.0764\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1929 - accuracy: 0.1376 - val_loss: 2.2050 - val_accuracy: 0.0764\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1946 - accuracy: 0.1231 - val_loss: 2.2057 - val_accuracy: 0.0764\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1387 - val_loss: 2.2058 - val_accuracy: 0.0764\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1268 - val_loss: 2.2053 - val_accuracy: 0.0764\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1948 - accuracy: 0.1365 - val_loss: 2.2054 - val_accuracy: 0.0764\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1961 - accuracy: 0.1287 - val_loss: 2.2052 - val_accuracy: 0.0764\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1165 - val_loss: 2.2059 - val_accuracy: 0.0764\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1252 - val_loss: 2.2060 - val_accuracy: 0.0764\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1986 - accuracy: 0.1136 - val_loss: 2.2057 - val_accuracy: 0.0764\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1927 - accuracy: 0.1496 - val_loss: 2.2058 - val_accuracy: 0.0764\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1268 - val_loss: 2.2057 - val_accuracy: 0.0764\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1985 - accuracy: 0.1163 - val_loss: 2.2054 - val_accuracy: 0.0764\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1979 - accuracy: 0.1204 - val_loss: 2.2056 - val_accuracy: 0.0764\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1953 - accuracy: 0.1229 - val_loss: 2.2055 - val_accuracy: 0.0764\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1166 - val_loss: 2.2056 - val_accuracy: 0.0764\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1952 - accuracy: 0.1243 - val_loss: 2.2059 - val_accuracy: 0.0764\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1390 - val_loss: 2.2064 - val_accuracy: 0.0764\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1928 - accuracy: 0.1289 - val_loss: 2.2065 - val_accuracy: 0.0764\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1926 - accuracy: 0.1383 - val_loss: 2.2066 - val_accuracy: 0.0764\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1977 - accuracy: 0.1125 - val_loss: 2.2063 - val_accuracy: 0.0764\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1954 - accuracy: 0.1198 - val_loss: 2.2069 - val_accuracy: 0.0764\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1922 - accuracy: 0.1374 - val_loss: 2.2078 - val_accuracy: 0.0764\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1962 - accuracy: 0.1199 - val_loss: 2.2078 - val_accuracy: 0.0764\n",
      "Accuracy: 0.0833, Loss: 2.1981\n",
      "\n",
      "mel_spectrogram - Mean Accuracy: 0.0933  0.0234\n",
      "\n",
      "==================================================\n",
      "Training model for mfcc\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0e30cbd73244f7b3785b2f851575c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mfcc Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/5 ---\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 2.1972 - accuracy: 0.0955 - val_loss: 2.1982 - val_accuracy: 0.0903\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1968 - accuracy: 0.1340 - val_loss: 2.1994 - val_accuracy: 0.0903\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1967 - accuracy: 0.1148 - val_loss: 2.2005 - val_accuracy: 0.0486\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1174 - val_loss: 2.2016 - val_accuracy: 0.0486\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1951 - accuracy: 0.1394 - val_loss: 2.2028 - val_accuracy: 0.0486\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1958 - accuracy: 0.1245 - val_loss: 2.2036 - val_accuracy: 0.0486\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1164 - val_loss: 2.2045 - val_accuracy: 0.0486\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1944 - accuracy: 0.1361 - val_loss: 2.2058 - val_accuracy: 0.0486\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1379 - val_loss: 2.2067 - val_accuracy: 0.0486\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1960 - accuracy: 0.1245 - val_loss: 2.2075 - val_accuracy: 0.0486\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1163 - val_loss: 2.2085 - val_accuracy: 0.0486\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.1484 - val_loss: 2.2093 - val_accuracy: 0.0486\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1933 - accuracy: 0.1223 - val_loss: 2.2102 - val_accuracy: 0.0486\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1931 - accuracy: 0.1307 - val_loss: 2.2110 - val_accuracy: 0.0486\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1927 - accuracy: 0.1127 - val_loss: 2.2117 - val_accuracy: 0.0486\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1930 - accuracy: 0.1172 - val_loss: 2.2126 - val_accuracy: 0.0486\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1920 - accuracy: 0.1377 - val_loss: 2.2135 - val_accuracy: 0.0486\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1910 - accuracy: 0.1222 - val_loss: 2.2142 - val_accuracy: 0.0486\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1964 - accuracy: 0.1251 - val_loss: 2.2145 - val_accuracy: 0.0486\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1922 - accuracy: 0.1124 - val_loss: 2.2154 - val_accuracy: 0.0486\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1920 - accuracy: 0.1436 - val_loss: 2.2161 - val_accuracy: 0.0486\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1951 - accuracy: 0.1390 - val_loss: 2.2166 - val_accuracy: 0.0486\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1089 - val_loss: 2.2172 - val_accuracy: 0.0486\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1892 - accuracy: 0.1382 - val_loss: 2.2181 - val_accuracy: 0.0486\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1332 - val_loss: 2.2185 - val_accuracy: 0.0486\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1914 - accuracy: 0.1375 - val_loss: 2.2192 - val_accuracy: 0.0486\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1402 - val_loss: 2.2196 - val_accuracy: 0.0486\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1909 - accuracy: 0.1382 - val_loss: 2.2204 - val_accuracy: 0.0486\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1907 - accuracy: 0.1308 - val_loss: 2.2209 - val_accuracy: 0.0486\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1261 - val_loss: 2.2213 - val_accuracy: 0.0486\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1921 - accuracy: 0.1201 - val_loss: 2.2219 - val_accuracy: 0.0486\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1876 - accuracy: 0.1389 - val_loss: 2.2224 - val_accuracy: 0.0486\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1236 - val_loss: 2.2227 - val_accuracy: 0.0486\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1913 - accuracy: 0.1307 - val_loss: 2.2231 - val_accuracy: 0.0486\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1856 - accuracy: 0.1433 - val_loss: 2.2240 - val_accuracy: 0.0486\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1936 - accuracy: 0.1255 - val_loss: 2.2242 - val_accuracy: 0.0486\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1913 - accuracy: 0.1159 - val_loss: 2.2246 - val_accuracy: 0.0486\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1926 - accuracy: 0.1374 - val_loss: 2.2247 - val_accuracy: 0.0486\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1889 - accuracy: 0.1446 - val_loss: 2.2253 - val_accuracy: 0.0486\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1921 - accuracy: 0.1255 - val_loss: 2.2255 - val_accuracy: 0.0486\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1873 - accuracy: 0.1494 - val_loss: 2.2261 - val_accuracy: 0.0486\n",
      "Accuracy: 0.0889, Loss: 2.1977\n",
      "\n",
      "--- Fold 2/5 ---\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/envs/myenv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 11ms/step - loss: 2.1973 - accuracy: 0.1139 - val_loss: 2.1974 - val_accuracy: 0.1042\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1969 - accuracy: 0.1033 - val_loss: 2.1979 - val_accuracy: 0.0903\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1965 - accuracy: 0.1396 - val_loss: 2.1982 - val_accuracy: 0.0903\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1970 - accuracy: 0.1164 - val_loss: 2.1984 - val_accuracy: 0.0903\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1258 - val_loss: 2.1989 - val_accuracy: 0.0903\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.1175 - val_loss: 2.1992 - val_accuracy: 0.0903\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1962 - accuracy: 0.1351 - val_loss: 2.1996 - val_accuracy: 0.0903\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1963 - accuracy: 0.1198 - val_loss: 2.2000 - val_accuracy: 0.0903\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1948 - accuracy: 0.1198 - val_loss: 2.2003 - val_accuracy: 0.0903\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1946 - accuracy: 0.1363 - val_loss: 2.2006 - val_accuracy: 0.0903\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1941 - accuracy: 0.1275 - val_loss: 2.2009 - val_accuracy: 0.0903\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1375 - val_loss: 2.2012 - val_accuracy: 0.0903\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1982 - accuracy: 0.1120 - val_loss: 2.2014 - val_accuracy: 0.0903\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1400 - val_loss: 2.2018 - val_accuracy: 0.0903\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1950 - accuracy: 0.1358 - val_loss: 2.2020 - val_accuracy: 0.0903\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1958 - accuracy: 0.1232 - val_loss: 2.2023 - val_accuracy: 0.0903\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1949 - accuracy: 0.1187 - val_loss: 2.2026 - val_accuracy: 0.0903\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1302 - val_loss: 2.2029 - val_accuracy: 0.0903\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1223 - val_loss: 2.2032 - val_accuracy: 0.0903\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1401 - val_loss: 2.2036 - val_accuracy: 0.0903\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1949 - accuracy: 0.1207 - val_loss: 2.2036 - val_accuracy: 0.0903\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1943 - accuracy: 0.1448 - val_loss: 2.2040 - val_accuracy: 0.0903\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1941 - accuracy: 0.1176 - val_loss: 2.2042 - val_accuracy: 0.0903\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1938 - accuracy: 0.1448 - val_loss: 2.2043 - val_accuracy: 0.0903\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1914 - accuracy: 0.1591 - val_loss: 2.2047 - val_accuracy: 0.0903\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1926 - accuracy: 0.1502 - val_loss: 2.2048 - val_accuracy: 0.0903\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1487 - val_loss: 2.2051 - val_accuracy: 0.0903\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1969 - accuracy: 0.1168 - val_loss: 2.2051 - val_accuracy: 0.0903\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1934 - accuracy: 0.1199 - val_loss: 2.2054 - val_accuracy: 0.0903\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1932 - accuracy: 0.1185 - val_loss: 2.2058 - val_accuracy: 0.0903\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1947 - accuracy: 0.1320 - val_loss: 2.2058 - val_accuracy: 0.0903\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1929 - accuracy: 0.1369 - val_loss: 2.2060 - val_accuracy: 0.0903\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1939 - accuracy: 0.1383 - val_loss: 2.2062 - val_accuracy: 0.0903\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1935 - accuracy: 0.1335 - val_loss: 2.2063 - val_accuracy: 0.0903\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1900 - accuracy: 0.1496 - val_loss: 2.2067 - val_accuracy: 0.0903\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.1942 - accuracy: 0.1207 - val_loss: 2.2067 - val_accuracy: 0.0903\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1959 - accuracy: 0.1177 - val_loss: 2.2068 - val_accuracy: 0.0903\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 2.1947 - accuracy: 0.1359 - val_loss: 2.2071 - val_accuracy: 0.0903\n",
      "Epoch 39/200\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 2.2138 - accuracy: 0.1250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 69\u001b[0m\n\u001b[1;32m     64\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     65\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m feature_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistories\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training results storage\n",
    "all_results = {}\n",
    "all_models = {}\n",
    "\n",
    "# Fit on the full dataset\n",
    "global_label_encoder = LabelEncoder()\n",
    "global_label_encoder.fit(df['instrumentID'])  # Use original labels\n",
    "\n",
    "\n",
    "# Train individual models for each feature type\n",
    "for feature_type in tqdm(available_feature_types, desc = \"Feature Types\"):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training model for {feature_type}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = df_dict[feature_type]\n",
    "    input_shape = FEATURE_SHAPES[feature_type]\n",
    "    \n",
    "    # Initialize results storage for this feature type\n",
    "    feature_results = {\n",
    "        'accuracy_list': [],\n",
    "        'loss_list': [],\n",
    "        'classification_reports': [],\n",
    "        'confusion_matrices': [],\n",
    "        'histories': [],\n",
    "        'models': []\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(list(kf.split(df)), desc = f\"{feature_type} Folds\")):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Further split training data\n",
    "        train_indices, val_indices = train_test_split(\n",
    "            np.arange(len(train_df)), test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        val_df = train_df.iloc[val_indices].reset_index(drop=True)\n",
    "        train_df = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "        \n",
    "        # --- DEBUG: Check label distribution in training set ---\n",
    "        print(\"Label distribution in train_df:\", train_df['instrumentID'].value_counts())\n",
    "        print(\"Any NaNs in X?\", np.isnan(X).any())\n",
    "        print(\"All X values the same?\", np.all(X == X.flat[0]))\n",
    "        # --- END DEBUG ---\n",
    "        \n",
    "        # Create data generators\n",
    "        train_generator = SingleFeatureDataGenerator(train_df, feature_type, label_encoder=global_label_encoder)\n",
    "        val_generator = SingleFeatureDataGenerator(val_df, feature_type, label_encoder=global_label_encoder)\n",
    "        test_generator = SingleFeatureDataGenerator(test_df, feature_type, label_encoder=global_label_encoder)\n",
    "        \n",
    "        \n",
    "        # --- DEBUG: Inspect a batch from the generator ---\n",
    "        X, y = train_generator[0]\n",
    "        print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "        print(\"X min/max:\", np.min(X), np.max(X))\n",
    "        print(\"y (class distribution in batch):\", np.sum(y, axis=0))\n",
    "        plt.imshow(X[0, :, :, 0], aspect='auto')\n",
    "        plt.title(\"First feature image in batch\")\n",
    "        plt.show()\n",
    "        print(\"First label (one-hot):\", y[0])\n",
    "        print(\"First label (class index):\", np.argmax(y[0]))\n",
    "        # --- END DEBUG ---\n",
    "\n",
    "        \n",
    "        # Create and compile model\n",
    "        model = create_simple_model(input_shape, num_classes, f\"{feature_type}_model\")\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        \n",
    "        # Early stopping\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=40, restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        feature_results['histories'].append(history.history)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        loss, accuracy = model.evaluate(test_generator, verbose=0)\n",
    "        feature_results['accuracy_list'].append(accuracy)\n",
    "        feature_results['loss_list'].append(loss)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}, Loss: {loss:.4f}\")\n",
    "        \n",
    "        # Predict and generate reports\n",
    "        y_pred = model.predict(test_generator, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_true = test_generator.get_labels()\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_true, y_pred_classes, output_dict=True)\n",
    "        feature_results['classification_reports'].append(report)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred_classes).tolist()\n",
    "        feature_results['confusion_matrices'].append(conf_matrix)\n",
    "        \n",
    "        # Save the best model (last one for now)\n",
    "        feature_results['models'].append(model)\n",
    "    \n",
    "    # Store results for this feature type\n",
    "    all_results[feature_type] = feature_results\n",
    "    all_models[feature_type] = feature_results['models'][-1]  # Save the last model\n",
    "    \n",
    "    # Print summary for this feature type\n",
    "    mean_acc = np.mean(feature_results['accuracy_list'])\n",
    "    std_acc = np.std(feature_results['accuracy_list'])\n",
    "    print(f\"\\n{feature_type} - Mean Accuracy: {mean_acc:.4f}  {std_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble predictions\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Creating Ensemble Predictions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use the last fold of each feature type for ensemble evaluation\n",
    "ensemble_results = {\n",
    "    'accuracy_list': [],\n",
    "    'loss_list': [],\n",
    "    'classification_reports': [],\n",
    "    'confusion_matrices': []\n",
    "}\n",
    "\n",
    "# For simplicity, we'll use the last fold of each feature type\n",
    "for fold in tqdm(range(KFOLD_SPLITS), desc = \"Ensemble Folds\", Leave = True):\n",
    "    print(f\"\\n--- Ensemble Fold {fold + 1}/{KFOLD_SPLITS} ---\")\n",
    "    \n",
    "    # Get predictions from all models for this fold\n",
    "    all_predictions = {}\n",
    "    \n",
    "    for feature_type in available_feature_types:\n",
    "        if feature_type in all_results:\n",
    "            # Get the model from this fold\n",
    "            model = all_results[feature_type]['models'][fold]\n",
    "            \n",
    "            # Get test data for this fold (we need to recreate it)\n",
    "            df = df_dict[feature_type]\n",
    "            kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=42)\n",
    "            train_idx, test_idx = list(kf.split(df))[fold]\n",
    "            test_df = df.iloc[test_idx].reset_index(drop=True)\n",
    "            \n",
    "            test_generator = SingleFeatureDataGenerator(test_df, feature_type, batch_size=BATCH_SIZE, shuffle=False)\n",
    "            \n",
    "            # Get predictions\n",
    "            pred = model.predict(test_generator, verbose=0)\n",
    "            all_predictions[feature_type] = pred\n",
    "            \n",
    "            # Store true labels (should be the same for all feature types)\n",
    "            if 'y_true' not in locals():\n",
    "                y_true = test_generator.get_labels()\n",
    "    \n",
    "    # Simple averaging ensemble\n",
    "    if all_predictions:\n",
    "        ensemble_pred = np.mean(list(all_predictions.values()), axis=0)\n",
    "        ensemble_pred_classes = np.argmax(ensemble_pred, axis=1)\n",
    "        \n",
    "        # Calculate ensemble accuracy\n",
    "        ensemble_accuracy = accuracy_score(y_true, ensemble_pred_classes)\n",
    "        ensemble_results['accuracy_list'].append(ensemble_accuracy)\n",
    "        \n",
    "        print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_true, ensemble_pred_classes, output_dict=True)\n",
    "        ensemble_results['classification_reports'].append(report)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true, ensemble_pred_classes).tolist()\n",
    "        ensemble_results['confusion_matrices'].append(conf_matrix)\n",
    "\n",
    "# Store ensemble results\n",
    "all_results['ensemble'] = ensemble_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and models\n",
    "try:\n",
    "    os.mkdir(\"ensemble_models\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists\")\n",
    "except Exception:\n",
    "    print(\"Unknown error\")\n",
    "\n",
    "# Create version folder\n",
    "date_part = datetime.now().date().__str__().replace('-', '_')\n",
    "last_version = os.listdir(path=\"ensemble_models\") if os.path.exists(\"ensemble_models\") else []\n",
    "last_version = [name.rpartition(\"_v\")[-1] for name in last_version if date_part in name]\n",
    "if len(last_version):\n",
    "    last_version = int(sorted(last_version)[-1])\n",
    "else:\n",
    "    last_version = 0\n",
    "folder_name = f\"{date_part}_v{last_version+1}\"\n",
    "\n",
    "os.makedirs(os.path.join(\"ensemble_models\", folder_name), exist_ok=True)\n",
    "\n",
    "# Save individual models\n",
    "for feature_type, model in all_models.items():\n",
    "    model_path = os.path.join(\"ensemble_models\", folder_name, f\"{feature_type}_model.h5\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Saved {feature_type} model to {model_path}\")\n",
    "\n",
    "# Save results\n",
    "results_data = {\n",
    "    'individual_results': {ft: {k: v for k, v in res.items() if k != 'models'} \n",
    "                          for ft, res in all_results.items() if ft != 'ensemble'},\n",
    "    'ensemble_results': all_results['ensemble'],\n",
    "    'feature_types': available_feature_types,\n",
    "    'num_classes': num_classes,\n",
    "    'feature_shapes': FEATURE_SHAPES,\n",
    "    'training_config': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'kfold_splits': KFOLD_SPLITS,\n",
    "        'fixed_length': FIXED_LENGTH\n",
    "    },\n",
    "    'instrument_mappings': instruments_mappings.to_dict()\n",
    "}\n",
    "\n",
    "results_path = os.path.join(\"ensemble_models\", folder_name, \"results.json\")\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\nResults saved to: {results_path}\")\n",
    "print(f\"Models saved to: ensemble_models/{folder_name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nIndividual Model Performance:\")\n",
    "for feature_type in available_feature_types:\n",
    "    if feature_type in all_results:\n",
    "        accuracies = all_results[feature_type]['accuracy_list']\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        print(f\"  {feature_type}: {mean_acc:.4f}  {std_acc:.4f}\")\n",
    "\n",
    "print(\"\\nEnsemble Performance:\")\n",
    "if 'ensemble' in all_results:\n",
    "    ensemble_accuracies = all_results['ensemble']['accuracy_list']\n",
    "    ensemble_mean = np.mean(ensemble_accuracies)\n",
    "    ensemble_std = np.std(ensemble_accuracies)\n",
    "    print(f\"  Ensemble: {ensemble_mean:.4f}  {ensemble_std:.4f}\")\n",
    "\n",
    "# Find best individual model\n",
    "best_individual = max(\n",
    "    [(ft, np.mean(all_results[ft]['accuracy_list'])) \n",
    "     for ft in available_feature_types if ft in all_results],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "improvement = ensemble_mean - best_individual[1]\n",
    "print(f\"\\nBest Individual Model: {best_individual[0]} ({best_individual[1]:.4f})\")\n",
    "print(f\"Ensemble Improvement: {improvement:.4f} ({improvement*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
